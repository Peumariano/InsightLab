/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/openai/_shims/MultipartBody.mjs":
/*!******************************************************!*\
  !*** ./node_modules/openai/_shims/MultipartBody.mjs ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   MultipartBody: () => (/* binding */ MultipartBody)\n/* harmony export */ });\n/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nclass MultipartBody {\n    constructor(body) {\n        this.body = body;\n    }\n    get [Symbol.toStringTag]() {\n        return 'MultipartBody';\n    }\n}\n//# sourceMappingURL=MultipartBody.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/_shims/MultipartBody.mjs?");

/***/ }),

/***/ "./node_modules/openai/_shims/index.mjs":
/*!**********************************************!*\
  !*** ./node_modules/openai/_shims/index.mjs ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Blob: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.Blob),\n/* harmony export */   File: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.File),\n/* harmony export */   FormData: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.FormData),\n/* harmony export */   Headers: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.Headers),\n/* harmony export */   ReadableStream: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.ReadableStream),\n/* harmony export */   Request: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.Request),\n/* harmony export */   Response: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.Response),\n/* harmony export */   auto: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.auto),\n/* harmony export */   fetch: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.fetch),\n/* harmony export */   fileFromPath: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.fileFromPath),\n/* harmony export */   getDefaultAgent: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.getDefaultAgent),\n/* harmony export */   getMultipartRequestOptions: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.getMultipartRequestOptions),\n/* harmony export */   isFsReadStream: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.isFsReadStream),\n/* harmony export */   kind: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.kind),\n/* harmony export */   setShims: () => (/* reexport safe */ _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.setShims)\n/* harmony export */ });\n/* harmony import */ var _registry_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./registry.mjs */ \"./node_modules/openai/_shims/registry.mjs\");\n/* harmony import */ var openai_shims_auto_runtime__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! openai/_shims/auto/runtime */ \"./node_modules/openai/_shims/web-runtime.mjs\");\n/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\n\n\nif (!_registry_mjs__WEBPACK_IMPORTED_MODULE_0__.kind) _registry_mjs__WEBPACK_IMPORTED_MODULE_0__.setShims(openai_shims_auto_runtime__WEBPACK_IMPORTED_MODULE_1__.getRuntime(), { auto: true });\n\n\n\n//# sourceURL=webpack://y/./node_modules/openai/_shims/index.mjs?");

/***/ }),

/***/ "./node_modules/openai/_shims/registry.mjs":
/*!*************************************************!*\
  !*** ./node_modules/openai/_shims/registry.mjs ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Blob: () => (/* binding */ Blob),\n/* harmony export */   File: () => (/* binding */ File),\n/* harmony export */   FormData: () => (/* binding */ FormData),\n/* harmony export */   Headers: () => (/* binding */ Headers),\n/* harmony export */   ReadableStream: () => (/* binding */ ReadableStream),\n/* harmony export */   Request: () => (/* binding */ Request),\n/* harmony export */   Response: () => (/* binding */ Response),\n/* harmony export */   auto: () => (/* binding */ auto),\n/* harmony export */   fetch: () => (/* binding */ fetch),\n/* harmony export */   fileFromPath: () => (/* binding */ fileFromPath),\n/* harmony export */   getDefaultAgent: () => (/* binding */ getDefaultAgent),\n/* harmony export */   getMultipartRequestOptions: () => (/* binding */ getMultipartRequestOptions),\n/* harmony export */   isFsReadStream: () => (/* binding */ isFsReadStream),\n/* harmony export */   kind: () => (/* binding */ kind),\n/* harmony export */   setShims: () => (/* binding */ setShims)\n/* harmony export */ });\nlet auto = false;\nlet kind = undefined;\nlet fetch = undefined;\nlet Request = undefined;\nlet Response = undefined;\nlet Headers = undefined;\nlet FormData = undefined;\nlet Blob = undefined;\nlet File = undefined;\nlet ReadableStream = undefined;\nlet getMultipartRequestOptions = undefined;\nlet getDefaultAgent = undefined;\nlet fileFromPath = undefined;\nlet isFsReadStream = undefined;\nfunction setShims(shims, options = { auto: false }) {\n    if (auto) {\n        throw new Error(`you must \\`import 'openai/shims/${shims.kind}'\\` before importing anything else from openai`);\n    }\n    if (kind) {\n        throw new Error(`can't \\`import 'openai/shims/${shims.kind}'\\` after \\`import 'openai/shims/${kind}'\\``);\n    }\n    auto = options.auto;\n    kind = shims.kind;\n    fetch = shims.fetch;\n    Request = shims.Request;\n    Response = shims.Response;\n    Headers = shims.Headers;\n    FormData = shims.FormData;\n    Blob = shims.Blob;\n    File = shims.File;\n    ReadableStream = shims.ReadableStream;\n    getMultipartRequestOptions = shims.getMultipartRequestOptions;\n    getDefaultAgent = shims.getDefaultAgent;\n    fileFromPath = shims.fileFromPath;\n    isFsReadStream = shims.isFsReadStream;\n}\n//# sourceMappingURL=registry.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/_shims/registry.mjs?");

/***/ }),

/***/ "./node_modules/openai/_shims/web-runtime.mjs":
/*!****************************************************!*\
  !*** ./node_modules/openai/_shims/web-runtime.mjs ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getRuntime: () => (/* binding */ getRuntime)\n/* harmony export */ });\n/* harmony import */ var _MultipartBody_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./MultipartBody.mjs */ \"./node_modules/openai/_shims/MultipartBody.mjs\");\n\nfunction getRuntime({ manuallyImported } = {}) {\n    const recommendation = manuallyImported ?\n        `You may need to use polyfills`\n        : `Add one of these imports before your first \\`import â€¦ from 'openai'\\`:\n- \\`import 'openai/shims/node'\\` (if you're running on Node)\n- \\`import 'openai/shims/web'\\` (otherwise)\n`;\n    let _fetch, _Request, _Response, _Headers;\n    try {\n        // @ts-ignore\n        _fetch = fetch;\n        // @ts-ignore\n        _Request = Request;\n        // @ts-ignore\n        _Response = Response;\n        // @ts-ignore\n        _Headers = Headers;\n    }\n    catch (error) {\n        throw new Error(`this environment is missing the following Web Fetch API type: ${error.message}. ${recommendation}`);\n    }\n    return {\n        kind: 'web',\n        fetch: _fetch,\n        Request: _Request,\n        Response: _Response,\n        Headers: _Headers,\n        FormData: \n        // @ts-ignore\n        typeof FormData !== 'undefined' ? FormData : (class FormData {\n            // @ts-ignore\n            constructor() {\n                throw new Error(`file uploads aren't supported in this environment yet as 'FormData' is undefined. ${recommendation}`);\n            }\n        }),\n        Blob: typeof Blob !== 'undefined' ? Blob : (class Blob {\n            constructor() {\n                throw new Error(`file uploads aren't supported in this environment yet as 'Blob' is undefined. ${recommendation}`);\n            }\n        }),\n        File: \n        // @ts-ignore\n        typeof File !== 'undefined' ? File : (class File {\n            // @ts-ignore\n            constructor() {\n                throw new Error(`file uploads aren't supported in this environment yet as 'File' is undefined. ${recommendation}`);\n            }\n        }),\n        ReadableStream: \n        // @ts-ignore\n        typeof ReadableStream !== 'undefined' ? ReadableStream : (class ReadableStream {\n            // @ts-ignore\n            constructor() {\n                throw new Error(`streaming isn't supported in this environment yet as 'ReadableStream' is undefined. ${recommendation}`);\n            }\n        }),\n        getMultipartRequestOptions: async (\n        // @ts-ignore\n        form, opts) => ({\n            ...opts,\n            body: new _MultipartBody_mjs__WEBPACK_IMPORTED_MODULE_0__.MultipartBody(form),\n        }),\n        getDefaultAgent: (url) => undefined,\n        fileFromPath: () => {\n            throw new Error('The `fileFromPath` function is only supported in Node. See the README for more details: https://www.github.com/openai/openai-node#file-uploads');\n        },\n        isFsReadStream: (value) => false,\n    };\n}\n//# sourceMappingURL=web-runtime.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/_shims/web-runtime.mjs?");

/***/ }),

/***/ "./node_modules/openai/_vendor/partial-json-parser/parser.mjs":
/*!********************************************************************!*\
  !*** ./node_modules/openai/_vendor/partial-json-parser/parser.mjs ***!
  \********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   MalformedJSON: () => (/* binding */ MalformedJSON),\n/* harmony export */   PartialJSON: () => (/* binding */ PartialJSON),\n/* harmony export */   partialParse: () => (/* binding */ partialParse)\n/* harmony export */ });\nconst STR = 0b000000001;\nconst NUM = 0b000000010;\nconst ARR = 0b000000100;\nconst OBJ = 0b000001000;\nconst NULL = 0b000010000;\nconst BOOL = 0b000100000;\nconst NAN = 0b001000000;\nconst INFINITY = 0b010000000;\nconst MINUS_INFINITY = 0b100000000;\nconst INF = INFINITY | MINUS_INFINITY;\nconst SPECIAL = NULL | BOOL | INF | NAN;\nconst ATOM = STR | NUM | SPECIAL;\nconst COLLECTION = ARR | OBJ;\nconst ALL = ATOM | COLLECTION;\nconst Allow = {\n    STR,\n    NUM,\n    ARR,\n    OBJ,\n    NULL,\n    BOOL,\n    NAN,\n    INFINITY,\n    MINUS_INFINITY,\n    INF,\n    SPECIAL,\n    ATOM,\n    COLLECTION,\n    ALL,\n};\n// The JSON string segment was unable to be parsed completely\nclass PartialJSON extends Error {\n}\nclass MalformedJSON extends Error {\n}\n/**\n * Parse incomplete JSON\n * @param {string} jsonString Partial JSON to be parsed\n * @param {number} allowPartial Specify what types are allowed to be partial, see {@link Allow} for details\n * @returns The parsed JSON\n * @throws {PartialJSON} If the JSON is incomplete (related to the `allow` parameter)\n * @throws {MalformedJSON} If the JSON is malformed\n */\nfunction parseJSON(jsonString, allowPartial = Allow.ALL) {\n    if (typeof jsonString !== 'string') {\n        throw new TypeError(`expecting str, got ${typeof jsonString}`);\n    }\n    if (!jsonString.trim()) {\n        throw new Error(`${jsonString} is empty`);\n    }\n    return _parseJSON(jsonString.trim(), allowPartial);\n}\nconst _parseJSON = (jsonString, allow) => {\n    const length = jsonString.length;\n    let index = 0;\n    const markPartialJSON = (msg) => {\n        throw new PartialJSON(`${msg} at position ${index}`);\n    };\n    const throwMalformedError = (msg) => {\n        throw new MalformedJSON(`${msg} at position ${index}`);\n    };\n    const parseAny = () => {\n        skipBlank();\n        if (index >= length)\n            markPartialJSON('Unexpected end of input');\n        if (jsonString[index] === '\"')\n            return parseStr();\n        if (jsonString[index] === '{')\n            return parseObj();\n        if (jsonString[index] === '[')\n            return parseArr();\n        if (jsonString.substring(index, index + 4) === 'null' ||\n            (Allow.NULL & allow && length - index < 4 && 'null'.startsWith(jsonString.substring(index)))) {\n            index += 4;\n            return null;\n        }\n        if (jsonString.substring(index, index + 4) === 'true' ||\n            (Allow.BOOL & allow && length - index < 4 && 'true'.startsWith(jsonString.substring(index)))) {\n            index += 4;\n            return true;\n        }\n        if (jsonString.substring(index, index + 5) === 'false' ||\n            (Allow.BOOL & allow && length - index < 5 && 'false'.startsWith(jsonString.substring(index)))) {\n            index += 5;\n            return false;\n        }\n        if (jsonString.substring(index, index + 8) === 'Infinity' ||\n            (Allow.INFINITY & allow && length - index < 8 && 'Infinity'.startsWith(jsonString.substring(index)))) {\n            index += 8;\n            return Infinity;\n        }\n        if (jsonString.substring(index, index + 9) === '-Infinity' ||\n            (Allow.MINUS_INFINITY & allow &&\n                1 < length - index &&\n                length - index < 9 &&\n                '-Infinity'.startsWith(jsonString.substring(index)))) {\n            index += 9;\n            return -Infinity;\n        }\n        if (jsonString.substring(index, index + 3) === 'NaN' ||\n            (Allow.NAN & allow && length - index < 3 && 'NaN'.startsWith(jsonString.substring(index)))) {\n            index += 3;\n            return NaN;\n        }\n        return parseNum();\n    };\n    const parseStr = () => {\n        const start = index;\n        let escape = false;\n        index++; // skip initial quote\n        while (index < length && (jsonString[index] !== '\"' || (escape && jsonString[index - 1] === '\\\\'))) {\n            escape = jsonString[index] === '\\\\' ? !escape : false;\n            index++;\n        }\n        if (jsonString.charAt(index) == '\"') {\n            try {\n                return JSON.parse(jsonString.substring(start, ++index - Number(escape)));\n            }\n            catch (e) {\n                throwMalformedError(String(e));\n            }\n        }\n        else if (Allow.STR & allow) {\n            try {\n                return JSON.parse(jsonString.substring(start, index - Number(escape)) + '\"');\n            }\n            catch (e) {\n                // SyntaxError: Invalid escape sequence\n                return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf('\\\\')) + '\"');\n            }\n        }\n        markPartialJSON('Unterminated string literal');\n    };\n    const parseObj = () => {\n        index++; // skip initial brace\n        skipBlank();\n        const obj = {};\n        try {\n            while (jsonString[index] !== '}') {\n                skipBlank();\n                if (index >= length && Allow.OBJ & allow)\n                    return obj;\n                const key = parseStr();\n                skipBlank();\n                index++; // skip colon\n                try {\n                    const value = parseAny();\n                    Object.defineProperty(obj, key, { value, writable: true, enumerable: true, configurable: true });\n                }\n                catch (e) {\n                    if (Allow.OBJ & allow)\n                        return obj;\n                    else\n                        throw e;\n                }\n                skipBlank();\n                if (jsonString[index] === ',')\n                    index++; // skip comma\n            }\n        }\n        catch (e) {\n            if (Allow.OBJ & allow)\n                return obj;\n            else\n                markPartialJSON(\"Expected '}' at end of object\");\n        }\n        index++; // skip final brace\n        return obj;\n    };\n    const parseArr = () => {\n        index++; // skip initial bracket\n        const arr = [];\n        try {\n            while (jsonString[index] !== ']') {\n                arr.push(parseAny());\n                skipBlank();\n                if (jsonString[index] === ',') {\n                    index++; // skip comma\n                }\n            }\n        }\n        catch (e) {\n            if (Allow.ARR & allow) {\n                return arr;\n            }\n            markPartialJSON(\"Expected ']' at end of array\");\n        }\n        index++; // skip final bracket\n        return arr;\n    };\n    const parseNum = () => {\n        if (index === 0) {\n            if (jsonString === '-' && Allow.NUM & allow)\n                markPartialJSON(\"Not sure what '-' is\");\n            try {\n                return JSON.parse(jsonString);\n            }\n            catch (e) {\n                if (Allow.NUM & allow) {\n                    try {\n                        if ('.' === jsonString[jsonString.length - 1])\n                            return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf('.')));\n                        return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf('e')));\n                    }\n                    catch (e) { }\n                }\n                throwMalformedError(String(e));\n            }\n        }\n        const start = index;\n        if (jsonString[index] === '-')\n            index++;\n        while (jsonString[index] && !',]}'.includes(jsonString[index]))\n            index++;\n        if (index == length && !(Allow.NUM & allow))\n            markPartialJSON('Unterminated number literal');\n        try {\n            return JSON.parse(jsonString.substring(start, index));\n        }\n        catch (e) {\n            if (jsonString.substring(start, index) === '-' && Allow.NUM & allow)\n                markPartialJSON(\"Not sure what '-' is\");\n            try {\n                return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf('e')));\n            }\n            catch (e) {\n                throwMalformedError(String(e));\n            }\n        }\n    };\n    const skipBlank = () => {\n        while (index < length && ' \\n\\r\\t'.includes(jsonString[index])) {\n            index++;\n        }\n    };\n    return parseAny();\n};\n// using this function with malformed JSON is undefined behavior\nconst partialParse = (input) => parseJSON(input, Allow.ALL ^ Allow.NUM);\n\n//# sourceMappingURL=parser.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/_vendor/partial-json-parser/parser.mjs?");

/***/ }),

/***/ "./node_modules/openai/core.mjs":
/*!**************************************!*\
  !*** ./node_modules/openai/core.mjs ***!
  \**************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   APIClient: () => (/* binding */ APIClient),\n/* harmony export */   APIPromise: () => (/* binding */ APIPromise),\n/* harmony export */   AbstractPage: () => (/* binding */ AbstractPage),\n/* harmony export */   PagePromise: () => (/* binding */ PagePromise),\n/* harmony export */   castToError: () => (/* binding */ castToError),\n/* harmony export */   coerceBoolean: () => (/* binding */ coerceBoolean),\n/* harmony export */   coerceFloat: () => (/* binding */ coerceFloat),\n/* harmony export */   coerceInteger: () => (/* binding */ coerceInteger),\n/* harmony export */   createForm: () => (/* reexport safe */ _uploads_mjs__WEBPACK_IMPORTED_MODULE_1__.createForm),\n/* harmony export */   createResponseHeaders: () => (/* binding */ createResponseHeaders),\n/* harmony export */   debug: () => (/* binding */ debug),\n/* harmony export */   ensurePresent: () => (/* binding */ ensurePresent),\n/* harmony export */   getHeader: () => (/* binding */ getHeader),\n/* harmony export */   getRequiredHeader: () => (/* binding */ getRequiredHeader),\n/* harmony export */   hasOwn: () => (/* binding */ hasOwn),\n/* harmony export */   isEmptyObj: () => (/* binding */ isEmptyObj),\n/* harmony export */   isHeadersProtocol: () => (/* binding */ isHeadersProtocol),\n/* harmony export */   isObj: () => (/* binding */ isObj),\n/* harmony export */   isRequestOptions: () => (/* binding */ isRequestOptions),\n/* harmony export */   isRunningInBrowser: () => (/* binding */ isRunningInBrowser),\n/* harmony export */   maybeCoerceBoolean: () => (/* binding */ maybeCoerceBoolean),\n/* harmony export */   maybeCoerceFloat: () => (/* binding */ maybeCoerceFloat),\n/* harmony export */   maybeCoerceInteger: () => (/* binding */ maybeCoerceInteger),\n/* harmony export */   maybeMultipartFormRequestOptions: () => (/* reexport safe */ _uploads_mjs__WEBPACK_IMPORTED_MODULE_1__.maybeMultipartFormRequestOptions),\n/* harmony export */   multipartFormRequestOptions: () => (/* reexport safe */ _uploads_mjs__WEBPACK_IMPORTED_MODULE_1__.multipartFormRequestOptions),\n/* harmony export */   readEnv: () => (/* binding */ readEnv),\n/* harmony export */   safeJSON: () => (/* binding */ safeJSON),\n/* harmony export */   sleep: () => (/* binding */ sleep),\n/* harmony export */   toBase64: () => (/* binding */ toBase64)\n/* harmony export */ });\n/* harmony import */ var _version_mjs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./version.mjs */ \"./node_modules/openai/version.mjs\");\n/* harmony import */ var _streaming_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./streaming.mjs */ \"./node_modules/openai/streaming.mjs\");\n/* harmony import */ var _error_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./error.mjs */ \"./node_modules/openai/error.mjs\");\n/* harmony import */ var _shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./_shims/index.mjs */ \"./node_modules/openai/_shims/index.mjs\");\n/* harmony import */ var _uploads_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./uploads.mjs */ \"./node_modules/openai/uploads.mjs\");\nvar __classPrivateFieldSet = (undefined && undefined.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {\n    if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n    return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n};\nvar __classPrivateFieldGet = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar _AbstractPage_client;\n\n\n\n\n\n\nasync function defaultParseResponse(props) {\n    const { response } = props;\n    if (props.options.stream) {\n        debug('response', response.status, response.url, response.headers, response.body);\n        // Note: there is an invariant here that isn't represented in the type system\n        // that if you set `stream: true` the response type must also be `Stream<T>`\n        if (props.options.__streamClass) {\n            return props.options.__streamClass.fromSSEResponse(response, props.controller);\n        }\n        return _streaming_mjs__WEBPACK_IMPORTED_MODULE_2__.Stream.fromSSEResponse(response, props.controller);\n    }\n    // fetch refuses to read the body when the status code is 204.\n    if (response.status === 204) {\n        return null;\n    }\n    if (props.options.__binaryResponse) {\n        return response;\n    }\n    const contentType = response.headers.get('content-type');\n    const isJSON = contentType?.includes('application/json') || contentType?.includes('application/vnd.api+json');\n    if (isJSON) {\n        const json = await response.json();\n        debug('response', response.status, response.url, response.headers, json);\n        return _addRequestID(json, response);\n    }\n    const text = await response.text();\n    debug('response', response.status, response.url, response.headers, text);\n    // TODO handle blob, arraybuffer, other content types, etc.\n    return text;\n}\nfunction _addRequestID(value, response) {\n    if (!value || typeof value !== 'object' || Array.isArray(value)) {\n        return value;\n    }\n    return Object.defineProperty(value, '_request_id', {\n        value: response.headers.get('x-request-id'),\n        enumerable: false,\n    });\n}\n/**\n * A subclass of `Promise` providing additional helper methods\n * for interacting with the SDK.\n */\nclass APIPromise extends Promise {\n    constructor(responsePromise, parseResponse = defaultParseResponse) {\n        super((resolve) => {\n            // this is maybe a bit weird but this has to be a no-op to not implicitly\n            // parse the response body; instead .then, .catch, .finally are overridden\n            // to parse the response\n            resolve(null);\n        });\n        this.responsePromise = responsePromise;\n        this.parseResponse = parseResponse;\n    }\n    _thenUnwrap(transform) {\n        return new APIPromise(this.responsePromise, async (props) => _addRequestID(transform(await this.parseResponse(props), props), props.response));\n    }\n    /**\n     * Gets the raw `Response` instance instead of parsing the response\n     * data.\n     *\n     * If you want to parse the response body but still get the `Response`\n     * instance, you can use {@link withResponse()}.\n     *\n     * ðŸ‘‹ Getting the wrong TypeScript type for `Response`?\n     * Try setting `\"moduleResolution\": \"NodeNext\"` if you can,\n     * or add one of these imports before your first `import â€¦ from 'openai'`:\n     * - `import 'openai/shims/node'` (if you're running on Node)\n     * - `import 'openai/shims/web'` (otherwise)\n     */\n    asResponse() {\n        return this.responsePromise.then((p) => p.response);\n    }\n    /**\n     * Gets the parsed response data, the raw `Response` instance and the ID of the request,\n     * returned via the X-Request-ID header which is useful for debugging requests and reporting\n     * issues to OpenAI.\n     *\n     * If you just want to get the raw `Response` instance without parsing it,\n     * you can use {@link asResponse()}.\n     *\n     *\n     * ðŸ‘‹ Getting the wrong TypeScript type for `Response`?\n     * Try setting `\"moduleResolution\": \"NodeNext\"` if you can,\n     * or add one of these imports before your first `import â€¦ from 'openai'`:\n     * - `import 'openai/shims/node'` (if you're running on Node)\n     * - `import 'openai/shims/web'` (otherwise)\n     */\n    async withResponse() {\n        const [data, response] = await Promise.all([this.parse(), this.asResponse()]);\n        return { data, response, request_id: response.headers.get('x-request-id') };\n    }\n    parse() {\n        if (!this.parsedPromise) {\n            this.parsedPromise = this.responsePromise.then(this.parseResponse);\n        }\n        return this.parsedPromise;\n    }\n    then(onfulfilled, onrejected) {\n        return this.parse().then(onfulfilled, onrejected);\n    }\n    catch(onrejected) {\n        return this.parse().catch(onrejected);\n    }\n    finally(onfinally) {\n        return this.parse().finally(onfinally);\n    }\n}\nclass APIClient {\n    constructor({ baseURL, maxRetries = 2, timeout = 600000, // 10 minutes\n    httpAgent, fetch: overriddenFetch, }) {\n        this.baseURL = baseURL;\n        this.maxRetries = validatePositiveInteger('maxRetries', maxRetries);\n        this.timeout = validatePositiveInteger('timeout', timeout);\n        this.httpAgent = httpAgent;\n        this.fetch = overriddenFetch ?? _shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__.fetch;\n    }\n    authHeaders(opts) {\n        return {};\n    }\n    /**\n     * Override this to add your own default headers, for example:\n     *\n     *  {\n     *    ...super.defaultHeaders(),\n     *    Authorization: 'Bearer 123',\n     *  }\n     */\n    defaultHeaders(opts) {\n        return {\n            Accept: 'application/json',\n            'Content-Type': 'application/json',\n            'User-Agent': this.getUserAgent(),\n            ...getPlatformHeaders(),\n            ...this.authHeaders(opts),\n        };\n    }\n    /**\n     * Override this to add your own headers validation:\n     */\n    validateHeaders(headers, customHeaders) { }\n    defaultIdempotencyKey() {\n        return `stainless-node-retry-${uuid4()}`;\n    }\n    get(path, opts) {\n        return this.methodRequest('get', path, opts);\n    }\n    post(path, opts) {\n        return this.methodRequest('post', path, opts);\n    }\n    patch(path, opts) {\n        return this.methodRequest('patch', path, opts);\n    }\n    put(path, opts) {\n        return this.methodRequest('put', path, opts);\n    }\n    delete(path, opts) {\n        return this.methodRequest('delete', path, opts);\n    }\n    methodRequest(method, path, opts) {\n        return this.request(Promise.resolve(opts).then(async (opts) => {\n            const body = opts && (0,_uploads_mjs__WEBPACK_IMPORTED_MODULE_1__.isBlobLike)(opts?.body) ? new DataView(await opts.body.arrayBuffer())\n                : opts?.body instanceof DataView ? opts.body\n                    : opts?.body instanceof ArrayBuffer ? new DataView(opts.body)\n                        : opts && ArrayBuffer.isView(opts?.body) ? new DataView(opts.body.buffer)\n                            : opts?.body;\n            return { method, path, ...opts, body };\n        }));\n    }\n    getAPIList(path, Page, opts) {\n        return this.requestAPIList(Page, { method: 'get', path, ...opts });\n    }\n    calculateContentLength(body) {\n        if (typeof body === 'string') {\n            if (typeof Buffer !== 'undefined') {\n                return Buffer.byteLength(body, 'utf8').toString();\n            }\n            if (typeof TextEncoder !== 'undefined') {\n                const encoder = new TextEncoder();\n                const encoded = encoder.encode(body);\n                return encoded.length.toString();\n            }\n        }\n        else if (ArrayBuffer.isView(body)) {\n            return body.byteLength.toString();\n        }\n        return null;\n    }\n    buildRequest(options, { retryCount = 0 } = {}) {\n        options = { ...options };\n        const { method, path, query, headers: headers = {} } = options;\n        const body = ArrayBuffer.isView(options.body) || (options.__binaryRequest && typeof options.body === 'string') ?\n            options.body\n            : (0,_uploads_mjs__WEBPACK_IMPORTED_MODULE_1__.isMultipartBody)(options.body) ? options.body.body\n                : options.body ? JSON.stringify(options.body, null, 2)\n                    : null;\n        const contentLength = this.calculateContentLength(body);\n        const url = this.buildURL(path, query);\n        if ('timeout' in options)\n            validatePositiveInteger('timeout', options.timeout);\n        options.timeout = options.timeout ?? this.timeout;\n        const httpAgent = options.httpAgent ?? this.httpAgent ?? (0,_shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__.getDefaultAgent)(url);\n        const minAgentTimeout = options.timeout + 1000;\n        if (typeof httpAgent?.options?.timeout === 'number' &&\n            minAgentTimeout > (httpAgent.options.timeout ?? 0)) {\n            // Allow any given request to bump our agent active socket timeout.\n            // This may seem strange, but leaking active sockets should be rare and not particularly problematic,\n            // and without mutating agent we would need to create more of them.\n            // This tradeoff optimizes for performance.\n            httpAgent.options.timeout = minAgentTimeout;\n        }\n        if (this.idempotencyHeader && method !== 'get') {\n            if (!options.idempotencyKey)\n                options.idempotencyKey = this.defaultIdempotencyKey();\n            headers[this.idempotencyHeader] = options.idempotencyKey;\n        }\n        const reqHeaders = this.buildHeaders({ options, headers, contentLength, retryCount });\n        const req = {\n            method,\n            ...(body && { body: body }),\n            headers: reqHeaders,\n            ...(httpAgent && { agent: httpAgent }),\n            // @ts-ignore node-fetch uses a custom AbortSignal type that is\n            // not compatible with standard web types\n            signal: options.signal ?? null,\n        };\n        return { req, url, timeout: options.timeout };\n    }\n    buildHeaders({ options, headers, contentLength, retryCount, }) {\n        const reqHeaders = {};\n        if (contentLength) {\n            reqHeaders['content-length'] = contentLength;\n        }\n        const defaultHeaders = this.defaultHeaders(options);\n        applyHeadersMut(reqHeaders, defaultHeaders);\n        applyHeadersMut(reqHeaders, headers);\n        // let builtin fetch set the Content-Type for multipart bodies\n        if ((0,_uploads_mjs__WEBPACK_IMPORTED_MODULE_1__.isMultipartBody)(options.body) && _shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__.kind !== 'node') {\n            delete reqHeaders['content-type'];\n        }\n        // Don't set theses headers if they were already set or removed through default headers or by the caller.\n        // We check `defaultHeaders` and `headers`, which can contain nulls, instead of `reqHeaders` to account\n        // for the removal case.\n        if (getHeader(defaultHeaders, 'x-stainless-retry-count') === undefined &&\n            getHeader(headers, 'x-stainless-retry-count') === undefined) {\n            reqHeaders['x-stainless-retry-count'] = String(retryCount);\n        }\n        if (getHeader(defaultHeaders, 'x-stainless-timeout') === undefined &&\n            getHeader(headers, 'x-stainless-timeout') === undefined &&\n            options.timeout) {\n            reqHeaders['x-stainless-timeout'] = String(options.timeout);\n        }\n        this.validateHeaders(reqHeaders, headers);\n        return reqHeaders;\n    }\n    /**\n     * Used as a callback for mutating the given `FinalRequestOptions` object.\n     */\n    async prepareOptions(options) { }\n    /**\n     * Used as a callback for mutating the given `RequestInit` object.\n     *\n     * This is useful for cases where you want to add certain headers based off of\n     * the request properties, e.g. `method` or `url`.\n     */\n    async prepareRequest(request, { url, options }) { }\n    parseHeaders(headers) {\n        return (!headers ? {}\n            : Symbol.iterator in headers ?\n                Object.fromEntries(Array.from(headers).map((header) => [...header]))\n                : { ...headers });\n    }\n    makeStatusError(status, error, message, headers) {\n        return _error_mjs__WEBPACK_IMPORTED_MODULE_3__.APIError.generate(status, error, message, headers);\n    }\n    request(options, remainingRetries = null) {\n        return new APIPromise(this.makeRequest(options, remainingRetries));\n    }\n    async makeRequest(optionsInput, retriesRemaining) {\n        const options = await optionsInput;\n        const maxRetries = options.maxRetries ?? this.maxRetries;\n        if (retriesRemaining == null) {\n            retriesRemaining = maxRetries;\n        }\n        await this.prepareOptions(options);\n        const { req, url, timeout } = this.buildRequest(options, { retryCount: maxRetries - retriesRemaining });\n        await this.prepareRequest(req, { url, options });\n        debug('request', url, options, req.headers);\n        if (options.signal?.aborted) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_3__.APIUserAbortError();\n        }\n        const controller = new AbortController();\n        const response = await this.fetchWithTimeout(url, req, timeout, controller).catch(castToError);\n        if (response instanceof Error) {\n            if (options.signal?.aborted) {\n                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_3__.APIUserAbortError();\n            }\n            if (retriesRemaining) {\n                return this.retryRequest(options, retriesRemaining);\n            }\n            if (response.name === 'AbortError') {\n                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_3__.APIConnectionTimeoutError();\n            }\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_3__.APIConnectionError({ cause: response });\n        }\n        const responseHeaders = createResponseHeaders(response.headers);\n        if (!response.ok) {\n            if (retriesRemaining && this.shouldRetry(response)) {\n                const retryMessage = `retrying, ${retriesRemaining} attempts remaining`;\n                debug(`response (error; ${retryMessage})`, response.status, url, responseHeaders);\n                return this.retryRequest(options, retriesRemaining, responseHeaders);\n            }\n            const errText = await response.text().catch((e) => castToError(e).message);\n            const errJSON = safeJSON(errText);\n            const errMessage = errJSON ? undefined : errText;\n            const retryMessage = retriesRemaining ? `(error; no more retries left)` : `(error; not retryable)`;\n            debug(`response (error; ${retryMessage})`, response.status, url, responseHeaders, errMessage);\n            const err = this.makeStatusError(response.status, errJSON, errMessage, responseHeaders);\n            throw err;\n        }\n        return { response, options, controller };\n    }\n    requestAPIList(Page, options) {\n        const request = this.makeRequest(options, null);\n        return new PagePromise(this, request, Page);\n    }\n    buildURL(path, query) {\n        const url = isAbsoluteURL(path) ?\n            new URL(path)\n            : new URL(this.baseURL + (this.baseURL.endsWith('/') && path.startsWith('/') ? path.slice(1) : path));\n        const defaultQuery = this.defaultQuery();\n        if (!isEmptyObj(defaultQuery)) {\n            query = { ...defaultQuery, ...query };\n        }\n        if (typeof query === 'object' && query && !Array.isArray(query)) {\n            url.search = this.stringifyQuery(query);\n        }\n        return url.toString();\n    }\n    stringifyQuery(query) {\n        return Object.entries(query)\n            .filter(([_, value]) => typeof value !== 'undefined')\n            .map(([key, value]) => {\n            if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n                return `${encodeURIComponent(key)}=${encodeURIComponent(value)}`;\n            }\n            if (value === null) {\n                return `${encodeURIComponent(key)}=`;\n            }\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_3__.OpenAIError(`Cannot stringify type ${typeof value}; Expected string, number, boolean, or null. If you need to pass nested query parameters, you can manually encode them, e.g. { query: { 'foo[key1]': value1, 'foo[key2]': value2 } }, and please open a GitHub issue requesting better support for your use case.`);\n        })\n            .join('&');\n    }\n    async fetchWithTimeout(url, init, ms, controller) {\n        const { signal, ...options } = init || {};\n        if (signal)\n            signal.addEventListener('abort', () => controller.abort());\n        const timeout = setTimeout(() => controller.abort(), ms);\n        const fetchOptions = {\n            signal: controller.signal,\n            ...options,\n        };\n        if (fetchOptions.method) {\n            // Custom methods like 'patch' need to be uppercased\n            // See https://github.com/nodejs/undici/issues/2294\n            fetchOptions.method = fetchOptions.method.toUpperCase();\n        }\n        return (\n        // use undefined this binding; fetch errors if bound to something else in browser/cloudflare\n        this.fetch.call(undefined, url, fetchOptions).finally(() => {\n            clearTimeout(timeout);\n        }));\n    }\n    shouldRetry(response) {\n        // Note this is not a standard header.\n        const shouldRetryHeader = response.headers.get('x-should-retry');\n        // If the server explicitly says whether or not to retry, obey.\n        if (shouldRetryHeader === 'true')\n            return true;\n        if (shouldRetryHeader === 'false')\n            return false;\n        // Retry on request timeouts.\n        if (response.status === 408)\n            return true;\n        // Retry on lock timeouts.\n        if (response.status === 409)\n            return true;\n        // Retry on rate limits.\n        if (response.status === 429)\n            return true;\n        // Retry internal errors.\n        if (response.status >= 500)\n            return true;\n        return false;\n    }\n    async retryRequest(options, retriesRemaining, responseHeaders) {\n        let timeoutMillis;\n        // Note the `retry-after-ms` header may not be standard, but is a good idea and we'd like proactive support for it.\n        const retryAfterMillisHeader = responseHeaders?.['retry-after-ms'];\n        if (retryAfterMillisHeader) {\n            const timeoutMs = parseFloat(retryAfterMillisHeader);\n            if (!Number.isNaN(timeoutMs)) {\n                timeoutMillis = timeoutMs;\n            }\n        }\n        // About the Retry-After header: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After\n        const retryAfterHeader = responseHeaders?.['retry-after'];\n        if (retryAfterHeader && !timeoutMillis) {\n            const timeoutSeconds = parseFloat(retryAfterHeader);\n            if (!Number.isNaN(timeoutSeconds)) {\n                timeoutMillis = timeoutSeconds * 1000;\n            }\n            else {\n                timeoutMillis = Date.parse(retryAfterHeader) - Date.now();\n            }\n        }\n        // If the API asks us to wait a certain amount of time (and it's a reasonable amount),\n        // just do what it says, but otherwise calculate a default\n        if (!(timeoutMillis && 0 <= timeoutMillis && timeoutMillis < 60 * 1000)) {\n            const maxRetries = options.maxRetries ?? this.maxRetries;\n            timeoutMillis = this.calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries);\n        }\n        await sleep(timeoutMillis);\n        return this.makeRequest(options, retriesRemaining - 1);\n    }\n    calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries) {\n        const initialRetryDelay = 0.5;\n        const maxRetryDelay = 8.0;\n        const numRetries = maxRetries - retriesRemaining;\n        // Apply exponential backoff, but not more than the max.\n        const sleepSeconds = Math.min(initialRetryDelay * Math.pow(2, numRetries), maxRetryDelay);\n        // Apply some jitter, take up to at most 25 percent of the retry time.\n        const jitter = 1 - Math.random() * 0.25;\n        return sleepSeconds * jitter * 1000;\n    }\n    getUserAgent() {\n        return `${this.constructor.name}/JS ${_version_mjs__WEBPACK_IMPORTED_MODULE_4__.VERSION}`;\n    }\n}\nclass AbstractPage {\n    constructor(client, response, body, options) {\n        _AbstractPage_client.set(this, void 0);\n        __classPrivateFieldSet(this, _AbstractPage_client, client, \"f\");\n        this.options = options;\n        this.response = response;\n        this.body = body;\n    }\n    hasNextPage() {\n        const items = this.getPaginatedItems();\n        if (!items.length)\n            return false;\n        return this.nextPageInfo() != null;\n    }\n    async getNextPage() {\n        const nextInfo = this.nextPageInfo();\n        if (!nextInfo) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_3__.OpenAIError('No next page expected; please check `.hasNextPage()` before calling `.getNextPage()`.');\n        }\n        const nextOptions = { ...this.options };\n        if ('params' in nextInfo && typeof nextOptions.query === 'object') {\n            nextOptions.query = { ...nextOptions.query, ...nextInfo.params };\n        }\n        else if ('url' in nextInfo) {\n            const params = [...Object.entries(nextOptions.query || {}), ...nextInfo.url.searchParams.entries()];\n            for (const [key, value] of params) {\n                nextInfo.url.searchParams.set(key, value);\n            }\n            nextOptions.query = undefined;\n            nextOptions.path = nextInfo.url.toString();\n        }\n        return await __classPrivateFieldGet(this, _AbstractPage_client, \"f\").requestAPIList(this.constructor, nextOptions);\n    }\n    async *iterPages() {\n        // eslint-disable-next-line @typescript-eslint/no-this-alias\n        let page = this;\n        yield page;\n        while (page.hasNextPage()) {\n            page = await page.getNextPage();\n            yield page;\n        }\n    }\n    async *[(_AbstractPage_client = new WeakMap(), Symbol.asyncIterator)]() {\n        for await (const page of this.iterPages()) {\n            for (const item of page.getPaginatedItems()) {\n                yield item;\n            }\n        }\n    }\n}\n/**\n * This subclass of Promise will resolve to an instantiated Page once the request completes.\n *\n * It also implements AsyncIterable to allow auto-paginating iteration on an unawaited list call, eg:\n *\n *    for await (const item of client.items.list()) {\n *      console.log(item)\n *    }\n */\nclass PagePromise extends APIPromise {\n    constructor(client, request, Page) {\n        super(request, async (props) => new Page(client, props.response, await defaultParseResponse(props), props.options));\n    }\n    /**\n     * Allow auto-paginating iteration on an unawaited list call, eg:\n     *\n     *    for await (const item of client.items.list()) {\n     *      console.log(item)\n     *    }\n     */\n    async *[Symbol.asyncIterator]() {\n        const page = await this;\n        for await (const item of page) {\n            yield item;\n        }\n    }\n}\nconst createResponseHeaders = (headers) => {\n    return new Proxy(Object.fromEntries(\n    // @ts-ignore\n    headers.entries()), {\n        get(target, name) {\n            const key = name.toString();\n            return target[key.toLowerCase()] || target[key];\n        },\n    });\n};\n// This is required so that we can determine if a given object matches the RequestOptions\n// type at runtime. While this requires duplication, it is enforced by the TypeScript\n// compiler such that any missing / extraneous keys will cause an error.\nconst requestOptionsKeys = {\n    method: true,\n    path: true,\n    query: true,\n    body: true,\n    headers: true,\n    maxRetries: true,\n    stream: true,\n    timeout: true,\n    httpAgent: true,\n    signal: true,\n    idempotencyKey: true,\n    __metadata: true,\n    __binaryRequest: true,\n    __binaryResponse: true,\n    __streamClass: true,\n};\nconst isRequestOptions = (obj) => {\n    return (typeof obj === 'object' &&\n        obj !== null &&\n        !isEmptyObj(obj) &&\n        Object.keys(obj).every((k) => hasOwn(requestOptionsKeys, k)));\n};\nconst getPlatformProperties = () => {\n    if (typeof Deno !== 'undefined' && Deno.build != null) {\n        return {\n            'X-Stainless-Lang': 'js',\n            'X-Stainless-Package-Version': _version_mjs__WEBPACK_IMPORTED_MODULE_4__.VERSION,\n            'X-Stainless-OS': normalizePlatform(Deno.build.os),\n            'X-Stainless-Arch': normalizeArch(Deno.build.arch),\n            'X-Stainless-Runtime': 'deno',\n            'X-Stainless-Runtime-Version': typeof Deno.version === 'string' ? Deno.version : Deno.version?.deno ?? 'unknown',\n        };\n    }\n    if (typeof EdgeRuntime !== 'undefined') {\n        return {\n            'X-Stainless-Lang': 'js',\n            'X-Stainless-Package-Version': _version_mjs__WEBPACK_IMPORTED_MODULE_4__.VERSION,\n            'X-Stainless-OS': 'Unknown',\n            'X-Stainless-Arch': `other:${EdgeRuntime}`,\n            'X-Stainless-Runtime': 'edge',\n            'X-Stainless-Runtime-Version': process.version,\n        };\n    }\n    // Check if Node.js\n    if (Object.prototype.toString.call(typeof process !== 'undefined' ? process : 0) === '[object process]') {\n        return {\n            'X-Stainless-Lang': 'js',\n            'X-Stainless-Package-Version': _version_mjs__WEBPACK_IMPORTED_MODULE_4__.VERSION,\n            'X-Stainless-OS': normalizePlatform(process.platform),\n            'X-Stainless-Arch': normalizeArch(process.arch),\n            'X-Stainless-Runtime': 'node',\n            'X-Stainless-Runtime-Version': process.version,\n        };\n    }\n    const browserInfo = getBrowserInfo();\n    if (browserInfo) {\n        return {\n            'X-Stainless-Lang': 'js',\n            'X-Stainless-Package-Version': _version_mjs__WEBPACK_IMPORTED_MODULE_4__.VERSION,\n            'X-Stainless-OS': 'Unknown',\n            'X-Stainless-Arch': 'unknown',\n            'X-Stainless-Runtime': `browser:${browserInfo.browser}`,\n            'X-Stainless-Runtime-Version': browserInfo.version,\n        };\n    }\n    // TODO add support for Cloudflare workers, etc.\n    return {\n        'X-Stainless-Lang': 'js',\n        'X-Stainless-Package-Version': _version_mjs__WEBPACK_IMPORTED_MODULE_4__.VERSION,\n        'X-Stainless-OS': 'Unknown',\n        'X-Stainless-Arch': 'unknown',\n        'X-Stainless-Runtime': 'unknown',\n        'X-Stainless-Runtime-Version': 'unknown',\n    };\n};\n// Note: modified from https://github.com/JS-DevTools/host-environment/blob/b1ab79ecde37db5d6e163c050e54fe7d287d7c92/src/isomorphic.browser.ts\nfunction getBrowserInfo() {\n    if (typeof navigator === 'undefined' || !navigator) {\n        return null;\n    }\n    // NOTE: The order matters here!\n    const browserPatterns = [\n        { key: 'edge', pattern: /Edge(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n        { key: 'ie', pattern: /MSIE(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n        { key: 'ie', pattern: /Trident(?:.*rv\\:(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n        { key: 'chrome', pattern: /Chrome(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n        { key: 'firefox', pattern: /Firefox(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n        { key: 'safari', pattern: /(?:Version\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?(?:\\W+Mobile\\S*)?\\W+Safari/ },\n    ];\n    // Find the FIRST matching browser\n    for (const { key, pattern } of browserPatterns) {\n        const match = pattern.exec(navigator.userAgent);\n        if (match) {\n            const major = match[1] || 0;\n            const minor = match[2] || 0;\n            const patch = match[3] || 0;\n            return { browser: key, version: `${major}.${minor}.${patch}` };\n        }\n    }\n    return null;\n}\nconst normalizeArch = (arch) => {\n    // Node docs:\n    // - https://nodejs.org/api/process.html#processarch\n    // Deno docs:\n    // - https://doc.deno.land/deno/stable/~/Deno.build\n    if (arch === 'x32')\n        return 'x32';\n    if (arch === 'x86_64' || arch === 'x64')\n        return 'x64';\n    if (arch === 'arm')\n        return 'arm';\n    if (arch === 'aarch64' || arch === 'arm64')\n        return 'arm64';\n    if (arch)\n        return `other:${arch}`;\n    return 'unknown';\n};\nconst normalizePlatform = (platform) => {\n    // Node platforms:\n    // - https://nodejs.org/api/process.html#processplatform\n    // Deno platforms:\n    // - https://doc.deno.land/deno/stable/~/Deno.build\n    // - https://github.com/denoland/deno/issues/14799\n    platform = platform.toLowerCase();\n    // NOTE: this iOS check is untested and may not work\n    // Node does not work natively on IOS, there is a fork at\n    // https://github.com/nodejs-mobile/nodejs-mobile\n    // however it is unknown at the time of writing how to detect if it is running\n    if (platform.includes('ios'))\n        return 'iOS';\n    if (platform === 'android')\n        return 'Android';\n    if (platform === 'darwin')\n        return 'MacOS';\n    if (platform === 'win32')\n        return 'Windows';\n    if (platform === 'freebsd')\n        return 'FreeBSD';\n    if (platform === 'openbsd')\n        return 'OpenBSD';\n    if (platform === 'linux')\n        return 'Linux';\n    if (platform)\n        return `Other:${platform}`;\n    return 'Unknown';\n};\nlet _platformHeaders;\nconst getPlatformHeaders = () => {\n    return (_platformHeaders ?? (_platformHeaders = getPlatformProperties()));\n};\nconst safeJSON = (text) => {\n    try {\n        return JSON.parse(text);\n    }\n    catch (err) {\n        return undefined;\n    }\n};\n// https://url.spec.whatwg.org/#url-scheme-string\nconst startsWithSchemeRegexp = /^[a-z][a-z0-9+.-]*:/i;\nconst isAbsoluteURL = (url) => {\n    return startsWithSchemeRegexp.test(url);\n};\nconst sleep = (ms) => new Promise((resolve) => setTimeout(resolve, ms));\nconst validatePositiveInteger = (name, n) => {\n    if (typeof n !== 'number' || !Number.isInteger(n)) {\n        throw new _error_mjs__WEBPACK_IMPORTED_MODULE_3__.OpenAIError(`${name} must be an integer`);\n    }\n    if (n < 0) {\n        throw new _error_mjs__WEBPACK_IMPORTED_MODULE_3__.OpenAIError(`${name} must be a positive integer`);\n    }\n    return n;\n};\nconst castToError = (err) => {\n    if (err instanceof Error)\n        return err;\n    if (typeof err === 'object' && err !== null) {\n        try {\n            return new Error(JSON.stringify(err));\n        }\n        catch { }\n    }\n    return new Error(err);\n};\nconst ensurePresent = (value) => {\n    if (value == null)\n        throw new _error_mjs__WEBPACK_IMPORTED_MODULE_3__.OpenAIError(`Expected a value to be given but received ${value} instead.`);\n    return value;\n};\n/**\n * Read an environment variable.\n *\n * Trims beginning and trailing whitespace.\n *\n * Will return undefined if the environment variable doesn't exist or cannot be accessed.\n */\nconst readEnv = (env) => {\n    if (typeof process !== 'undefined') {\n        return process.env?.[env]?.trim() ?? undefined;\n    }\n    if (typeof Deno !== 'undefined') {\n        return Deno.env?.get?.(env)?.trim();\n    }\n    return undefined;\n};\nconst coerceInteger = (value) => {\n    if (typeof value === 'number')\n        return Math.round(value);\n    if (typeof value === 'string')\n        return parseInt(value, 10);\n    throw new _error_mjs__WEBPACK_IMPORTED_MODULE_3__.OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\nconst coerceFloat = (value) => {\n    if (typeof value === 'number')\n        return value;\n    if (typeof value === 'string')\n        return parseFloat(value);\n    throw new _error_mjs__WEBPACK_IMPORTED_MODULE_3__.OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\nconst coerceBoolean = (value) => {\n    if (typeof value === 'boolean')\n        return value;\n    if (typeof value === 'string')\n        return value === 'true';\n    return Boolean(value);\n};\nconst maybeCoerceInteger = (value) => {\n    if (value === undefined) {\n        return undefined;\n    }\n    return coerceInteger(value);\n};\nconst maybeCoerceFloat = (value) => {\n    if (value === undefined) {\n        return undefined;\n    }\n    return coerceFloat(value);\n};\nconst maybeCoerceBoolean = (value) => {\n    if (value === undefined) {\n        return undefined;\n    }\n    return coerceBoolean(value);\n};\n// https://stackoverflow.com/a/34491287\nfunction isEmptyObj(obj) {\n    if (!obj)\n        return true;\n    for (const _k in obj)\n        return false;\n    return true;\n}\n// https://eslint.org/docs/latest/rules/no-prototype-builtins\nfunction hasOwn(obj, key) {\n    return Object.prototype.hasOwnProperty.call(obj, key);\n}\n/**\n * Copies headers from \"newHeaders\" onto \"targetHeaders\",\n * using lower-case for all properties,\n * ignoring any keys with undefined values,\n * and deleting any keys with null values.\n */\nfunction applyHeadersMut(targetHeaders, newHeaders) {\n    for (const k in newHeaders) {\n        if (!hasOwn(newHeaders, k))\n            continue;\n        const lowerKey = k.toLowerCase();\n        if (!lowerKey)\n            continue;\n        const val = newHeaders[k];\n        if (val === null) {\n            delete targetHeaders[lowerKey];\n        }\n        else if (val !== undefined) {\n            targetHeaders[lowerKey] = val;\n        }\n    }\n}\nconst SENSITIVE_HEADERS = new Set(['authorization', 'api-key']);\nfunction debug(action, ...args) {\n    if (typeof process !== 'undefined' && process?.env?.['DEBUG'] === 'true') {\n        const modifiedArgs = args.map((arg) => {\n            if (!arg) {\n                return arg;\n            }\n            // Check for sensitive headers in request body 'headers' object\n            if (arg['headers']) {\n                // clone so we don't mutate\n                const modifiedArg = { ...arg, headers: { ...arg['headers'] } };\n                for (const header in arg['headers']) {\n                    if (SENSITIVE_HEADERS.has(header.toLowerCase())) {\n                        modifiedArg['headers'][header] = 'REDACTED';\n                    }\n                }\n                return modifiedArg;\n            }\n            let modifiedArg = null;\n            // Check for sensitive headers in headers object\n            for (const header in arg) {\n                if (SENSITIVE_HEADERS.has(header.toLowerCase())) {\n                    // avoid making a copy until we need to\n                    modifiedArg ?? (modifiedArg = { ...arg });\n                    modifiedArg[header] = 'REDACTED';\n                }\n            }\n            return modifiedArg ?? arg;\n        });\n        console.log(`OpenAI:DEBUG:${action}`, ...modifiedArgs);\n    }\n}\n/**\n * https://stackoverflow.com/a/2117523\n */\nconst uuid4 = () => {\n    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {\n        const r = (Math.random() * 16) | 0;\n        const v = c === 'x' ? r : (r & 0x3) | 0x8;\n        return v.toString(16);\n    });\n};\nconst isRunningInBrowser = () => {\n    return (\n    // @ts-ignore\n    typeof window !== 'undefined' &&\n        // @ts-ignore\n        typeof window.document !== 'undefined' &&\n        // @ts-ignore\n        typeof navigator !== 'undefined');\n};\nconst isHeadersProtocol = (headers) => {\n    return typeof headers?.get === 'function';\n};\nconst getRequiredHeader = (headers, header) => {\n    const foundHeader = getHeader(headers, header);\n    if (foundHeader === undefined) {\n        throw new Error(`Could not find ${header} header`);\n    }\n    return foundHeader;\n};\nconst getHeader = (headers, header) => {\n    const lowerCasedHeader = header.toLowerCase();\n    if (isHeadersProtocol(headers)) {\n        // to deal with the case where the header looks like Stainless-Event-Id\n        const intercapsHeader = header[0]?.toUpperCase() +\n            header.substring(1).replace(/([^\\w])(\\w)/g, (_m, g1, g2) => g1 + g2.toUpperCase());\n        for (const key of [header, lowerCasedHeader, header.toUpperCase(), intercapsHeader]) {\n            const value = headers.get(key);\n            if (value) {\n                return value;\n            }\n        }\n    }\n    for (const [key, value] of Object.entries(headers)) {\n        if (key.toLowerCase() === lowerCasedHeader) {\n            if (Array.isArray(value)) {\n                if (value.length <= 1)\n                    return value[0];\n                console.warn(`Received ${value.length} entries for the ${header} header, using the first entry.`);\n                return value[0];\n            }\n            return value;\n        }\n    }\n    return undefined;\n};\n/**\n * Encodes a string to Base64 format.\n */\nconst toBase64 = (str) => {\n    if (!str)\n        return '';\n    if (typeof Buffer !== 'undefined') {\n        return Buffer.from(str).toString('base64');\n    }\n    if (typeof btoa !== 'undefined') {\n        return btoa(str);\n    }\n    throw new _error_mjs__WEBPACK_IMPORTED_MODULE_3__.OpenAIError('Cannot generate b64 string; Expected `Buffer` or `btoa` to be defined');\n};\nfunction isObj(obj) {\n    return obj != null && typeof obj === 'object' && !Array.isArray(obj);\n}\n//# sourceMappingURL=core.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/core.mjs?");

/***/ }),

/***/ "./node_modules/openai/error.mjs":
/*!***************************************!*\
  !*** ./node_modules/openai/error.mjs ***!
  \***************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   APIConnectionError: () => (/* binding */ APIConnectionError),\n/* harmony export */   APIConnectionTimeoutError: () => (/* binding */ APIConnectionTimeoutError),\n/* harmony export */   APIError: () => (/* binding */ APIError),\n/* harmony export */   APIUserAbortError: () => (/* binding */ APIUserAbortError),\n/* harmony export */   AuthenticationError: () => (/* binding */ AuthenticationError),\n/* harmony export */   BadRequestError: () => (/* binding */ BadRequestError),\n/* harmony export */   ConflictError: () => (/* binding */ ConflictError),\n/* harmony export */   ContentFilterFinishReasonError: () => (/* binding */ ContentFilterFinishReasonError),\n/* harmony export */   InternalServerError: () => (/* binding */ InternalServerError),\n/* harmony export */   LengthFinishReasonError: () => (/* binding */ LengthFinishReasonError),\n/* harmony export */   NotFoundError: () => (/* binding */ NotFoundError),\n/* harmony export */   OpenAIError: () => (/* binding */ OpenAIError),\n/* harmony export */   PermissionDeniedError: () => (/* binding */ PermissionDeniedError),\n/* harmony export */   RateLimitError: () => (/* binding */ RateLimitError),\n/* harmony export */   UnprocessableEntityError: () => (/* binding */ UnprocessableEntityError)\n/* harmony export */ });\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./core.mjs */ \"./node_modules/openai/core.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nclass OpenAIError extends Error {\n}\nclass APIError extends OpenAIError {\n    constructor(status, error, message, headers) {\n        super(`${APIError.makeMessage(status, error, message)}`);\n        this.status = status;\n        this.headers = headers;\n        this.request_id = headers?.['x-request-id'];\n        this.error = error;\n        const data = error;\n        this.code = data?.['code'];\n        this.param = data?.['param'];\n        this.type = data?.['type'];\n    }\n    static makeMessage(status, error, message) {\n        const msg = error?.message ?\n            typeof error.message === 'string' ?\n                error.message\n                : JSON.stringify(error.message)\n            : error ? JSON.stringify(error)\n                : message;\n        if (status && msg) {\n            return `${status} ${msg}`;\n        }\n        if (status) {\n            return `${status} status code (no body)`;\n        }\n        if (msg) {\n            return msg;\n        }\n        return '(no status code or body)';\n    }\n    static generate(status, errorResponse, message, headers) {\n        if (!status || !headers) {\n            return new APIConnectionError({ message, cause: (0,_core_mjs__WEBPACK_IMPORTED_MODULE_0__.castToError)(errorResponse) });\n        }\n        const error = errorResponse?.['error'];\n        if (status === 400) {\n            return new BadRequestError(status, error, message, headers);\n        }\n        if (status === 401) {\n            return new AuthenticationError(status, error, message, headers);\n        }\n        if (status === 403) {\n            return new PermissionDeniedError(status, error, message, headers);\n        }\n        if (status === 404) {\n            return new NotFoundError(status, error, message, headers);\n        }\n        if (status === 409) {\n            return new ConflictError(status, error, message, headers);\n        }\n        if (status === 422) {\n            return new UnprocessableEntityError(status, error, message, headers);\n        }\n        if (status === 429) {\n            return new RateLimitError(status, error, message, headers);\n        }\n        if (status >= 500) {\n            return new InternalServerError(status, error, message, headers);\n        }\n        return new APIError(status, error, message, headers);\n    }\n}\nclass APIUserAbortError extends APIError {\n    constructor({ message } = {}) {\n        super(undefined, undefined, message || 'Request was aborted.', undefined);\n    }\n}\nclass APIConnectionError extends APIError {\n    constructor({ message, cause }) {\n        super(undefined, undefined, message || 'Connection error.', undefined);\n        // in some environments the 'cause' property is already declared\n        // @ts-ignore\n        if (cause)\n            this.cause = cause;\n    }\n}\nclass APIConnectionTimeoutError extends APIConnectionError {\n    constructor({ message } = {}) {\n        super({ message: message ?? 'Request timed out.' });\n    }\n}\nclass BadRequestError extends APIError {\n}\nclass AuthenticationError extends APIError {\n}\nclass PermissionDeniedError extends APIError {\n}\nclass NotFoundError extends APIError {\n}\nclass ConflictError extends APIError {\n}\nclass UnprocessableEntityError extends APIError {\n}\nclass RateLimitError extends APIError {\n}\nclass InternalServerError extends APIError {\n}\nclass LengthFinishReasonError extends OpenAIError {\n    constructor() {\n        super(`Could not parse response content as the length limit was reached`);\n    }\n}\nclass ContentFilterFinishReasonError extends OpenAIError {\n    constructor() {\n        super(`Could not parse response content as the request was rejected by the content filter`);\n    }\n}\n//# sourceMappingURL=error.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/error.mjs?");

/***/ }),

/***/ "./node_modules/openai/index.mjs":
/*!***************************************!*\
  !*** ./node_modules/openai/index.mjs ***!
  \***************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   APIConnectionError: () => (/* reexport safe */ _error_mjs__WEBPACK_IMPORTED_MODULE_1__.APIConnectionError),\n/* harmony export */   APIConnectionTimeoutError: () => (/* reexport safe */ _error_mjs__WEBPACK_IMPORTED_MODULE_1__.APIConnectionTimeoutError),\n/* harmony export */   APIError: () => (/* reexport safe */ _error_mjs__WEBPACK_IMPORTED_MODULE_1__.APIError),\n/* harmony export */   APIUserAbortError: () => (/* reexport safe */ _error_mjs__WEBPACK_IMPORTED_MODULE_1__.APIUserAbortError),\n/* harmony export */   AuthenticationError: () => (/* reexport safe */ _error_mjs__WEBPACK_IMPORTED_MODULE_1__.AuthenticationError),\n/* harmony export */   AzureOpenAI: () => (/* binding */ AzureOpenAI),\n/* harmony export */   BadRequestError: () => (/* reexport safe */ _error_mjs__WEBPACK_IMPORTED_MODULE_1__.BadRequestError),\n/* harmony export */   ConflictError: () => (/* reexport safe */ _error_mjs__WEBPACK_IMPORTED_MODULE_1__.ConflictError),\n/* harmony export */   InternalServerError: () => (/* reexport safe */ _error_mjs__WEBPACK_IMPORTED_MODULE_1__.InternalServerError),\n/* harmony export */   NotFoundError: () => (/* reexport safe */ _error_mjs__WEBPACK_IMPORTED_MODULE_1__.NotFoundError),\n/* harmony export */   OpenAI: () => (/* binding */ OpenAI),\n/* harmony export */   OpenAIError: () => (/* reexport safe */ _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError),\n/* harmony export */   PermissionDeniedError: () => (/* reexport safe */ _error_mjs__WEBPACK_IMPORTED_MODULE_1__.PermissionDeniedError),\n/* harmony export */   RateLimitError: () => (/* reexport safe */ _error_mjs__WEBPACK_IMPORTED_MODULE_1__.RateLimitError),\n/* harmony export */   UnprocessableEntityError: () => (/* reexport safe */ _error_mjs__WEBPACK_IMPORTED_MODULE_1__.UnprocessableEntityError),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   fileFromPath: () => (/* reexport safe */ _uploads_mjs__WEBPACK_IMPORTED_MODULE_16__.fileFromPath),\n/* harmony export */   toFile: () => (/* reexport safe */ _uploads_mjs__WEBPACK_IMPORTED_MODULE_15__.toFile)\n/* harmony export */ });\n/* harmony import */ var _internal_qs_index_mjs__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./internal/qs/index.mjs */ \"./node_modules/openai/internal/qs/stringify.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _error_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./error.mjs */ \"./node_modules/openai/error.mjs\");\n/* harmony import */ var _uploads_mjs__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./uploads.mjs */ \"./node_modules/openai/uploads.mjs\");\n/* harmony import */ var _uploads_mjs__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./uploads.mjs */ \"./node_modules/openai/_shims/index.mjs\");\n/* harmony import */ var _resources_index_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./resources/completions.mjs */ \"./node_modules/openai/resources/completions.mjs\");\n/* harmony import */ var _resources_index_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./resources/chat/chat.mjs */ \"./node_modules/openai/resources/chat/chat.mjs\");\n/* harmony import */ var _resources_index_mjs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./resources/embeddings.mjs */ \"./node_modules/openai/resources/embeddings.mjs\");\n/* harmony import */ var _resources_index_mjs__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./resources/files.mjs */ \"./node_modules/openai/resources/files.mjs\");\n/* harmony import */ var _resources_index_mjs__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./resources/images.mjs */ \"./node_modules/openai/resources/images.mjs\");\n/* harmony import */ var _resources_index_mjs__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./resources/audio/audio.mjs */ \"./node_modules/openai/resources/audio/audio.mjs\");\n/* harmony import */ var _resources_index_mjs__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./resources/moderations.mjs */ \"./node_modules/openai/resources/moderations.mjs\");\n/* harmony import */ var _resources_index_mjs__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./resources/models.mjs */ \"./node_modules/openai/resources/models.mjs\");\n/* harmony import */ var _resources_index_mjs__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./resources/fine-tuning/fine-tuning.mjs */ \"./node_modules/openai/resources/fine-tuning/fine-tuning.mjs\");\n/* harmony import */ var _resources_index_mjs__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./resources/beta/beta.mjs */ \"./node_modules/openai/resources/beta/beta.mjs\");\n/* harmony import */ var _resources_index_mjs__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./resources/batches.mjs */ \"./node_modules/openai/resources/batches.mjs\");\n/* harmony import */ var _resources_index_mjs__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./resources/uploads/uploads.mjs */ \"./node_modules/openai/resources/uploads/uploads.mjs\");\n/* harmony import */ var _resources_chat_completions_completions_mjs__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./resources/chat/completions/completions.mjs */ \"./node_modules/openai/resources/chat/completions/completions.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nvar _a;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/**\n * API Client for interfacing with the OpenAI API.\n */\nclass OpenAI extends _core_mjs__WEBPACK_IMPORTED_MODULE_0__.APIClient {\n    /**\n     * API Client for interfacing with the OpenAI API.\n     *\n     * @param {string | undefined} [opts.apiKey=process.env['OPENAI_API_KEY'] ?? undefined]\n     * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n     * @param {string | null | undefined} [opts.project=process.env['OPENAI_PROJECT_ID'] ?? null]\n     * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL'] ?? https://api.openai.com/v1] - Override the default base URL for the API.\n     * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n     * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.\n     * @param {Core.Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n     * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n     * @param {Core.Headers} opts.defaultHeaders - Default headers to include with every request to the API.\n     * @param {Core.DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.\n     * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n     */\n    constructor({ baseURL = _core_mjs__WEBPACK_IMPORTED_MODULE_0__.readEnv('OPENAI_BASE_URL'), apiKey = _core_mjs__WEBPACK_IMPORTED_MODULE_0__.readEnv('OPENAI_API_KEY'), organization = _core_mjs__WEBPACK_IMPORTED_MODULE_0__.readEnv('OPENAI_ORG_ID') ?? null, project = _core_mjs__WEBPACK_IMPORTED_MODULE_0__.readEnv('OPENAI_PROJECT_ID') ?? null, ...opts } = {}) {\n        if (apiKey === undefined) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(\"The OPENAI_API_KEY environment variable is missing or empty; either provide it, or instantiate the OpenAI client with an apiKey option, like new OpenAI({ apiKey: 'My API Key' }).\");\n        }\n        const options = {\n            apiKey,\n            organization,\n            project,\n            ...opts,\n            baseURL: baseURL || `https://api.openai.com/v1`,\n        };\n        if (!options.dangerouslyAllowBrowser && _core_mjs__WEBPACK_IMPORTED_MODULE_0__.isRunningInBrowser()) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(\"It looks like you're running in a browser-like environment.\\n\\nThis is disabled by default, as it risks exposing your secret API credentials to attackers.\\nIf you understand the risks and have appropriate mitigations in place,\\nyou can set the `dangerouslyAllowBrowser` option to `true`, e.g.,\\n\\nnew OpenAI({ apiKey, dangerouslyAllowBrowser: true });\\n\\nhttps://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\\n\");\n        }\n        super({\n            baseURL: options.baseURL,\n            timeout: options.timeout ?? 600000 /* 10 minutes */,\n            httpAgent: options.httpAgent,\n            maxRetries: options.maxRetries,\n            fetch: options.fetch,\n        });\n        this.completions = new _resources_index_mjs__WEBPACK_IMPORTED_MODULE_2__.Completions(this);\n        this.chat = new _resources_index_mjs__WEBPACK_IMPORTED_MODULE_3__.Chat(this);\n        this.embeddings = new _resources_index_mjs__WEBPACK_IMPORTED_MODULE_4__.Embeddings(this);\n        this.files = new _resources_index_mjs__WEBPACK_IMPORTED_MODULE_5__.Files(this);\n        this.images = new _resources_index_mjs__WEBPACK_IMPORTED_MODULE_6__.Images(this);\n        this.audio = new _resources_index_mjs__WEBPACK_IMPORTED_MODULE_7__.Audio(this);\n        this.moderations = new _resources_index_mjs__WEBPACK_IMPORTED_MODULE_8__.Moderations(this);\n        this.models = new _resources_index_mjs__WEBPACK_IMPORTED_MODULE_9__.Models(this);\n        this.fineTuning = new _resources_index_mjs__WEBPACK_IMPORTED_MODULE_10__.FineTuning(this);\n        this.beta = new _resources_index_mjs__WEBPACK_IMPORTED_MODULE_11__.Beta(this);\n        this.batches = new _resources_index_mjs__WEBPACK_IMPORTED_MODULE_12__.Batches(this);\n        this.uploads = new _resources_index_mjs__WEBPACK_IMPORTED_MODULE_13__.Uploads(this);\n        this._options = options;\n        this.apiKey = apiKey;\n        this.organization = organization;\n        this.project = project;\n    }\n    defaultQuery() {\n        return this._options.defaultQuery;\n    }\n    defaultHeaders(opts) {\n        return {\n            ...super.defaultHeaders(opts),\n            'OpenAI-Organization': this.organization,\n            'OpenAI-Project': this.project,\n            ...this._options.defaultHeaders,\n        };\n    }\n    authHeaders(opts) {\n        return { Authorization: `Bearer ${this.apiKey}` };\n    }\n    stringifyQuery(query) {\n        return _internal_qs_index_mjs__WEBPACK_IMPORTED_MODULE_14__.stringify(query, { arrayFormat: 'brackets' });\n    }\n}\n_a = OpenAI;\nOpenAI.OpenAI = _a;\nOpenAI.DEFAULT_TIMEOUT = 600000; // 10 minutes\nOpenAI.OpenAIError = _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError;\nOpenAI.APIError = _error_mjs__WEBPACK_IMPORTED_MODULE_1__.APIError;\nOpenAI.APIConnectionError = _error_mjs__WEBPACK_IMPORTED_MODULE_1__.APIConnectionError;\nOpenAI.APIConnectionTimeoutError = _error_mjs__WEBPACK_IMPORTED_MODULE_1__.APIConnectionTimeoutError;\nOpenAI.APIUserAbortError = _error_mjs__WEBPACK_IMPORTED_MODULE_1__.APIUserAbortError;\nOpenAI.NotFoundError = _error_mjs__WEBPACK_IMPORTED_MODULE_1__.NotFoundError;\nOpenAI.ConflictError = _error_mjs__WEBPACK_IMPORTED_MODULE_1__.ConflictError;\nOpenAI.RateLimitError = _error_mjs__WEBPACK_IMPORTED_MODULE_1__.RateLimitError;\nOpenAI.BadRequestError = _error_mjs__WEBPACK_IMPORTED_MODULE_1__.BadRequestError;\nOpenAI.AuthenticationError = _error_mjs__WEBPACK_IMPORTED_MODULE_1__.AuthenticationError;\nOpenAI.InternalServerError = _error_mjs__WEBPACK_IMPORTED_MODULE_1__.InternalServerError;\nOpenAI.PermissionDeniedError = _error_mjs__WEBPACK_IMPORTED_MODULE_1__.PermissionDeniedError;\nOpenAI.UnprocessableEntityError = _error_mjs__WEBPACK_IMPORTED_MODULE_1__.UnprocessableEntityError;\nOpenAI.toFile = _uploads_mjs__WEBPACK_IMPORTED_MODULE_15__.toFile;\nOpenAI.fileFromPath = _uploads_mjs__WEBPACK_IMPORTED_MODULE_16__.fileFromPath;\nOpenAI.Completions = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_2__.Completions;\nOpenAI.Chat = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_3__.Chat;\nOpenAI.ChatCompletionsPage = _resources_chat_completions_completions_mjs__WEBPACK_IMPORTED_MODULE_17__.ChatCompletionsPage;\nOpenAI.Embeddings = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_4__.Embeddings;\nOpenAI.Files = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_5__.Files;\nOpenAI.FileObjectsPage = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_5__.FileObjectsPage;\nOpenAI.Images = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_6__.Images;\nOpenAI.Audio = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_7__.Audio;\nOpenAI.Moderations = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_8__.Moderations;\nOpenAI.Models = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_9__.Models;\nOpenAI.ModelsPage = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_9__.ModelsPage;\nOpenAI.FineTuning = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_10__.FineTuning;\nOpenAI.Beta = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_11__.Beta;\nOpenAI.Batches = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_12__.Batches;\nOpenAI.BatchesPage = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_12__.BatchesPage;\nOpenAI.Uploads = _resources_index_mjs__WEBPACK_IMPORTED_MODULE_13__.Uploads;\n/** API Client for interfacing with the Azure OpenAI API. */\nclass AzureOpenAI extends OpenAI {\n    /**\n     * API Client for interfacing with the Azure OpenAI API.\n     *\n     * @param {string | undefined} [opts.apiVersion=process.env['OPENAI_API_VERSION'] ?? undefined]\n     * @param {string | undefined} [opts.endpoint=process.env['AZURE_OPENAI_ENDPOINT'] ?? undefined] - Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`\n     * @param {string | undefined} [opts.apiKey=process.env['AZURE_OPENAI_API_KEY'] ?? undefined]\n     * @param {string | undefined} opts.deployment - A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.\n     * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n     * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL']] - Sets the base URL for the API, e.g. `https://example-resource.azure.openai.com/openai/`.\n     * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n     * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.\n     * @param {Core.Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n     * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n     * @param {Core.Headers} opts.defaultHeaders - Default headers to include with every request to the API.\n     * @param {Core.DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.\n     * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n     */\n    constructor({ baseURL = _core_mjs__WEBPACK_IMPORTED_MODULE_0__.readEnv('OPENAI_BASE_URL'), apiKey = _core_mjs__WEBPACK_IMPORTED_MODULE_0__.readEnv('AZURE_OPENAI_API_KEY'), apiVersion = _core_mjs__WEBPACK_IMPORTED_MODULE_0__.readEnv('OPENAI_API_VERSION'), endpoint, deployment, azureADTokenProvider, dangerouslyAllowBrowser, ...opts } = {}) {\n        if (!apiVersion) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(\"The OPENAI_API_VERSION environment variable is missing or empty; either provide it, or instantiate the AzureOpenAI client with an apiVersion option, like new AzureOpenAI({ apiVersion: 'My API Version' }).\");\n        }\n        if (typeof azureADTokenProvider === 'function') {\n            dangerouslyAllowBrowser = true;\n        }\n        if (!azureADTokenProvider && !apiKey) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError('Missing credentials. Please pass one of `apiKey` and `azureADTokenProvider`, or set the `AZURE_OPENAI_API_KEY` environment variable.');\n        }\n        if (azureADTokenProvider && apiKey) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError('The `apiKey` and `azureADTokenProvider` arguments are mutually exclusive; only one can be passed at a time.');\n        }\n        // define a sentinel value to avoid any typing issues\n        apiKey ?? (apiKey = API_KEY_SENTINEL);\n        opts.defaultQuery = { ...opts.defaultQuery, 'api-version': apiVersion };\n        if (!baseURL) {\n            if (!endpoint) {\n                endpoint = process.env['AZURE_OPENAI_ENDPOINT'];\n            }\n            if (!endpoint) {\n                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError('Must provide one of the `baseURL` or `endpoint` arguments, or the `AZURE_OPENAI_ENDPOINT` environment variable');\n            }\n            baseURL = `${endpoint}/openai`;\n        }\n        else {\n            if (endpoint) {\n                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError('baseURL and endpoint are mutually exclusive');\n            }\n        }\n        super({\n            apiKey,\n            baseURL,\n            ...opts,\n            ...(dangerouslyAllowBrowser !== undefined ? { dangerouslyAllowBrowser } : {}),\n        });\n        this.apiVersion = '';\n        this._azureADTokenProvider = azureADTokenProvider;\n        this.apiVersion = apiVersion;\n        this.deploymentName = deployment;\n    }\n    buildRequest(options, props = {}) {\n        if (_deployments_endpoints.has(options.path) && options.method === 'post' && options.body !== undefined) {\n            if (!_core_mjs__WEBPACK_IMPORTED_MODULE_0__.isObj(options.body)) {\n                throw new Error('Expected request body to be an object');\n            }\n            const model = this.deploymentName || options.body['model'] || options.__metadata?.['model'];\n            if (model !== undefined && !this.baseURL.includes('/deployments')) {\n                options.path = `/deployments/${model}${options.path}`;\n            }\n        }\n        return super.buildRequest(options, props);\n    }\n    async _getAzureADToken() {\n        if (typeof this._azureADTokenProvider === 'function') {\n            const token = await this._azureADTokenProvider();\n            if (!token || typeof token !== 'string') {\n                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(`Expected 'azureADTokenProvider' argument to return a string but it returned ${token}`);\n            }\n            return token;\n        }\n        return undefined;\n    }\n    authHeaders(opts) {\n        return {};\n    }\n    async prepareOptions(opts) {\n        /**\n         * The user should provide a bearer token provider if they want\n         * to use Azure AD authentication. The user shouldn't set the\n         * Authorization header manually because the header is overwritten\n         * with the Azure AD token if a bearer token provider is provided.\n         */\n        if (opts.headers?.['api-key']) {\n            return super.prepareOptions(opts);\n        }\n        const token = await this._getAzureADToken();\n        opts.headers ?? (opts.headers = {});\n        if (token) {\n            opts.headers['Authorization'] = `Bearer ${token}`;\n        }\n        else if (this.apiKey !== API_KEY_SENTINEL) {\n            opts.headers['api-key'] = this.apiKey;\n        }\n        else {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError('Unable to handle auth');\n        }\n        return super.prepareOptions(opts);\n    }\n}\nconst _deployments_endpoints = new Set([\n    '/completions',\n    '/chat/completions',\n    '/embeddings',\n    '/audio/transcriptions',\n    '/audio/translations',\n    '/audio/speech',\n    '/images/generations',\n]);\nconst API_KEY_SENTINEL = '<Missing Key>';\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (OpenAI);\n//# sourceMappingURL=index.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/index.mjs?");

/***/ }),

/***/ "./node_modules/openai/internal/decoders/line.mjs":
/*!********************************************************!*\
  !*** ./node_modules/openai/internal/decoders/line.mjs ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   LineDecoder: () => (/* binding */ LineDecoder),\n/* harmony export */   findDoubleNewlineIndex: () => (/* binding */ findDoubleNewlineIndex)\n/* harmony export */ });\n/* harmony import */ var _error_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../error.mjs */ \"./node_modules/openai/error.mjs\");\nvar __classPrivateFieldSet = (undefined && undefined.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {\n    if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n    return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n};\nvar __classPrivateFieldGet = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar _LineDecoder_carriageReturnIndex;\n\n/**\n * A re-implementation of httpx's `LineDecoder` in Python that handles incrementally\n * reading lines from text.\n *\n * https://github.com/encode/httpx/blob/920333ea98118e9cf617f246905d7b202510941c/httpx/_decoders.py#L258\n */\nclass LineDecoder {\n    constructor() {\n        _LineDecoder_carriageReturnIndex.set(this, void 0);\n        this.buffer = new Uint8Array();\n        __classPrivateFieldSet(this, _LineDecoder_carriageReturnIndex, null, \"f\");\n    }\n    decode(chunk) {\n        if (chunk == null) {\n            return [];\n        }\n        const binaryChunk = chunk instanceof ArrayBuffer ? new Uint8Array(chunk)\n            : typeof chunk === 'string' ? new TextEncoder().encode(chunk)\n                : chunk;\n        let newData = new Uint8Array(this.buffer.length + binaryChunk.length);\n        newData.set(this.buffer);\n        newData.set(binaryChunk, this.buffer.length);\n        this.buffer = newData;\n        const lines = [];\n        let patternIndex;\n        while ((patternIndex = findNewlineIndex(this.buffer, __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\"))) != null) {\n            if (patternIndex.carriage && __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\") == null) {\n                // skip until we either get a corresponding `\\n`, a new `\\r` or nothing\n                __classPrivateFieldSet(this, _LineDecoder_carriageReturnIndex, patternIndex.index, \"f\");\n                continue;\n            }\n            // we got double \\r or \\rtext\\n\n            if (__classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\") != null &&\n                (patternIndex.index !== __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\") + 1 || patternIndex.carriage)) {\n                lines.push(this.decodeText(this.buffer.slice(0, __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\") - 1)));\n                this.buffer = this.buffer.slice(__classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\"));\n                __classPrivateFieldSet(this, _LineDecoder_carriageReturnIndex, null, \"f\");\n                continue;\n            }\n            const endIndex = __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, \"f\") !== null ? patternIndex.preceding - 1 : patternIndex.preceding;\n            const line = this.decodeText(this.buffer.slice(0, endIndex));\n            lines.push(line);\n            this.buffer = this.buffer.slice(patternIndex.index);\n            __classPrivateFieldSet(this, _LineDecoder_carriageReturnIndex, null, \"f\");\n        }\n        return lines;\n    }\n    decodeText(bytes) {\n        if (bytes == null)\n            return '';\n        if (typeof bytes === 'string')\n            return bytes;\n        // Node:\n        if (typeof Buffer !== 'undefined') {\n            if (bytes instanceof Buffer) {\n                return bytes.toString();\n            }\n            if (bytes instanceof Uint8Array) {\n                return Buffer.from(bytes).toString();\n            }\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_0__.OpenAIError(`Unexpected: received non-Uint8Array (${bytes.constructor.name}) stream chunk in an environment with a global \"Buffer\" defined, which this library assumes to be Node. Please report this error.`);\n        }\n        // Browser\n        if (typeof TextDecoder !== 'undefined') {\n            if (bytes instanceof Uint8Array || bytes instanceof ArrayBuffer) {\n                this.textDecoder ?? (this.textDecoder = new TextDecoder('utf8'));\n                return this.textDecoder.decode(bytes);\n            }\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_0__.OpenAIError(`Unexpected: received non-Uint8Array/ArrayBuffer (${bytes.constructor.name}) in a web platform. Please report this error.`);\n        }\n        throw new _error_mjs__WEBPACK_IMPORTED_MODULE_0__.OpenAIError(`Unexpected: neither Buffer nor TextDecoder are available as globals. Please report this error.`);\n    }\n    flush() {\n        if (!this.buffer.length) {\n            return [];\n        }\n        return this.decode('\\n');\n    }\n}\n_LineDecoder_carriageReturnIndex = new WeakMap();\n// prettier-ignore\nLineDecoder.NEWLINE_CHARS = new Set(['\\n', '\\r']);\nLineDecoder.NEWLINE_REGEXP = /\\r\\n|[\\n\\r]/g;\n/**\n * This function searches the buffer for the end patterns, (\\r or \\n)\n * and returns an object with the index preceding the matched newline and the\n * index after the newline char. `null` is returned if no new line is found.\n *\n * ```ts\n * findNewLineIndex('abc\\ndef') -> { preceding: 2, index: 3 }\n * ```\n */\nfunction findNewlineIndex(buffer, startIndex) {\n    const newline = 0x0a; // \\n\n    const carriage = 0x0d; // \\r\n    for (let i = startIndex ?? 0; i < buffer.length; i++) {\n        if (buffer[i] === newline) {\n            return { preceding: i, index: i + 1, carriage: false };\n        }\n        if (buffer[i] === carriage) {\n            return { preceding: i, index: i + 1, carriage: true };\n        }\n    }\n    return null;\n}\nfunction findDoubleNewlineIndex(buffer) {\n    // This function searches the buffer for the end patterns (\\r\\r, \\n\\n, \\r\\n\\r\\n)\n    // and returns the index right after the first occurrence of any pattern,\n    // or -1 if none of the patterns are found.\n    const newline = 0x0a; // \\n\n    const carriage = 0x0d; // \\r\n    for (let i = 0; i < buffer.length - 1; i++) {\n        if (buffer[i] === newline && buffer[i + 1] === newline) {\n            // \\n\\n\n            return i + 2;\n        }\n        if (buffer[i] === carriage && buffer[i + 1] === carriage) {\n            // \\r\\r\n            return i + 2;\n        }\n        if (buffer[i] === carriage &&\n            buffer[i + 1] === newline &&\n            i + 3 < buffer.length &&\n            buffer[i + 2] === carriage &&\n            buffer[i + 3] === newline) {\n            // \\r\\n\\r\\n\n            return i + 4;\n        }\n    }\n    return -1;\n}\n//# sourceMappingURL=line.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/internal/decoders/line.mjs?");

/***/ }),

/***/ "./node_modules/openai/internal/qs/formats.mjs":
/*!*****************************************************!*\
  !*** ./node_modules/openai/internal/qs/formats.mjs ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   RFC1738: () => (/* binding */ RFC1738),\n/* harmony export */   RFC3986: () => (/* binding */ RFC3986),\n/* harmony export */   default_format: () => (/* binding */ default_format),\n/* harmony export */   formatters: () => (/* binding */ formatters)\n/* harmony export */ });\nconst default_format = 'RFC3986';\nconst formatters = {\n    RFC1738: (v) => String(v).replace(/%20/g, '+'),\n    RFC3986: (v) => String(v),\n};\nconst RFC1738 = 'RFC1738';\nconst RFC3986 = 'RFC3986';\n//# sourceMappingURL=formats.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/internal/qs/formats.mjs?");

/***/ }),

/***/ "./node_modules/openai/internal/qs/stringify.mjs":
/*!*******************************************************!*\
  !*** ./node_modules/openai/internal/qs/stringify.mjs ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   stringify: () => (/* binding */ stringify)\n/* harmony export */ });\n/* harmony import */ var _utils_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils.mjs */ \"./node_modules/openai/internal/qs/utils.mjs\");\n/* harmony import */ var _formats_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./formats.mjs */ \"./node_modules/openai/internal/qs/formats.mjs\");\n\n\nconst has = Object.prototype.hasOwnProperty;\nconst array_prefix_generators = {\n    brackets(prefix) {\n        return String(prefix) + '[]';\n    },\n    comma: 'comma',\n    indices(prefix, key) {\n        return String(prefix) + '[' + key + ']';\n    },\n    repeat(prefix) {\n        return String(prefix);\n    },\n};\nconst is_array = Array.isArray;\nconst push = Array.prototype.push;\nconst push_to_array = function (arr, value_or_array) {\n    push.apply(arr, is_array(value_or_array) ? value_or_array : [value_or_array]);\n};\nconst to_ISO = Date.prototype.toISOString;\nconst defaults = {\n    addQueryPrefix: false,\n    allowDots: false,\n    allowEmptyArrays: false,\n    arrayFormat: 'indices',\n    charset: 'utf-8',\n    charsetSentinel: false,\n    delimiter: '&',\n    encode: true,\n    encodeDotInKeys: false,\n    encoder: _utils_mjs__WEBPACK_IMPORTED_MODULE_0__.encode,\n    encodeValuesOnly: false,\n    format: _formats_mjs__WEBPACK_IMPORTED_MODULE_1__.default_format,\n    formatter: _formats_mjs__WEBPACK_IMPORTED_MODULE_1__.formatters[_formats_mjs__WEBPACK_IMPORTED_MODULE_1__.default_format],\n    /** @deprecated */\n    indices: false,\n    serializeDate(date) {\n        return to_ISO.call(date);\n    },\n    skipNulls: false,\n    strictNullHandling: false,\n};\nfunction is_non_nullish_primitive(v) {\n    return (typeof v === 'string' ||\n        typeof v === 'number' ||\n        typeof v === 'boolean' ||\n        typeof v === 'symbol' ||\n        typeof v === 'bigint');\n}\nconst sentinel = {};\nfunction inner_stringify(object, prefix, generateArrayPrefix, commaRoundTrip, allowEmptyArrays, strictNullHandling, skipNulls, encodeDotInKeys, encoder, filter, sort, allowDots, serializeDate, format, formatter, encodeValuesOnly, charset, sideChannel) {\n    let obj = object;\n    let tmp_sc = sideChannel;\n    let step = 0;\n    let find_flag = false;\n    while ((tmp_sc = tmp_sc.get(sentinel)) !== void undefined && !find_flag) {\n        // Where object last appeared in the ref tree\n        const pos = tmp_sc.get(object);\n        step += 1;\n        if (typeof pos !== 'undefined') {\n            if (pos === step) {\n                throw new RangeError('Cyclic object value');\n            }\n            else {\n                find_flag = true; // Break while\n            }\n        }\n        if (typeof tmp_sc.get(sentinel) === 'undefined') {\n            step = 0;\n        }\n    }\n    if (typeof filter === 'function') {\n        obj = filter(prefix, obj);\n    }\n    else if (obj instanceof Date) {\n        obj = serializeDate?.(obj);\n    }\n    else if (generateArrayPrefix === 'comma' && is_array(obj)) {\n        obj = (0,_utils_mjs__WEBPACK_IMPORTED_MODULE_0__.maybe_map)(obj, function (value) {\n            if (value instanceof Date) {\n                return serializeDate?.(value);\n            }\n            return value;\n        });\n    }\n    if (obj === null) {\n        if (strictNullHandling) {\n            return encoder && !encodeValuesOnly ?\n                // @ts-expect-error\n                encoder(prefix, defaults.encoder, charset, 'key', format)\n                : prefix;\n        }\n        obj = '';\n    }\n    if (is_non_nullish_primitive(obj) || (0,_utils_mjs__WEBPACK_IMPORTED_MODULE_0__.is_buffer)(obj)) {\n        if (encoder) {\n            const key_value = encodeValuesOnly ? prefix\n                // @ts-expect-error\n                : encoder(prefix, defaults.encoder, charset, 'key', format);\n            return [\n                formatter?.(key_value) +\n                    '=' +\n                    // @ts-expect-error\n                    formatter?.(encoder(obj, defaults.encoder, charset, 'value', format)),\n            ];\n        }\n        return [formatter?.(prefix) + '=' + formatter?.(String(obj))];\n    }\n    const values = [];\n    if (typeof obj === 'undefined') {\n        return values;\n    }\n    let obj_keys;\n    if (generateArrayPrefix === 'comma' && is_array(obj)) {\n        // we need to join elements in\n        if (encodeValuesOnly && encoder) {\n            // @ts-expect-error values only\n            obj = (0,_utils_mjs__WEBPACK_IMPORTED_MODULE_0__.maybe_map)(obj, encoder);\n        }\n        obj_keys = [{ value: obj.length > 0 ? obj.join(',') || null : void undefined }];\n    }\n    else if (is_array(filter)) {\n        obj_keys = filter;\n    }\n    else {\n        const keys = Object.keys(obj);\n        obj_keys = sort ? keys.sort(sort) : keys;\n    }\n    const encoded_prefix = encodeDotInKeys ? String(prefix).replace(/\\./g, '%2E') : String(prefix);\n    const adjusted_prefix = commaRoundTrip && is_array(obj) && obj.length === 1 ? encoded_prefix + '[]' : encoded_prefix;\n    if (allowEmptyArrays && is_array(obj) && obj.length === 0) {\n        return adjusted_prefix + '[]';\n    }\n    for (let j = 0; j < obj_keys.length; ++j) {\n        const key = obj_keys[j];\n        const value = \n        // @ts-ignore\n        typeof key === 'object' && typeof key.value !== 'undefined' ? key.value : obj[key];\n        if (skipNulls && value === null) {\n            continue;\n        }\n        // @ts-ignore\n        const encoded_key = allowDots && encodeDotInKeys ? key.replace(/\\./g, '%2E') : key;\n        const key_prefix = is_array(obj) ?\n            typeof generateArrayPrefix === 'function' ?\n                generateArrayPrefix(adjusted_prefix, encoded_key)\n                : adjusted_prefix\n            : adjusted_prefix + (allowDots ? '.' + encoded_key : '[' + encoded_key + ']');\n        sideChannel.set(object, step);\n        const valueSideChannel = new WeakMap();\n        valueSideChannel.set(sentinel, sideChannel);\n        push_to_array(values, inner_stringify(value, key_prefix, generateArrayPrefix, commaRoundTrip, allowEmptyArrays, strictNullHandling, skipNulls, encodeDotInKeys, \n        // @ts-ignore\n        generateArrayPrefix === 'comma' && encodeValuesOnly && is_array(obj) ? null : encoder, filter, sort, allowDots, serializeDate, format, formatter, encodeValuesOnly, charset, valueSideChannel));\n    }\n    return values;\n}\nfunction normalize_stringify_options(opts = defaults) {\n    if (typeof opts.allowEmptyArrays !== 'undefined' && typeof opts.allowEmptyArrays !== 'boolean') {\n        throw new TypeError('`allowEmptyArrays` option can only be `true` or `false`, when provided');\n    }\n    if (typeof opts.encodeDotInKeys !== 'undefined' && typeof opts.encodeDotInKeys !== 'boolean') {\n        throw new TypeError('`encodeDotInKeys` option can only be `true` or `false`, when provided');\n    }\n    if (opts.encoder !== null && typeof opts.encoder !== 'undefined' && typeof opts.encoder !== 'function') {\n        throw new TypeError('Encoder has to be a function.');\n    }\n    const charset = opts.charset || defaults.charset;\n    if (typeof opts.charset !== 'undefined' && opts.charset !== 'utf-8' && opts.charset !== 'iso-8859-1') {\n        throw new TypeError('The charset option must be either utf-8, iso-8859-1, or undefined');\n    }\n    let format = _formats_mjs__WEBPACK_IMPORTED_MODULE_1__.default_format;\n    if (typeof opts.format !== 'undefined') {\n        if (!has.call(_formats_mjs__WEBPACK_IMPORTED_MODULE_1__.formatters, opts.format)) {\n            throw new TypeError('Unknown format option provided.');\n        }\n        format = opts.format;\n    }\n    const formatter = _formats_mjs__WEBPACK_IMPORTED_MODULE_1__.formatters[format];\n    let filter = defaults.filter;\n    if (typeof opts.filter === 'function' || is_array(opts.filter)) {\n        filter = opts.filter;\n    }\n    let arrayFormat;\n    if (opts.arrayFormat && opts.arrayFormat in array_prefix_generators) {\n        arrayFormat = opts.arrayFormat;\n    }\n    else if ('indices' in opts) {\n        arrayFormat = opts.indices ? 'indices' : 'repeat';\n    }\n    else {\n        arrayFormat = defaults.arrayFormat;\n    }\n    if ('commaRoundTrip' in opts && typeof opts.commaRoundTrip !== 'boolean') {\n        throw new TypeError('`commaRoundTrip` must be a boolean, or absent');\n    }\n    const allowDots = typeof opts.allowDots === 'undefined' ?\n        !!opts.encodeDotInKeys === true ?\n            true\n            : defaults.allowDots\n        : !!opts.allowDots;\n    return {\n        addQueryPrefix: typeof opts.addQueryPrefix === 'boolean' ? opts.addQueryPrefix : defaults.addQueryPrefix,\n        // @ts-ignore\n        allowDots: allowDots,\n        allowEmptyArrays: typeof opts.allowEmptyArrays === 'boolean' ? !!opts.allowEmptyArrays : defaults.allowEmptyArrays,\n        arrayFormat: arrayFormat,\n        charset: charset,\n        charsetSentinel: typeof opts.charsetSentinel === 'boolean' ? opts.charsetSentinel : defaults.charsetSentinel,\n        commaRoundTrip: !!opts.commaRoundTrip,\n        delimiter: typeof opts.delimiter === 'undefined' ? defaults.delimiter : opts.delimiter,\n        encode: typeof opts.encode === 'boolean' ? opts.encode : defaults.encode,\n        encodeDotInKeys: typeof opts.encodeDotInKeys === 'boolean' ? opts.encodeDotInKeys : defaults.encodeDotInKeys,\n        encoder: typeof opts.encoder === 'function' ? opts.encoder : defaults.encoder,\n        encodeValuesOnly: typeof opts.encodeValuesOnly === 'boolean' ? opts.encodeValuesOnly : defaults.encodeValuesOnly,\n        filter: filter,\n        format: format,\n        formatter: formatter,\n        serializeDate: typeof opts.serializeDate === 'function' ? opts.serializeDate : defaults.serializeDate,\n        skipNulls: typeof opts.skipNulls === 'boolean' ? opts.skipNulls : defaults.skipNulls,\n        // @ts-ignore\n        sort: typeof opts.sort === 'function' ? opts.sort : null,\n        strictNullHandling: typeof opts.strictNullHandling === 'boolean' ? opts.strictNullHandling : defaults.strictNullHandling,\n    };\n}\nfunction stringify(object, opts = {}) {\n    let obj = object;\n    const options = normalize_stringify_options(opts);\n    let obj_keys;\n    let filter;\n    if (typeof options.filter === 'function') {\n        filter = options.filter;\n        obj = filter('', obj);\n    }\n    else if (is_array(options.filter)) {\n        filter = options.filter;\n        obj_keys = filter;\n    }\n    const keys = [];\n    if (typeof obj !== 'object' || obj === null) {\n        return '';\n    }\n    const generateArrayPrefix = array_prefix_generators[options.arrayFormat];\n    const commaRoundTrip = generateArrayPrefix === 'comma' && options.commaRoundTrip;\n    if (!obj_keys) {\n        obj_keys = Object.keys(obj);\n    }\n    if (options.sort) {\n        obj_keys.sort(options.sort);\n    }\n    const sideChannel = new WeakMap();\n    for (let i = 0; i < obj_keys.length; ++i) {\n        const key = obj_keys[i];\n        if (options.skipNulls && obj[key] === null) {\n            continue;\n        }\n        push_to_array(keys, inner_stringify(obj[key], key, \n        // @ts-expect-error\n        generateArrayPrefix, commaRoundTrip, options.allowEmptyArrays, options.strictNullHandling, options.skipNulls, options.encodeDotInKeys, options.encode ? options.encoder : null, options.filter, options.sort, options.allowDots, options.serializeDate, options.format, options.formatter, options.encodeValuesOnly, options.charset, sideChannel));\n    }\n    const joined = keys.join(options.delimiter);\n    let prefix = options.addQueryPrefix === true ? '?' : '';\n    if (options.charsetSentinel) {\n        if (options.charset === 'iso-8859-1') {\n            // encodeURIComponent('&#10003;'), the \"numeric entity\" representation of a checkmark\n            prefix += 'utf8=%26%2310003%3B&';\n        }\n        else {\n            // encodeURIComponent('âœ“')\n            prefix += 'utf8=%E2%9C%93&';\n        }\n    }\n    return joined.length > 0 ? prefix + joined : '';\n}\n//# sourceMappingURL=stringify.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/internal/qs/stringify.mjs?");

/***/ }),

/***/ "./node_modules/openai/internal/qs/utils.mjs":
/*!***************************************************!*\
  !*** ./node_modules/openai/internal/qs/utils.mjs ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   assign_single_source: () => (/* binding */ assign_single_source),\n/* harmony export */   combine: () => (/* binding */ combine),\n/* harmony export */   compact: () => (/* binding */ compact),\n/* harmony export */   decode: () => (/* binding */ decode),\n/* harmony export */   encode: () => (/* binding */ encode),\n/* harmony export */   is_buffer: () => (/* binding */ is_buffer),\n/* harmony export */   is_regexp: () => (/* binding */ is_regexp),\n/* harmony export */   maybe_map: () => (/* binding */ maybe_map),\n/* harmony export */   merge: () => (/* binding */ merge)\n/* harmony export */ });\n/* harmony import */ var _formats_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./formats.mjs */ \"./node_modules/openai/internal/qs/formats.mjs\");\n\nconst has = Object.prototype.hasOwnProperty;\nconst is_array = Array.isArray;\nconst hex_table = (() => {\n    const array = [];\n    for (let i = 0; i < 256; ++i) {\n        array.push('%' + ((i < 16 ? '0' : '') + i.toString(16)).toUpperCase());\n    }\n    return array;\n})();\nfunction compact_queue(queue) {\n    while (queue.length > 1) {\n        const item = queue.pop();\n        if (!item)\n            continue;\n        const obj = item.obj[item.prop];\n        if (is_array(obj)) {\n            const compacted = [];\n            for (let j = 0; j < obj.length; ++j) {\n                if (typeof obj[j] !== 'undefined') {\n                    compacted.push(obj[j]);\n                }\n            }\n            // @ts-ignore\n            item.obj[item.prop] = compacted;\n        }\n    }\n}\nfunction array_to_object(source, options) {\n    const obj = options && options.plainObjects ? Object.create(null) : {};\n    for (let i = 0; i < source.length; ++i) {\n        if (typeof source[i] !== 'undefined') {\n            obj[i] = source[i];\n        }\n    }\n    return obj;\n}\nfunction merge(target, source, options = {}) {\n    if (!source) {\n        return target;\n    }\n    if (typeof source !== 'object') {\n        if (is_array(target)) {\n            target.push(source);\n        }\n        else if (target && typeof target === 'object') {\n            if ((options && (options.plainObjects || options.allowPrototypes)) ||\n                !has.call(Object.prototype, source)) {\n                target[source] = true;\n            }\n        }\n        else {\n            return [target, source];\n        }\n        return target;\n    }\n    if (!target || typeof target !== 'object') {\n        return [target].concat(source);\n    }\n    let mergeTarget = target;\n    if (is_array(target) && !is_array(source)) {\n        // @ts-ignore\n        mergeTarget = array_to_object(target, options);\n    }\n    if (is_array(target) && is_array(source)) {\n        source.forEach(function (item, i) {\n            if (has.call(target, i)) {\n                const targetItem = target[i];\n                if (targetItem && typeof targetItem === 'object' && item && typeof item === 'object') {\n                    target[i] = merge(targetItem, item, options);\n                }\n                else {\n                    target.push(item);\n                }\n            }\n            else {\n                target[i] = item;\n            }\n        });\n        return target;\n    }\n    return Object.keys(source).reduce(function (acc, key) {\n        const value = source[key];\n        if (has.call(acc, key)) {\n            acc[key] = merge(acc[key], value, options);\n        }\n        else {\n            acc[key] = value;\n        }\n        return acc;\n    }, mergeTarget);\n}\nfunction assign_single_source(target, source) {\n    return Object.keys(source).reduce(function (acc, key) {\n        acc[key] = source[key];\n        return acc;\n    }, target);\n}\nfunction decode(str, _, charset) {\n    const strWithoutPlus = str.replace(/\\+/g, ' ');\n    if (charset === 'iso-8859-1') {\n        // unescape never throws, no try...catch needed:\n        return strWithoutPlus.replace(/%[0-9a-f]{2}/gi, unescape);\n    }\n    // utf-8\n    try {\n        return decodeURIComponent(strWithoutPlus);\n    }\n    catch (e) {\n        return strWithoutPlus;\n    }\n}\nconst limit = 1024;\nconst encode = (str, _defaultEncoder, charset, _kind, format) => {\n    // This code was originally written by Brian White for the io.js core querystring library.\n    // It has been adapted here for stricter adherence to RFC 3986\n    if (str.length === 0) {\n        return str;\n    }\n    let string = str;\n    if (typeof str === 'symbol') {\n        string = Symbol.prototype.toString.call(str);\n    }\n    else if (typeof str !== 'string') {\n        string = String(str);\n    }\n    if (charset === 'iso-8859-1') {\n        return escape(string).replace(/%u[0-9a-f]{4}/gi, function ($0) {\n            return '%26%23' + parseInt($0.slice(2), 16) + '%3B';\n        });\n    }\n    let out = '';\n    for (let j = 0; j < string.length; j += limit) {\n        const segment = string.length >= limit ? string.slice(j, j + limit) : string;\n        const arr = [];\n        for (let i = 0; i < segment.length; ++i) {\n            let c = segment.charCodeAt(i);\n            if (c === 0x2d || // -\n                c === 0x2e || // .\n                c === 0x5f || // _\n                c === 0x7e || // ~\n                (c >= 0x30 && c <= 0x39) || // 0-9\n                (c >= 0x41 && c <= 0x5a) || // a-z\n                (c >= 0x61 && c <= 0x7a) || // A-Z\n                (format === _formats_mjs__WEBPACK_IMPORTED_MODULE_0__.RFC1738 && (c === 0x28 || c === 0x29)) // ( )\n            ) {\n                arr[arr.length] = segment.charAt(i);\n                continue;\n            }\n            if (c < 0x80) {\n                arr[arr.length] = hex_table[c];\n                continue;\n            }\n            if (c < 0x800) {\n                arr[arr.length] = hex_table[0xc0 | (c >> 6)] + hex_table[0x80 | (c & 0x3f)];\n                continue;\n            }\n            if (c < 0xd800 || c >= 0xe000) {\n                arr[arr.length] =\n                    hex_table[0xe0 | (c >> 12)] + hex_table[0x80 | ((c >> 6) & 0x3f)] + hex_table[0x80 | (c & 0x3f)];\n                continue;\n            }\n            i += 1;\n            c = 0x10000 + (((c & 0x3ff) << 10) | (segment.charCodeAt(i) & 0x3ff));\n            arr[arr.length] =\n                hex_table[0xf0 | (c >> 18)] +\n                    hex_table[0x80 | ((c >> 12) & 0x3f)] +\n                    hex_table[0x80 | ((c >> 6) & 0x3f)] +\n                    hex_table[0x80 | (c & 0x3f)];\n        }\n        out += arr.join('');\n    }\n    return out;\n};\nfunction compact(value) {\n    const queue = [{ obj: { o: value }, prop: 'o' }];\n    const refs = [];\n    for (let i = 0; i < queue.length; ++i) {\n        const item = queue[i];\n        // @ts-ignore\n        const obj = item.obj[item.prop];\n        const keys = Object.keys(obj);\n        for (let j = 0; j < keys.length; ++j) {\n            const key = keys[j];\n            const val = obj[key];\n            if (typeof val === 'object' && val !== null && refs.indexOf(val) === -1) {\n                queue.push({ obj: obj, prop: key });\n                refs.push(val);\n            }\n        }\n    }\n    compact_queue(queue);\n    return value;\n}\nfunction is_regexp(obj) {\n    return Object.prototype.toString.call(obj) === '[object RegExp]';\n}\nfunction is_buffer(obj) {\n    if (!obj || typeof obj !== 'object') {\n        return false;\n    }\n    return !!(obj.constructor && obj.constructor.isBuffer && obj.constructor.isBuffer(obj));\n}\nfunction combine(a, b) {\n    return [].concat(a, b);\n}\nfunction maybe_map(val, fn) {\n    if (is_array(val)) {\n        const mapped = [];\n        for (let i = 0; i < val.length; i += 1) {\n            mapped.push(fn(val[i]));\n        }\n        return mapped;\n    }\n    return fn(val);\n}\n//# sourceMappingURL=utils.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/internal/qs/utils.mjs?");

/***/ }),

/***/ "./node_modules/openai/internal/stream-utils.mjs":
/*!*******************************************************!*\
  !*** ./node_modules/openai/internal/stream-utils.mjs ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ReadableStreamToAsyncIterable: () => (/* binding */ ReadableStreamToAsyncIterable)\n/* harmony export */ });\n/**\n * Most browsers don't yet have async iterable support for ReadableStream,\n * and Node has a very different way of reading bytes from its \"ReadableStream\".\n *\n * This polyfill was pulled from https://github.com/MattiasBuelens/web-streams-polyfill/pull/122#issuecomment-1627354490\n */\nfunction ReadableStreamToAsyncIterable(stream) {\n    if (stream[Symbol.asyncIterator])\n        return stream;\n    const reader = stream.getReader();\n    return {\n        async next() {\n            try {\n                const result = await reader.read();\n                if (result?.done)\n                    reader.releaseLock(); // release lock when stream becomes closed\n                return result;\n            }\n            catch (e) {\n                reader.releaseLock(); // release lock when stream becomes errored\n                throw e;\n            }\n        },\n        async return() {\n            const cancelPromise = reader.cancel();\n            reader.releaseLock();\n            await cancelPromise;\n            return { done: true, value: undefined };\n        },\n        [Symbol.asyncIterator]() {\n            return this;\n        },\n    };\n}\n//# sourceMappingURL=stream-utils.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/internal/stream-utils.mjs?");

/***/ }),

/***/ "./node_modules/openai/lib/AbstractChatCompletionRunner.mjs":
/*!******************************************************************!*\
  !*** ./node_modules/openai/lib/AbstractChatCompletionRunner.mjs ***!
  \******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AbstractChatCompletionRunner: () => (/* binding */ AbstractChatCompletionRunner)\n/* harmony export */ });\n/* harmony import */ var _error_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../error.mjs */ \"./node_modules/openai/error.mjs\");\n/* harmony import */ var _RunnableFunction_mjs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./RunnableFunction.mjs */ \"./node_modules/openai/lib/RunnableFunction.mjs\");\n/* harmony import */ var _chatCompletionUtils_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./chatCompletionUtils.mjs */ \"./node_modules/openai/lib/chatCompletionUtils.mjs\");\n/* harmony import */ var _EventStream_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./EventStream.mjs */ \"./node_modules/openai/lib/EventStream.mjs\");\n/* harmony import */ var _lib_parser_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../lib/parser.mjs */ \"./node_modules/openai/lib/parser.mjs\");\nvar __classPrivateFieldGet = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar _AbstractChatCompletionRunner_instances, _AbstractChatCompletionRunner_getFinalContent, _AbstractChatCompletionRunner_getFinalMessage, _AbstractChatCompletionRunner_getFinalFunctionCall, _AbstractChatCompletionRunner_getFinalFunctionCallResult, _AbstractChatCompletionRunner_calculateTotalUsage, _AbstractChatCompletionRunner_validateParams, _AbstractChatCompletionRunner_stringifyFunctionCallResult;\n\n\n\n\n\nconst DEFAULT_MAX_CHAT_COMPLETIONS = 10;\nclass AbstractChatCompletionRunner extends _EventStream_mjs__WEBPACK_IMPORTED_MODULE_0__.EventStream {\n    constructor() {\n        super(...arguments);\n        _AbstractChatCompletionRunner_instances.add(this);\n        this._chatCompletions = [];\n        this.messages = [];\n    }\n    _addChatCompletion(chatCompletion) {\n        this._chatCompletions.push(chatCompletion);\n        this._emit('chatCompletion', chatCompletion);\n        const message = chatCompletion.choices[0]?.message;\n        if (message)\n            this._addMessage(message);\n        return chatCompletion;\n    }\n    _addMessage(message, emit = true) {\n        if (!('content' in message))\n            message.content = null;\n        this.messages.push(message);\n        if (emit) {\n            this._emit('message', message);\n            if (((0,_chatCompletionUtils_mjs__WEBPACK_IMPORTED_MODULE_1__.isFunctionMessage)(message) || (0,_chatCompletionUtils_mjs__WEBPACK_IMPORTED_MODULE_1__.isToolMessage)(message)) && message.content) {\n                // Note, this assumes that {role: 'tool', content: â€¦} is always the result of a call of tool of type=function.\n                this._emit('functionCallResult', message.content);\n            }\n            else if ((0,_chatCompletionUtils_mjs__WEBPACK_IMPORTED_MODULE_1__.isAssistantMessage)(message) && message.function_call) {\n                this._emit('functionCall', message.function_call);\n            }\n            else if ((0,_chatCompletionUtils_mjs__WEBPACK_IMPORTED_MODULE_1__.isAssistantMessage)(message) && message.tool_calls) {\n                for (const tool_call of message.tool_calls) {\n                    if (tool_call.type === 'function') {\n                        this._emit('functionCall', tool_call.function);\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * @returns a promise that resolves with the final ChatCompletion, or rejects\n     * if an error occurred or the stream ended prematurely without producing a ChatCompletion.\n     */\n    async finalChatCompletion() {\n        await this.done();\n        const completion = this._chatCompletions[this._chatCompletions.length - 1];\n        if (!completion)\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_2__.OpenAIError('stream ended without producing a ChatCompletion');\n        return completion;\n    }\n    /**\n     * @returns a promise that resolves with the content of the final ChatCompletionMessage, or rejects\n     * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n     */\n    async finalContent() {\n        await this.done();\n        return __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_getFinalContent).call(this);\n    }\n    /**\n     * @returns a promise that resolves with the the final assistant ChatCompletionMessage response,\n     * or rejects if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n     */\n    async finalMessage() {\n        await this.done();\n        return __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_getFinalMessage).call(this);\n    }\n    /**\n     * @returns a promise that resolves with the content of the final FunctionCall, or rejects\n     * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n     */\n    async finalFunctionCall() {\n        await this.done();\n        return __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_getFinalFunctionCall).call(this);\n    }\n    async finalFunctionCallResult() {\n        await this.done();\n        return __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_getFinalFunctionCallResult).call(this);\n    }\n    async totalUsage() {\n        await this.done();\n        return __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_calculateTotalUsage).call(this);\n    }\n    allChatCompletions() {\n        return [...this._chatCompletions];\n    }\n    _emitFinal() {\n        const completion = this._chatCompletions[this._chatCompletions.length - 1];\n        if (completion)\n            this._emit('finalChatCompletion', completion);\n        const finalMessage = __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_getFinalMessage).call(this);\n        if (finalMessage)\n            this._emit('finalMessage', finalMessage);\n        const finalContent = __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_getFinalContent).call(this);\n        if (finalContent)\n            this._emit('finalContent', finalContent);\n        const finalFunctionCall = __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_getFinalFunctionCall).call(this);\n        if (finalFunctionCall)\n            this._emit('finalFunctionCall', finalFunctionCall);\n        const finalFunctionCallResult = __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_getFinalFunctionCallResult).call(this);\n        if (finalFunctionCallResult != null)\n            this._emit('finalFunctionCallResult', finalFunctionCallResult);\n        if (this._chatCompletions.some((c) => c.usage)) {\n            this._emit('totalUsage', __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_calculateTotalUsage).call(this));\n        }\n    }\n    async _createChatCompletion(client, params, options) {\n        const signal = options?.signal;\n        if (signal) {\n            if (signal.aborted)\n                this.controller.abort();\n            signal.addEventListener('abort', () => this.controller.abort());\n        }\n        __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_validateParams).call(this, params);\n        const chatCompletion = await client.chat.completions.create({ ...params, stream: false }, { ...options, signal: this.controller.signal });\n        this._connected();\n        return this._addChatCompletion((0,_lib_parser_mjs__WEBPACK_IMPORTED_MODULE_3__.parseChatCompletion)(chatCompletion, params));\n    }\n    async _runChatCompletion(client, params, options) {\n        for (const message of params.messages) {\n            this._addMessage(message, false);\n        }\n        return await this._createChatCompletion(client, params, options);\n    }\n    async _runFunctions(client, params, options) {\n        const role = 'function';\n        const { function_call = 'auto', stream, ...restParams } = params;\n        const singleFunctionToCall = typeof function_call !== 'string' && function_call?.name;\n        const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\n        const functionsByName = {};\n        for (const f of params.functions) {\n            functionsByName[f.name || f.function.name] = f;\n        }\n        const functions = params.functions.map((f) => ({\n            name: f.name || f.function.name,\n            parameters: f.parameters,\n            description: f.description,\n        }));\n        for (const message of params.messages) {\n            this._addMessage(message, false);\n        }\n        for (let i = 0; i < maxChatCompletions; ++i) {\n            const chatCompletion = await this._createChatCompletion(client, {\n                ...restParams,\n                function_call,\n                functions,\n                messages: [...this.messages],\n            }, options);\n            const message = chatCompletion.choices[0]?.message;\n            if (!message) {\n                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_2__.OpenAIError(`missing message in ChatCompletion response`);\n            }\n            if (!message.function_call)\n                return;\n            const { name, arguments: args } = message.function_call;\n            const fn = functionsByName[name];\n            if (!fn) {\n                const content = `Invalid function_call: ${JSON.stringify(name)}. Available options are: ${functions\n                    .map((f) => JSON.stringify(f.name))\n                    .join(', ')}. Please try again`;\n                this._addMessage({ role, name, content });\n                continue;\n            }\n            else if (singleFunctionToCall && singleFunctionToCall !== name) {\n                const content = `Invalid function_call: ${JSON.stringify(name)}. ${JSON.stringify(singleFunctionToCall)} requested. Please try again`;\n                this._addMessage({ role, name, content });\n                continue;\n            }\n            let parsed;\n            try {\n                parsed = (0,_RunnableFunction_mjs__WEBPACK_IMPORTED_MODULE_4__.isRunnableFunctionWithParse)(fn) ? await fn.parse(args) : args;\n            }\n            catch (error) {\n                this._addMessage({\n                    role,\n                    name,\n                    content: error instanceof Error ? error.message : String(error),\n                });\n                continue;\n            }\n            // @ts-expect-error it can't rule out `never` type.\n            const rawContent = await fn.function(parsed, this);\n            const content = __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_stringifyFunctionCallResult).call(this, rawContent);\n            this._addMessage({ role, name, content });\n            if (singleFunctionToCall)\n                return;\n        }\n    }\n    async _runTools(client, params, options) {\n        const role = 'tool';\n        const { tool_choice = 'auto', stream, ...restParams } = params;\n        const singleFunctionToCall = typeof tool_choice !== 'string' && tool_choice?.function?.name;\n        const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\n        // TODO(someday): clean this logic up\n        const inputTools = params.tools.map((tool) => {\n            if ((0,_lib_parser_mjs__WEBPACK_IMPORTED_MODULE_3__.isAutoParsableTool)(tool)) {\n                if (!tool.$callback) {\n                    throw new _error_mjs__WEBPACK_IMPORTED_MODULE_2__.OpenAIError('Tool given to `.runTools()` that does not have an associated function');\n                }\n                return {\n                    type: 'function',\n                    function: {\n                        function: tool.$callback,\n                        name: tool.function.name,\n                        description: tool.function.description || '',\n                        parameters: tool.function.parameters,\n                        parse: tool.$parseRaw,\n                        strict: true,\n                    },\n                };\n            }\n            return tool;\n        });\n        const functionsByName = {};\n        for (const f of inputTools) {\n            if (f.type === 'function') {\n                functionsByName[f.function.name || f.function.function.name] = f.function;\n            }\n        }\n        const tools = 'tools' in params ?\n            inputTools.map((t) => t.type === 'function' ?\n                {\n                    type: 'function',\n                    function: {\n                        name: t.function.name || t.function.function.name,\n                        parameters: t.function.parameters,\n                        description: t.function.description,\n                        strict: t.function.strict,\n                    },\n                }\n                : t)\n            : undefined;\n        for (const message of params.messages) {\n            this._addMessage(message, false);\n        }\n        for (let i = 0; i < maxChatCompletions; ++i) {\n            const chatCompletion = await this._createChatCompletion(client, {\n                ...restParams,\n                tool_choice,\n                tools,\n                messages: [...this.messages],\n            }, options);\n            const message = chatCompletion.choices[0]?.message;\n            if (!message) {\n                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_2__.OpenAIError(`missing message in ChatCompletion response`);\n            }\n            if (!message.tool_calls?.length) {\n                return;\n            }\n            for (const tool_call of message.tool_calls) {\n                if (tool_call.type !== 'function')\n                    continue;\n                const tool_call_id = tool_call.id;\n                const { name, arguments: args } = tool_call.function;\n                const fn = functionsByName[name];\n                if (!fn) {\n                    const content = `Invalid tool_call: ${JSON.stringify(name)}. Available options are: ${Object.keys(functionsByName)\n                        .map((name) => JSON.stringify(name))\n                        .join(', ')}. Please try again`;\n                    this._addMessage({ role, tool_call_id, content });\n                    continue;\n                }\n                else if (singleFunctionToCall && singleFunctionToCall !== name) {\n                    const content = `Invalid tool_call: ${JSON.stringify(name)}. ${JSON.stringify(singleFunctionToCall)} requested. Please try again`;\n                    this._addMessage({ role, tool_call_id, content });\n                    continue;\n                }\n                let parsed;\n                try {\n                    parsed = (0,_RunnableFunction_mjs__WEBPACK_IMPORTED_MODULE_4__.isRunnableFunctionWithParse)(fn) ? await fn.parse(args) : args;\n                }\n                catch (error) {\n                    const content = error instanceof Error ? error.message : String(error);\n                    this._addMessage({ role, tool_call_id, content });\n                    continue;\n                }\n                // @ts-expect-error it can't rule out `never` type.\n                const rawContent = await fn.function(parsed, this);\n                const content = __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_stringifyFunctionCallResult).call(this, rawContent);\n                this._addMessage({ role, tool_call_id, content });\n                if (singleFunctionToCall) {\n                    return;\n                }\n            }\n        }\n        return;\n    }\n}\n_AbstractChatCompletionRunner_instances = new WeakSet(), _AbstractChatCompletionRunner_getFinalContent = function _AbstractChatCompletionRunner_getFinalContent() {\n    return __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, \"m\", _AbstractChatCompletionRunner_getFinalMessage).call(this).content ?? null;\n}, _AbstractChatCompletionRunner_getFinalMessage = function _AbstractChatCompletionRunner_getFinalMessage() {\n    let i = this.messages.length;\n    while (i-- > 0) {\n        const message = this.messages[i];\n        if ((0,_chatCompletionUtils_mjs__WEBPACK_IMPORTED_MODULE_1__.isAssistantMessage)(message)) {\n            const { function_call, ...rest } = message;\n            // TODO: support audio here\n            const ret = {\n                ...rest,\n                content: message.content ?? null,\n                refusal: message.refusal ?? null,\n            };\n            if (function_call) {\n                ret.function_call = function_call;\n            }\n            return ret;\n        }\n    }\n    throw new _error_mjs__WEBPACK_IMPORTED_MODULE_2__.OpenAIError('stream ended without producing a ChatCompletionMessage with role=assistant');\n}, _AbstractChatCompletionRunner_getFinalFunctionCall = function _AbstractChatCompletionRunner_getFinalFunctionCall() {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n        const message = this.messages[i];\n        if ((0,_chatCompletionUtils_mjs__WEBPACK_IMPORTED_MODULE_1__.isAssistantMessage)(message) && message?.function_call) {\n            return message.function_call;\n        }\n        if ((0,_chatCompletionUtils_mjs__WEBPACK_IMPORTED_MODULE_1__.isAssistantMessage)(message) && message?.tool_calls?.length) {\n            return message.tool_calls.at(-1)?.function;\n        }\n    }\n    return;\n}, _AbstractChatCompletionRunner_getFinalFunctionCallResult = function _AbstractChatCompletionRunner_getFinalFunctionCallResult() {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n        const message = this.messages[i];\n        if ((0,_chatCompletionUtils_mjs__WEBPACK_IMPORTED_MODULE_1__.isFunctionMessage)(message) && message.content != null) {\n            return message.content;\n        }\n        if ((0,_chatCompletionUtils_mjs__WEBPACK_IMPORTED_MODULE_1__.isToolMessage)(message) &&\n            message.content != null &&\n            typeof message.content === 'string' &&\n            this.messages.some((x) => x.role === 'assistant' &&\n                x.tool_calls?.some((y) => y.type === 'function' && y.id === message.tool_call_id))) {\n            return message.content;\n        }\n    }\n    return;\n}, _AbstractChatCompletionRunner_calculateTotalUsage = function _AbstractChatCompletionRunner_calculateTotalUsage() {\n    const total = {\n        completion_tokens: 0,\n        prompt_tokens: 0,\n        total_tokens: 0,\n    };\n    for (const { usage } of this._chatCompletions) {\n        if (usage) {\n            total.completion_tokens += usage.completion_tokens;\n            total.prompt_tokens += usage.prompt_tokens;\n            total.total_tokens += usage.total_tokens;\n        }\n    }\n    return total;\n}, _AbstractChatCompletionRunner_validateParams = function _AbstractChatCompletionRunner_validateParams(params) {\n    if (params.n != null && params.n > 1) {\n        throw new _error_mjs__WEBPACK_IMPORTED_MODULE_2__.OpenAIError('ChatCompletion convenience helpers only support n=1 at this time. To use n>1, please use chat.completions.create() directly.');\n    }\n}, _AbstractChatCompletionRunner_stringifyFunctionCallResult = function _AbstractChatCompletionRunner_stringifyFunctionCallResult(rawContent) {\n    return (typeof rawContent === 'string' ? rawContent\n        : rawContent === undefined ? 'undefined'\n            : JSON.stringify(rawContent));\n};\n//# sourceMappingURL=AbstractChatCompletionRunner.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/lib/AbstractChatCompletionRunner.mjs?");

/***/ }),

/***/ "./node_modules/openai/lib/AssistantStream.mjs":
/*!*****************************************************!*\
  !*** ./node_modules/openai/lib/AssistantStream.mjs ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AssistantStream: () => (/* binding */ AssistantStream)\n/* harmony export */ });\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _streaming_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../streaming.mjs */ \"./node_modules/openai/streaming.mjs\");\n/* harmony import */ var _error_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../error.mjs */ \"./node_modules/openai/error.mjs\");\n/* harmony import */ var _EventStream_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./EventStream.mjs */ \"./node_modules/openai/lib/EventStream.mjs\");\nvar __classPrivateFieldGet = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar __classPrivateFieldSet = (undefined && undefined.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {\n    if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n    return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n};\nvar _AssistantStream_instances, _AssistantStream_events, _AssistantStream_runStepSnapshots, _AssistantStream_messageSnapshots, _AssistantStream_messageSnapshot, _AssistantStream_finalRun, _AssistantStream_currentContentIndex, _AssistantStream_currentContent, _AssistantStream_currentToolCallIndex, _AssistantStream_currentToolCall, _AssistantStream_currentEvent, _AssistantStream_currentRunSnapshot, _AssistantStream_currentRunStepSnapshot, _AssistantStream_addEvent, _AssistantStream_endRequest, _AssistantStream_handleMessage, _AssistantStream_handleRunStep, _AssistantStream_handleEvent, _AssistantStream_accumulateRunStep, _AssistantStream_accumulateMessage, _AssistantStream_accumulateContent, _AssistantStream_handleRun;\n\n\n\n\nclass AssistantStream extends _EventStream_mjs__WEBPACK_IMPORTED_MODULE_0__.EventStream {\n    constructor() {\n        super(...arguments);\n        _AssistantStream_instances.add(this);\n        //Track all events in a single list for reference\n        _AssistantStream_events.set(this, []);\n        //Used to accumulate deltas\n        //We are accumulating many types so the value here is not strict\n        _AssistantStream_runStepSnapshots.set(this, {});\n        _AssistantStream_messageSnapshots.set(this, {});\n        _AssistantStream_messageSnapshot.set(this, void 0);\n        _AssistantStream_finalRun.set(this, void 0);\n        _AssistantStream_currentContentIndex.set(this, void 0);\n        _AssistantStream_currentContent.set(this, void 0);\n        _AssistantStream_currentToolCallIndex.set(this, void 0);\n        _AssistantStream_currentToolCall.set(this, void 0);\n        //For current snapshot methods\n        _AssistantStream_currentEvent.set(this, void 0);\n        _AssistantStream_currentRunSnapshot.set(this, void 0);\n        _AssistantStream_currentRunStepSnapshot.set(this, void 0);\n    }\n    [(_AssistantStream_events = new WeakMap(), _AssistantStream_runStepSnapshots = new WeakMap(), _AssistantStream_messageSnapshots = new WeakMap(), _AssistantStream_messageSnapshot = new WeakMap(), _AssistantStream_finalRun = new WeakMap(), _AssistantStream_currentContentIndex = new WeakMap(), _AssistantStream_currentContent = new WeakMap(), _AssistantStream_currentToolCallIndex = new WeakMap(), _AssistantStream_currentToolCall = new WeakMap(), _AssistantStream_currentEvent = new WeakMap(), _AssistantStream_currentRunSnapshot = new WeakMap(), _AssistantStream_currentRunStepSnapshot = new WeakMap(), _AssistantStream_instances = new WeakSet(), Symbol.asyncIterator)]() {\n        const pushQueue = [];\n        const readQueue = [];\n        let done = false;\n        //Catch all for passing along all events\n        this.on('event', (event) => {\n            const reader = readQueue.shift();\n            if (reader) {\n                reader.resolve(event);\n            }\n            else {\n                pushQueue.push(event);\n            }\n        });\n        this.on('end', () => {\n            done = true;\n            for (const reader of readQueue) {\n                reader.resolve(undefined);\n            }\n            readQueue.length = 0;\n        });\n        this.on('abort', (err) => {\n            done = true;\n            for (const reader of readQueue) {\n                reader.reject(err);\n            }\n            readQueue.length = 0;\n        });\n        this.on('error', (err) => {\n            done = true;\n            for (const reader of readQueue) {\n                reader.reject(err);\n            }\n            readQueue.length = 0;\n        });\n        return {\n            next: async () => {\n                if (!pushQueue.length) {\n                    if (done) {\n                        return { value: undefined, done: true };\n                    }\n                    return new Promise((resolve, reject) => readQueue.push({ resolve, reject })).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n                }\n                const chunk = pushQueue.shift();\n                return { value: chunk, done: false };\n            },\n            return: async () => {\n                this.abort();\n                return { value: undefined, done: true };\n            },\n        };\n    }\n    static fromReadableStream(stream) {\n        const runner = new AssistantStream();\n        runner._run(() => runner._fromReadableStream(stream));\n        return runner;\n    }\n    async _fromReadableStream(readableStream, options) {\n        const signal = options?.signal;\n        if (signal) {\n            if (signal.aborted)\n                this.controller.abort();\n            signal.addEventListener('abort', () => this.controller.abort());\n        }\n        this._connected();\n        const stream = _streaming_mjs__WEBPACK_IMPORTED_MODULE_1__.Stream.fromReadableStream(readableStream, this.controller);\n        for await (const event of stream) {\n            __classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_addEvent).call(this, event);\n        }\n        if (stream.controller.signal?.aborted) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_2__.APIUserAbortError();\n        }\n        return this._addRun(__classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_endRequest).call(this));\n    }\n    toReadableStream() {\n        const stream = new _streaming_mjs__WEBPACK_IMPORTED_MODULE_1__.Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n        return stream.toReadableStream();\n    }\n    static createToolAssistantStream(threadId, runId, runs, params, options) {\n        const runner = new AssistantStream();\n        runner._run(() => runner._runToolAssistantStream(threadId, runId, runs, params, {\n            ...options,\n            headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n        }));\n        return runner;\n    }\n    async _createToolAssistantStream(run, threadId, runId, params, options) {\n        const signal = options?.signal;\n        if (signal) {\n            if (signal.aborted)\n                this.controller.abort();\n            signal.addEventListener('abort', () => this.controller.abort());\n        }\n        const body = { ...params, stream: true };\n        const stream = await run.submitToolOutputs(threadId, runId, body, {\n            ...options,\n            signal: this.controller.signal,\n        });\n        this._connected();\n        for await (const event of stream) {\n            __classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_addEvent).call(this, event);\n        }\n        if (stream.controller.signal?.aborted) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_2__.APIUserAbortError();\n        }\n        return this._addRun(__classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_endRequest).call(this));\n    }\n    static createThreadAssistantStream(params, thread, options) {\n        const runner = new AssistantStream();\n        runner._run(() => runner._threadAssistantStream(params, thread, {\n            ...options,\n            headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n        }));\n        return runner;\n    }\n    static createAssistantStream(threadId, runs, params, options) {\n        const runner = new AssistantStream();\n        runner._run(() => runner._runAssistantStream(threadId, runs, params, {\n            ...options,\n            headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n        }));\n        return runner;\n    }\n    currentEvent() {\n        return __classPrivateFieldGet(this, _AssistantStream_currentEvent, \"f\");\n    }\n    currentRun() {\n        return __classPrivateFieldGet(this, _AssistantStream_currentRunSnapshot, \"f\");\n    }\n    currentMessageSnapshot() {\n        return __classPrivateFieldGet(this, _AssistantStream_messageSnapshot, \"f\");\n    }\n    currentRunStepSnapshot() {\n        return __classPrivateFieldGet(this, _AssistantStream_currentRunStepSnapshot, \"f\");\n    }\n    async finalRunSteps() {\n        await this.done();\n        return Object.values(__classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, \"f\"));\n    }\n    async finalMessages() {\n        await this.done();\n        return Object.values(__classPrivateFieldGet(this, _AssistantStream_messageSnapshots, \"f\"));\n    }\n    async finalRun() {\n        await this.done();\n        if (!__classPrivateFieldGet(this, _AssistantStream_finalRun, \"f\"))\n            throw Error('Final run was not received.');\n        return __classPrivateFieldGet(this, _AssistantStream_finalRun, \"f\");\n    }\n    async _createThreadAssistantStream(thread, params, options) {\n        const signal = options?.signal;\n        if (signal) {\n            if (signal.aborted)\n                this.controller.abort();\n            signal.addEventListener('abort', () => this.controller.abort());\n        }\n        const body = { ...params, stream: true };\n        const stream = await thread.createAndRun(body, { ...options, signal: this.controller.signal });\n        this._connected();\n        for await (const event of stream) {\n            __classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_addEvent).call(this, event);\n        }\n        if (stream.controller.signal?.aborted) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_2__.APIUserAbortError();\n        }\n        return this._addRun(__classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_endRequest).call(this));\n    }\n    async _createAssistantStream(run, threadId, params, options) {\n        const signal = options?.signal;\n        if (signal) {\n            if (signal.aborted)\n                this.controller.abort();\n            signal.addEventListener('abort', () => this.controller.abort());\n        }\n        const body = { ...params, stream: true };\n        const stream = await run.create(threadId, body, { ...options, signal: this.controller.signal });\n        this._connected();\n        for await (const event of stream) {\n            __classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_addEvent).call(this, event);\n        }\n        if (stream.controller.signal?.aborted) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_2__.APIUserAbortError();\n        }\n        return this._addRun(__classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_endRequest).call(this));\n    }\n    static accumulateDelta(acc, delta) {\n        for (const [key, deltaValue] of Object.entries(delta)) {\n            if (!acc.hasOwnProperty(key)) {\n                acc[key] = deltaValue;\n                continue;\n            }\n            let accValue = acc[key];\n            if (accValue === null || accValue === undefined) {\n                acc[key] = deltaValue;\n                continue;\n            }\n            // We don't accumulate these special properties\n            if (key === 'index' || key === 'type') {\n                acc[key] = deltaValue;\n                continue;\n            }\n            // Type-specific accumulation logic\n            if (typeof accValue === 'string' && typeof deltaValue === 'string') {\n                accValue += deltaValue;\n            }\n            else if (typeof accValue === 'number' && typeof deltaValue === 'number') {\n                accValue += deltaValue;\n            }\n            else if (_core_mjs__WEBPACK_IMPORTED_MODULE_3__.isObj(accValue) && _core_mjs__WEBPACK_IMPORTED_MODULE_3__.isObj(deltaValue)) {\n                accValue = this.accumulateDelta(accValue, deltaValue);\n            }\n            else if (Array.isArray(accValue) && Array.isArray(deltaValue)) {\n                if (accValue.every((x) => typeof x === 'string' || typeof x === 'number')) {\n                    accValue.push(...deltaValue); // Use spread syntax for efficient addition\n                    continue;\n                }\n                for (const deltaEntry of deltaValue) {\n                    if (!_core_mjs__WEBPACK_IMPORTED_MODULE_3__.isObj(deltaEntry)) {\n                        throw new Error(`Expected array delta entry to be an object but got: ${deltaEntry}`);\n                    }\n                    const index = deltaEntry['index'];\n                    if (index == null) {\n                        console.error(deltaEntry);\n                        throw new Error('Expected array delta entry to have an `index` property');\n                    }\n                    if (typeof index !== 'number') {\n                        throw new Error(`Expected array delta entry \\`index\\` property to be a number but got ${index}`);\n                    }\n                    const accEntry = accValue[index];\n                    if (accEntry == null) {\n                        accValue.push(deltaEntry);\n                    }\n                    else {\n                        accValue[index] = this.accumulateDelta(accEntry, deltaEntry);\n                    }\n                }\n                continue;\n            }\n            else {\n                throw Error(`Unhandled record type: ${key}, deltaValue: ${deltaValue}, accValue: ${accValue}`);\n            }\n            acc[key] = accValue;\n        }\n        return acc;\n    }\n    _addRun(run) {\n        return run;\n    }\n    async _threadAssistantStream(params, thread, options) {\n        return await this._createThreadAssistantStream(thread, params, options);\n    }\n    async _runAssistantStream(threadId, runs, params, options) {\n        return await this._createAssistantStream(runs, threadId, params, options);\n    }\n    async _runToolAssistantStream(threadId, runId, runs, params, options) {\n        return await this._createToolAssistantStream(runs, threadId, runId, params, options);\n    }\n}\n_AssistantStream_addEvent = function _AssistantStream_addEvent(event) {\n    if (this.ended)\n        return;\n    __classPrivateFieldSet(this, _AssistantStream_currentEvent, event, \"f\");\n    __classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_handleEvent).call(this, event);\n    switch (event.event) {\n        case 'thread.created':\n            //No action on this event.\n            break;\n        case 'thread.run.created':\n        case 'thread.run.queued':\n        case 'thread.run.in_progress':\n        case 'thread.run.requires_action':\n        case 'thread.run.completed':\n        case 'thread.run.incomplete':\n        case 'thread.run.failed':\n        case 'thread.run.cancelling':\n        case 'thread.run.cancelled':\n        case 'thread.run.expired':\n            __classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_handleRun).call(this, event);\n            break;\n        case 'thread.run.step.created':\n        case 'thread.run.step.in_progress':\n        case 'thread.run.step.delta':\n        case 'thread.run.step.completed':\n        case 'thread.run.step.failed':\n        case 'thread.run.step.cancelled':\n        case 'thread.run.step.expired':\n            __classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_handleRunStep).call(this, event);\n            break;\n        case 'thread.message.created':\n        case 'thread.message.in_progress':\n        case 'thread.message.delta':\n        case 'thread.message.completed':\n        case 'thread.message.incomplete':\n            __classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_handleMessage).call(this, event);\n            break;\n        case 'error':\n            //This is included for completeness, but errors are processed in the SSE event processing so this should not occur\n            throw new Error('Encountered an error event in event processing - errors should be processed earlier');\n        default:\n            assertNever(event);\n    }\n}, _AssistantStream_endRequest = function _AssistantStream_endRequest() {\n    if (this.ended) {\n        throw new _error_mjs__WEBPACK_IMPORTED_MODULE_2__.OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n    if (!__classPrivateFieldGet(this, _AssistantStream_finalRun, \"f\"))\n        throw Error('Final run has not been received');\n    return __classPrivateFieldGet(this, _AssistantStream_finalRun, \"f\");\n}, _AssistantStream_handleMessage = function _AssistantStream_handleMessage(event) {\n    const [accumulatedMessage, newContent] = __classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_accumulateMessage).call(this, event, __classPrivateFieldGet(this, _AssistantStream_messageSnapshot, \"f\"));\n    __classPrivateFieldSet(this, _AssistantStream_messageSnapshot, accumulatedMessage, \"f\");\n    __classPrivateFieldGet(this, _AssistantStream_messageSnapshots, \"f\")[accumulatedMessage.id] = accumulatedMessage;\n    for (const content of newContent) {\n        const snapshotContent = accumulatedMessage.content[content.index];\n        if (snapshotContent?.type == 'text') {\n            this._emit('textCreated', snapshotContent.text);\n        }\n    }\n    switch (event.event) {\n        case 'thread.message.created':\n            this._emit('messageCreated', event.data);\n            break;\n        case 'thread.message.in_progress':\n            break;\n        case 'thread.message.delta':\n            this._emit('messageDelta', event.data.delta, accumulatedMessage);\n            if (event.data.delta.content) {\n                for (const content of event.data.delta.content) {\n                    //If it is text delta, emit a text delta event\n                    if (content.type == 'text' && content.text) {\n                        let textDelta = content.text;\n                        let snapshot = accumulatedMessage.content[content.index];\n                        if (snapshot && snapshot.type == 'text') {\n                            this._emit('textDelta', textDelta, snapshot.text);\n                        }\n                        else {\n                            throw Error('The snapshot associated with this text delta is not text or missing');\n                        }\n                    }\n                    if (content.index != __classPrivateFieldGet(this, _AssistantStream_currentContentIndex, \"f\")) {\n                        //See if we have in progress content\n                        if (__classPrivateFieldGet(this, _AssistantStream_currentContent, \"f\")) {\n                            switch (__classPrivateFieldGet(this, _AssistantStream_currentContent, \"f\").type) {\n                                case 'text':\n                                    this._emit('textDone', __classPrivateFieldGet(this, _AssistantStream_currentContent, \"f\").text, __classPrivateFieldGet(this, _AssistantStream_messageSnapshot, \"f\"));\n                                    break;\n                                case 'image_file':\n                                    this._emit('imageFileDone', __classPrivateFieldGet(this, _AssistantStream_currentContent, \"f\").image_file, __classPrivateFieldGet(this, _AssistantStream_messageSnapshot, \"f\"));\n                                    break;\n                            }\n                        }\n                        __classPrivateFieldSet(this, _AssistantStream_currentContentIndex, content.index, \"f\");\n                    }\n                    __classPrivateFieldSet(this, _AssistantStream_currentContent, accumulatedMessage.content[content.index], \"f\");\n                }\n            }\n            break;\n        case 'thread.message.completed':\n        case 'thread.message.incomplete':\n            //We emit the latest content we were working on on completion (including incomplete)\n            if (__classPrivateFieldGet(this, _AssistantStream_currentContentIndex, \"f\") !== undefined) {\n                const currentContent = event.data.content[__classPrivateFieldGet(this, _AssistantStream_currentContentIndex, \"f\")];\n                if (currentContent) {\n                    switch (currentContent.type) {\n                        case 'image_file':\n                            this._emit('imageFileDone', currentContent.image_file, __classPrivateFieldGet(this, _AssistantStream_messageSnapshot, \"f\"));\n                            break;\n                        case 'text':\n                            this._emit('textDone', currentContent.text, __classPrivateFieldGet(this, _AssistantStream_messageSnapshot, \"f\"));\n                            break;\n                    }\n                }\n            }\n            if (__classPrivateFieldGet(this, _AssistantStream_messageSnapshot, \"f\")) {\n                this._emit('messageDone', event.data);\n            }\n            __classPrivateFieldSet(this, _AssistantStream_messageSnapshot, undefined, \"f\");\n    }\n}, _AssistantStream_handleRunStep = function _AssistantStream_handleRunStep(event) {\n    const accumulatedRunStep = __classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_accumulateRunStep).call(this, event);\n    __classPrivateFieldSet(this, _AssistantStream_currentRunStepSnapshot, accumulatedRunStep, \"f\");\n    switch (event.event) {\n        case 'thread.run.step.created':\n            this._emit('runStepCreated', event.data);\n            break;\n        case 'thread.run.step.delta':\n            const delta = event.data.delta;\n            if (delta.step_details &&\n                delta.step_details.type == 'tool_calls' &&\n                delta.step_details.tool_calls &&\n                accumulatedRunStep.step_details.type == 'tool_calls') {\n                for (const toolCall of delta.step_details.tool_calls) {\n                    if (toolCall.index == __classPrivateFieldGet(this, _AssistantStream_currentToolCallIndex, \"f\")) {\n                        this._emit('toolCallDelta', toolCall, accumulatedRunStep.step_details.tool_calls[toolCall.index]);\n                    }\n                    else {\n                        if (__classPrivateFieldGet(this, _AssistantStream_currentToolCall, \"f\")) {\n                            this._emit('toolCallDone', __classPrivateFieldGet(this, _AssistantStream_currentToolCall, \"f\"));\n                        }\n                        __classPrivateFieldSet(this, _AssistantStream_currentToolCallIndex, toolCall.index, \"f\");\n                        __classPrivateFieldSet(this, _AssistantStream_currentToolCall, accumulatedRunStep.step_details.tool_calls[toolCall.index], \"f\");\n                        if (__classPrivateFieldGet(this, _AssistantStream_currentToolCall, \"f\"))\n                            this._emit('toolCallCreated', __classPrivateFieldGet(this, _AssistantStream_currentToolCall, \"f\"));\n                    }\n                }\n            }\n            this._emit('runStepDelta', event.data.delta, accumulatedRunStep);\n            break;\n        case 'thread.run.step.completed':\n        case 'thread.run.step.failed':\n        case 'thread.run.step.cancelled':\n        case 'thread.run.step.expired':\n            __classPrivateFieldSet(this, _AssistantStream_currentRunStepSnapshot, undefined, \"f\");\n            const details = event.data.step_details;\n            if (details.type == 'tool_calls') {\n                if (__classPrivateFieldGet(this, _AssistantStream_currentToolCall, \"f\")) {\n                    this._emit('toolCallDone', __classPrivateFieldGet(this, _AssistantStream_currentToolCall, \"f\"));\n                    __classPrivateFieldSet(this, _AssistantStream_currentToolCall, undefined, \"f\");\n                }\n            }\n            this._emit('runStepDone', event.data, accumulatedRunStep);\n            break;\n        case 'thread.run.step.in_progress':\n            break;\n    }\n}, _AssistantStream_handleEvent = function _AssistantStream_handleEvent(event) {\n    __classPrivateFieldGet(this, _AssistantStream_events, \"f\").push(event);\n    this._emit('event', event);\n}, _AssistantStream_accumulateRunStep = function _AssistantStream_accumulateRunStep(event) {\n    switch (event.event) {\n        case 'thread.run.step.created':\n            __classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, \"f\")[event.data.id] = event.data;\n            return event.data;\n        case 'thread.run.step.delta':\n            let snapshot = __classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, \"f\")[event.data.id];\n            if (!snapshot) {\n                throw Error('Received a RunStepDelta before creation of a snapshot');\n            }\n            let data = event.data;\n            if (data.delta) {\n                const accumulated = AssistantStream.accumulateDelta(snapshot, data.delta);\n                __classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, \"f\")[event.data.id] = accumulated;\n            }\n            return __classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, \"f\")[event.data.id];\n        case 'thread.run.step.completed':\n        case 'thread.run.step.failed':\n        case 'thread.run.step.cancelled':\n        case 'thread.run.step.expired':\n        case 'thread.run.step.in_progress':\n            __classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, \"f\")[event.data.id] = event.data;\n            break;\n    }\n    if (__classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, \"f\")[event.data.id])\n        return __classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, \"f\")[event.data.id];\n    throw new Error('No snapshot available');\n}, _AssistantStream_accumulateMessage = function _AssistantStream_accumulateMessage(event, snapshot) {\n    let newContent = [];\n    switch (event.event) {\n        case 'thread.message.created':\n            //On creation the snapshot is just the initial message\n            return [event.data, newContent];\n        case 'thread.message.delta':\n            if (!snapshot) {\n                throw Error('Received a delta with no existing snapshot (there should be one from message creation)');\n            }\n            let data = event.data;\n            //If this delta does not have content, nothing to process\n            if (data.delta.content) {\n                for (const contentElement of data.delta.content) {\n                    if (contentElement.index in snapshot.content) {\n                        let currentContent = snapshot.content[contentElement.index];\n                        snapshot.content[contentElement.index] = __classPrivateFieldGet(this, _AssistantStream_instances, \"m\", _AssistantStream_accumulateContent).call(this, contentElement, currentContent);\n                    }\n                    else {\n                        snapshot.content[contentElement.index] = contentElement;\n                        // This is a new element\n                        newContent.push(contentElement);\n                    }\n                }\n            }\n            return [snapshot, newContent];\n        case 'thread.message.in_progress':\n        case 'thread.message.completed':\n        case 'thread.message.incomplete':\n            //No changes on other thread events\n            if (snapshot) {\n                return [snapshot, newContent];\n            }\n            else {\n                throw Error('Received thread message event with no existing snapshot');\n            }\n    }\n    throw Error('Tried to accumulate a non-message event');\n}, _AssistantStream_accumulateContent = function _AssistantStream_accumulateContent(contentElement, currentContent) {\n    return AssistantStream.accumulateDelta(currentContent, contentElement);\n}, _AssistantStream_handleRun = function _AssistantStream_handleRun(event) {\n    __classPrivateFieldSet(this, _AssistantStream_currentRunSnapshot, event.data, \"f\");\n    switch (event.event) {\n        case 'thread.run.created':\n            break;\n        case 'thread.run.queued':\n            break;\n        case 'thread.run.in_progress':\n            break;\n        case 'thread.run.requires_action':\n        case 'thread.run.cancelled':\n        case 'thread.run.failed':\n        case 'thread.run.completed':\n        case 'thread.run.expired':\n            __classPrivateFieldSet(this, _AssistantStream_finalRun, event.data, \"f\");\n            if (__classPrivateFieldGet(this, _AssistantStream_currentToolCall, \"f\")) {\n                this._emit('toolCallDone', __classPrivateFieldGet(this, _AssistantStream_currentToolCall, \"f\"));\n                __classPrivateFieldSet(this, _AssistantStream_currentToolCall, undefined, \"f\");\n            }\n            break;\n        case 'thread.run.cancelling':\n            break;\n    }\n};\nfunction assertNever(_x) { }\n//# sourceMappingURL=AssistantStream.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/lib/AssistantStream.mjs?");

/***/ }),

/***/ "./node_modules/openai/lib/ChatCompletionRunner.mjs":
/*!**********************************************************!*\
  !*** ./node_modules/openai/lib/ChatCompletionRunner.mjs ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ChatCompletionRunner: () => (/* binding */ ChatCompletionRunner)\n/* harmony export */ });\n/* harmony import */ var _AbstractChatCompletionRunner_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AbstractChatCompletionRunner.mjs */ \"./node_modules/openai/lib/AbstractChatCompletionRunner.mjs\");\n/* harmony import */ var _chatCompletionUtils_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./chatCompletionUtils.mjs */ \"./node_modules/openai/lib/chatCompletionUtils.mjs\");\n\n\nclass ChatCompletionRunner extends _AbstractChatCompletionRunner_mjs__WEBPACK_IMPORTED_MODULE_0__.AbstractChatCompletionRunner {\n    /** @deprecated - please use `runTools` instead. */\n    static runFunctions(client, params, options) {\n        const runner = new ChatCompletionRunner();\n        const opts = {\n            ...options,\n            headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runFunctions' },\n        };\n        runner._run(() => runner._runFunctions(client, params, opts));\n        return runner;\n    }\n    static runTools(client, params, options) {\n        const runner = new ChatCompletionRunner();\n        const opts = {\n            ...options,\n            headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n        };\n        runner._run(() => runner._runTools(client, params, opts));\n        return runner;\n    }\n    _addMessage(message, emit = true) {\n        super._addMessage(message, emit);\n        if ((0,_chatCompletionUtils_mjs__WEBPACK_IMPORTED_MODULE_1__.isAssistantMessage)(message) && message.content) {\n            this._emit('content', message.content);\n        }\n    }\n}\n//# sourceMappingURL=ChatCompletionRunner.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/lib/ChatCompletionRunner.mjs?");

/***/ }),

/***/ "./node_modules/openai/lib/ChatCompletionStream.mjs":
/*!**********************************************************!*\
  !*** ./node_modules/openai/lib/ChatCompletionStream.mjs ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ChatCompletionStream: () => (/* binding */ ChatCompletionStream)\n/* harmony export */ });\n/* harmony import */ var _error_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../error.mjs */ \"./node_modules/openai/error.mjs\");\n/* harmony import */ var _AbstractChatCompletionRunner_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AbstractChatCompletionRunner.mjs */ \"./node_modules/openai/lib/AbstractChatCompletionRunner.mjs\");\n/* harmony import */ var _streaming_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../streaming.mjs */ \"./node_modules/openai/streaming.mjs\");\n/* harmony import */ var _lib_parser_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../lib/parser.mjs */ \"./node_modules/openai/lib/parser.mjs\");\n/* harmony import */ var _vendor_partial_json_parser_parser_mjs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../_vendor/partial-json-parser/parser.mjs */ \"./node_modules/openai/_vendor/partial-json-parser/parser.mjs\");\nvar __classPrivateFieldSet = (undefined && undefined.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {\n    if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n    return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n};\nvar __classPrivateFieldGet = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar _ChatCompletionStream_instances, _ChatCompletionStream_params, _ChatCompletionStream_choiceEventStates, _ChatCompletionStream_currentChatCompletionSnapshot, _ChatCompletionStream_beginRequest, _ChatCompletionStream_getChoiceEventState, _ChatCompletionStream_addChunk, _ChatCompletionStream_emitToolCallDoneEvent, _ChatCompletionStream_emitContentDoneEvents, _ChatCompletionStream_endRequest, _ChatCompletionStream_getAutoParseableResponseFormat, _ChatCompletionStream_accumulateChatCompletion;\n\n\n\n\n\nclass ChatCompletionStream extends _AbstractChatCompletionRunner_mjs__WEBPACK_IMPORTED_MODULE_0__.AbstractChatCompletionRunner {\n    constructor(params) {\n        super();\n        _ChatCompletionStream_instances.add(this);\n        _ChatCompletionStream_params.set(this, void 0);\n        _ChatCompletionStream_choiceEventStates.set(this, void 0);\n        _ChatCompletionStream_currentChatCompletionSnapshot.set(this, void 0);\n        __classPrivateFieldSet(this, _ChatCompletionStream_params, params, \"f\");\n        __classPrivateFieldSet(this, _ChatCompletionStream_choiceEventStates, [], \"f\");\n    }\n    get currentChatCompletionSnapshot() {\n        return __classPrivateFieldGet(this, _ChatCompletionStream_currentChatCompletionSnapshot, \"f\");\n    }\n    /**\n     * Intended for use on the frontend, consuming a stream produced with\n     * `.toReadableStream()` on the backend.\n     *\n     * Note that messages sent to the model do not appear in `.on('message')`\n     * in this context.\n     */\n    static fromReadableStream(stream) {\n        const runner = new ChatCompletionStream(null);\n        runner._run(() => runner._fromReadableStream(stream));\n        return runner;\n    }\n    static createChatCompletion(client, params, options) {\n        const runner = new ChatCompletionStream(params);\n        runner._run(() => runner._runChatCompletion(client, { ...params, stream: true }, { ...options, headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' } }));\n        return runner;\n    }\n    async _createChatCompletion(client, params, options) {\n        super._createChatCompletion;\n        const signal = options?.signal;\n        if (signal) {\n            if (signal.aborted)\n                this.controller.abort();\n            signal.addEventListener('abort', () => this.controller.abort());\n        }\n        __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_beginRequest).call(this);\n        const stream = await client.chat.completions.create({ ...params, stream: true }, { ...options, signal: this.controller.signal });\n        this._connected();\n        for await (const chunk of stream) {\n            __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_addChunk).call(this, chunk);\n        }\n        if (stream.controller.signal?.aborted) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.APIUserAbortError();\n        }\n        return this._addChatCompletion(__classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_endRequest).call(this));\n    }\n    async _fromReadableStream(readableStream, options) {\n        const signal = options?.signal;\n        if (signal) {\n            if (signal.aborted)\n                this.controller.abort();\n            signal.addEventListener('abort', () => this.controller.abort());\n        }\n        __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_beginRequest).call(this);\n        this._connected();\n        const stream = _streaming_mjs__WEBPACK_IMPORTED_MODULE_2__.Stream.fromReadableStream(readableStream, this.controller);\n        let chatId;\n        for await (const chunk of stream) {\n            if (chatId && chatId !== chunk.id) {\n                // A new request has been made.\n                this._addChatCompletion(__classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_endRequest).call(this));\n            }\n            __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_addChunk).call(this, chunk);\n            chatId = chunk.id;\n        }\n        if (stream.controller.signal?.aborted) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.APIUserAbortError();\n        }\n        return this._addChatCompletion(__classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_endRequest).call(this));\n    }\n    [(_ChatCompletionStream_params = new WeakMap(), _ChatCompletionStream_choiceEventStates = new WeakMap(), _ChatCompletionStream_currentChatCompletionSnapshot = new WeakMap(), _ChatCompletionStream_instances = new WeakSet(), _ChatCompletionStream_beginRequest = function _ChatCompletionStream_beginRequest() {\n        if (this.ended)\n            return;\n        __classPrivateFieldSet(this, _ChatCompletionStream_currentChatCompletionSnapshot, undefined, \"f\");\n    }, _ChatCompletionStream_getChoiceEventState = function _ChatCompletionStream_getChoiceEventState(choice) {\n        let state = __classPrivateFieldGet(this, _ChatCompletionStream_choiceEventStates, \"f\")[choice.index];\n        if (state) {\n            return state;\n        }\n        state = {\n            content_done: false,\n            refusal_done: false,\n            logprobs_content_done: false,\n            logprobs_refusal_done: false,\n            done_tool_calls: new Set(),\n            current_tool_call_index: null,\n        };\n        __classPrivateFieldGet(this, _ChatCompletionStream_choiceEventStates, \"f\")[choice.index] = state;\n        return state;\n    }, _ChatCompletionStream_addChunk = function _ChatCompletionStream_addChunk(chunk) {\n        if (this.ended)\n            return;\n        const completion = __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_accumulateChatCompletion).call(this, chunk);\n        this._emit('chunk', chunk, completion);\n        for (const choice of chunk.choices) {\n            const choiceSnapshot = completion.choices[choice.index];\n            if (choice.delta.content != null &&\n                choiceSnapshot.message?.role === 'assistant' &&\n                choiceSnapshot.message?.content) {\n                this._emit('content', choice.delta.content, choiceSnapshot.message.content);\n                this._emit('content.delta', {\n                    delta: choice.delta.content,\n                    snapshot: choiceSnapshot.message.content,\n                    parsed: choiceSnapshot.message.parsed,\n                });\n            }\n            if (choice.delta.refusal != null &&\n                choiceSnapshot.message?.role === 'assistant' &&\n                choiceSnapshot.message?.refusal) {\n                this._emit('refusal.delta', {\n                    delta: choice.delta.refusal,\n                    snapshot: choiceSnapshot.message.refusal,\n                });\n            }\n            if (choice.logprobs?.content != null && choiceSnapshot.message?.role === 'assistant') {\n                this._emit('logprobs.content.delta', {\n                    content: choice.logprobs?.content,\n                    snapshot: choiceSnapshot.logprobs?.content ?? [],\n                });\n            }\n            if (choice.logprobs?.refusal != null && choiceSnapshot.message?.role === 'assistant') {\n                this._emit('logprobs.refusal.delta', {\n                    refusal: choice.logprobs?.refusal,\n                    snapshot: choiceSnapshot.logprobs?.refusal ?? [],\n                });\n            }\n            const state = __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_getChoiceEventState).call(this, choiceSnapshot);\n            if (choiceSnapshot.finish_reason) {\n                __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_emitContentDoneEvents).call(this, choiceSnapshot);\n                if (state.current_tool_call_index != null) {\n                    __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_emitToolCallDoneEvent).call(this, choiceSnapshot, state.current_tool_call_index);\n                }\n            }\n            for (const toolCall of choice.delta.tool_calls ?? []) {\n                if (state.current_tool_call_index !== toolCall.index) {\n                    __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_emitContentDoneEvents).call(this, choiceSnapshot);\n                    // new tool call started, the previous one is done\n                    if (state.current_tool_call_index != null) {\n                        __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_emitToolCallDoneEvent).call(this, choiceSnapshot, state.current_tool_call_index);\n                    }\n                }\n                state.current_tool_call_index = toolCall.index;\n            }\n            for (const toolCallDelta of choice.delta.tool_calls ?? []) {\n                const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallDelta.index];\n                if (!toolCallSnapshot?.type) {\n                    continue;\n                }\n                if (toolCallSnapshot?.type === 'function') {\n                    this._emit('tool_calls.function.arguments.delta', {\n                        name: toolCallSnapshot.function?.name,\n                        index: toolCallDelta.index,\n                        arguments: toolCallSnapshot.function.arguments,\n                        parsed_arguments: toolCallSnapshot.function.parsed_arguments,\n                        arguments_delta: toolCallDelta.function?.arguments ?? '',\n                    });\n                }\n                else {\n                    assertNever(toolCallSnapshot?.type);\n                }\n            }\n        }\n    }, _ChatCompletionStream_emitToolCallDoneEvent = function _ChatCompletionStream_emitToolCallDoneEvent(choiceSnapshot, toolCallIndex) {\n        const state = __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_getChoiceEventState).call(this, choiceSnapshot);\n        if (state.done_tool_calls.has(toolCallIndex)) {\n            // we've already fired the done event\n            return;\n        }\n        const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallIndex];\n        if (!toolCallSnapshot) {\n            throw new Error('no tool call snapshot');\n        }\n        if (!toolCallSnapshot.type) {\n            throw new Error('tool call snapshot missing `type`');\n        }\n        if (toolCallSnapshot.type === 'function') {\n            const inputTool = __classPrivateFieldGet(this, _ChatCompletionStream_params, \"f\")?.tools?.find((tool) => tool.type === 'function' && tool.function.name === toolCallSnapshot.function.name);\n            this._emit('tool_calls.function.arguments.done', {\n                name: toolCallSnapshot.function.name,\n                index: toolCallIndex,\n                arguments: toolCallSnapshot.function.arguments,\n                parsed_arguments: (0,_lib_parser_mjs__WEBPACK_IMPORTED_MODULE_3__.isAutoParsableTool)(inputTool) ? inputTool.$parseRaw(toolCallSnapshot.function.arguments)\n                    : inputTool?.function.strict ? JSON.parse(toolCallSnapshot.function.arguments)\n                        : null,\n            });\n        }\n        else {\n            assertNever(toolCallSnapshot.type);\n        }\n    }, _ChatCompletionStream_emitContentDoneEvents = function _ChatCompletionStream_emitContentDoneEvents(choiceSnapshot) {\n        const state = __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_getChoiceEventState).call(this, choiceSnapshot);\n        if (choiceSnapshot.message.content && !state.content_done) {\n            state.content_done = true;\n            const responseFormat = __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_getAutoParseableResponseFormat).call(this);\n            this._emit('content.done', {\n                content: choiceSnapshot.message.content,\n                parsed: responseFormat ? responseFormat.$parseRaw(choiceSnapshot.message.content) : null,\n            });\n        }\n        if (choiceSnapshot.message.refusal && !state.refusal_done) {\n            state.refusal_done = true;\n            this._emit('refusal.done', { refusal: choiceSnapshot.message.refusal });\n        }\n        if (choiceSnapshot.logprobs?.content && !state.logprobs_content_done) {\n            state.logprobs_content_done = true;\n            this._emit('logprobs.content.done', { content: choiceSnapshot.logprobs.content });\n        }\n        if (choiceSnapshot.logprobs?.refusal && !state.logprobs_refusal_done) {\n            state.logprobs_refusal_done = true;\n            this._emit('logprobs.refusal.done', { refusal: choiceSnapshot.logprobs.refusal });\n        }\n    }, _ChatCompletionStream_endRequest = function _ChatCompletionStream_endRequest() {\n        if (this.ended) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(`stream has ended, this shouldn't happen`);\n        }\n        const snapshot = __classPrivateFieldGet(this, _ChatCompletionStream_currentChatCompletionSnapshot, \"f\");\n        if (!snapshot) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(`request ended without sending any chunks`);\n        }\n        __classPrivateFieldSet(this, _ChatCompletionStream_currentChatCompletionSnapshot, undefined, \"f\");\n        __classPrivateFieldSet(this, _ChatCompletionStream_choiceEventStates, [], \"f\");\n        return finalizeChatCompletion(snapshot, __classPrivateFieldGet(this, _ChatCompletionStream_params, \"f\"));\n    }, _ChatCompletionStream_getAutoParseableResponseFormat = function _ChatCompletionStream_getAutoParseableResponseFormat() {\n        const responseFormat = __classPrivateFieldGet(this, _ChatCompletionStream_params, \"f\")?.response_format;\n        if ((0,_lib_parser_mjs__WEBPACK_IMPORTED_MODULE_3__.isAutoParsableResponseFormat)(responseFormat)) {\n            return responseFormat;\n        }\n        return null;\n    }, _ChatCompletionStream_accumulateChatCompletion = function _ChatCompletionStream_accumulateChatCompletion(chunk) {\n        var _a, _b, _c, _d;\n        let snapshot = __classPrivateFieldGet(this, _ChatCompletionStream_currentChatCompletionSnapshot, \"f\");\n        const { choices, ...rest } = chunk;\n        if (!snapshot) {\n            snapshot = __classPrivateFieldSet(this, _ChatCompletionStream_currentChatCompletionSnapshot, {\n                ...rest,\n                choices: [],\n            }, \"f\");\n        }\n        else {\n            Object.assign(snapshot, rest);\n        }\n        for (const { delta, finish_reason, index, logprobs = null, ...other } of chunk.choices) {\n            let choice = snapshot.choices[index];\n            if (!choice) {\n                choice = snapshot.choices[index] = { finish_reason, index, message: {}, logprobs, ...other };\n            }\n            if (logprobs) {\n                if (!choice.logprobs) {\n                    choice.logprobs = Object.assign({}, logprobs);\n                }\n                else {\n                    const { content, refusal, ...rest } = logprobs;\n                    assertIsEmpty(rest);\n                    Object.assign(choice.logprobs, rest);\n                    if (content) {\n                        (_a = choice.logprobs).content ?? (_a.content = []);\n                        choice.logprobs.content.push(...content);\n                    }\n                    if (refusal) {\n                        (_b = choice.logprobs).refusal ?? (_b.refusal = []);\n                        choice.logprobs.refusal.push(...refusal);\n                    }\n                }\n            }\n            if (finish_reason) {\n                choice.finish_reason = finish_reason;\n                if (__classPrivateFieldGet(this, _ChatCompletionStream_params, \"f\") && (0,_lib_parser_mjs__WEBPACK_IMPORTED_MODULE_3__.hasAutoParseableInput)(__classPrivateFieldGet(this, _ChatCompletionStream_params, \"f\"))) {\n                    if (finish_reason === 'length') {\n                        throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.LengthFinishReasonError();\n                    }\n                    if (finish_reason === 'content_filter') {\n                        throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.ContentFilterFinishReasonError();\n                    }\n                }\n            }\n            Object.assign(choice, other);\n            if (!delta)\n                continue; // Shouldn't happen; just in case.\n            const { content, refusal, function_call, role, tool_calls, ...rest } = delta;\n            assertIsEmpty(rest);\n            Object.assign(choice.message, rest);\n            if (refusal) {\n                choice.message.refusal = (choice.message.refusal || '') + refusal;\n            }\n            if (role)\n                choice.message.role = role;\n            if (function_call) {\n                if (!choice.message.function_call) {\n                    choice.message.function_call = function_call;\n                }\n                else {\n                    if (function_call.name)\n                        choice.message.function_call.name = function_call.name;\n                    if (function_call.arguments) {\n                        (_c = choice.message.function_call).arguments ?? (_c.arguments = '');\n                        choice.message.function_call.arguments += function_call.arguments;\n                    }\n                }\n            }\n            if (content) {\n                choice.message.content = (choice.message.content || '') + content;\n                if (!choice.message.refusal && __classPrivateFieldGet(this, _ChatCompletionStream_instances, \"m\", _ChatCompletionStream_getAutoParseableResponseFormat).call(this)) {\n                    choice.message.parsed = (0,_vendor_partial_json_parser_parser_mjs__WEBPACK_IMPORTED_MODULE_4__.partialParse)(choice.message.content);\n                }\n            }\n            if (tool_calls) {\n                if (!choice.message.tool_calls)\n                    choice.message.tool_calls = [];\n                for (const { index, id, type, function: fn, ...rest } of tool_calls) {\n                    const tool_call = ((_d = choice.message.tool_calls)[index] ?? (_d[index] = {}));\n                    Object.assign(tool_call, rest);\n                    if (id)\n                        tool_call.id = id;\n                    if (type)\n                        tool_call.type = type;\n                    if (fn)\n                        tool_call.function ?? (tool_call.function = { name: fn.name ?? '', arguments: '' });\n                    if (fn?.name)\n                        tool_call.function.name = fn.name;\n                    if (fn?.arguments) {\n                        tool_call.function.arguments += fn.arguments;\n                        if ((0,_lib_parser_mjs__WEBPACK_IMPORTED_MODULE_3__.shouldParseToolCall)(__classPrivateFieldGet(this, _ChatCompletionStream_params, \"f\"), tool_call)) {\n                            tool_call.function.parsed_arguments = (0,_vendor_partial_json_parser_parser_mjs__WEBPACK_IMPORTED_MODULE_4__.partialParse)(tool_call.function.arguments);\n                        }\n                    }\n                }\n            }\n        }\n        return snapshot;\n    }, Symbol.asyncIterator)]() {\n        const pushQueue = [];\n        const readQueue = [];\n        let done = false;\n        this.on('chunk', (chunk) => {\n            const reader = readQueue.shift();\n            if (reader) {\n                reader.resolve(chunk);\n            }\n            else {\n                pushQueue.push(chunk);\n            }\n        });\n        this.on('end', () => {\n            done = true;\n            for (const reader of readQueue) {\n                reader.resolve(undefined);\n            }\n            readQueue.length = 0;\n        });\n        this.on('abort', (err) => {\n            done = true;\n            for (const reader of readQueue) {\n                reader.reject(err);\n            }\n            readQueue.length = 0;\n        });\n        this.on('error', (err) => {\n            done = true;\n            for (const reader of readQueue) {\n                reader.reject(err);\n            }\n            readQueue.length = 0;\n        });\n        return {\n            next: async () => {\n                if (!pushQueue.length) {\n                    if (done) {\n                        return { value: undefined, done: true };\n                    }\n                    return new Promise((resolve, reject) => readQueue.push({ resolve, reject })).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n                }\n                const chunk = pushQueue.shift();\n                return { value: chunk, done: false };\n            },\n            return: async () => {\n                this.abort();\n                return { value: undefined, done: true };\n            },\n        };\n    }\n    toReadableStream() {\n        const stream = new _streaming_mjs__WEBPACK_IMPORTED_MODULE_2__.Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n        return stream.toReadableStream();\n    }\n}\nfunction finalizeChatCompletion(snapshot, params) {\n    const { id, choices, created, model, system_fingerprint, ...rest } = snapshot;\n    const completion = {\n        ...rest,\n        id,\n        choices: choices.map(({ message, finish_reason, index, logprobs, ...choiceRest }) => {\n            if (!finish_reason) {\n                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(`missing finish_reason for choice ${index}`);\n            }\n            const { content = null, function_call, tool_calls, ...messageRest } = message;\n            const role = message.role; // this is what we expect; in theory it could be different which would make our types a slight lie but would be fine.\n            if (!role) {\n                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(`missing role for choice ${index}`);\n            }\n            if (function_call) {\n                const { arguments: args, name } = function_call;\n                if (args == null) {\n                    throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(`missing function_call.arguments for choice ${index}`);\n                }\n                if (!name) {\n                    throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(`missing function_call.name for choice ${index}`);\n                }\n                return {\n                    ...choiceRest,\n                    message: {\n                        content,\n                        function_call: { arguments: args, name },\n                        role,\n                        refusal: message.refusal ?? null,\n                    },\n                    finish_reason,\n                    index,\n                    logprobs,\n                };\n            }\n            if (tool_calls) {\n                return {\n                    ...choiceRest,\n                    index,\n                    finish_reason,\n                    logprobs,\n                    message: {\n                        ...messageRest,\n                        role,\n                        content,\n                        refusal: message.refusal ?? null,\n                        tool_calls: tool_calls.map((tool_call, i) => {\n                            const { function: fn, type, id, ...toolRest } = tool_call;\n                            const { arguments: args, name, ...fnRest } = fn || {};\n                            if (id == null) {\n                                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(`missing choices[${index}].tool_calls[${i}].id\\n${str(snapshot)}`);\n                            }\n                            if (type == null) {\n                                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(`missing choices[${index}].tool_calls[${i}].type\\n${str(snapshot)}`);\n                            }\n                            if (name == null) {\n                                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(`missing choices[${index}].tool_calls[${i}].function.name\\n${str(snapshot)}`);\n                            }\n                            if (args == null) {\n                                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(`missing choices[${index}].tool_calls[${i}].function.arguments\\n${str(snapshot)}`);\n                            }\n                            return { ...toolRest, id, type, function: { ...fnRest, name, arguments: args } };\n                        }),\n                    },\n                };\n            }\n            return {\n                ...choiceRest,\n                message: { ...messageRest, content, role, refusal: message.refusal ?? null },\n                finish_reason,\n                index,\n                logprobs,\n            };\n        }),\n        created,\n        model,\n        object: 'chat.completion',\n        ...(system_fingerprint ? { system_fingerprint } : {}),\n    };\n    return (0,_lib_parser_mjs__WEBPACK_IMPORTED_MODULE_3__.maybeParseChatCompletion)(completion, params);\n}\nfunction str(x) {\n    return JSON.stringify(x);\n}\n/**\n * Ensures the given argument is an empty object, useful for\n * asserting that all known properties on an object have been\n * destructured.\n */\nfunction assertIsEmpty(obj) {\n    return;\n}\nfunction assertNever(_x) { }\n//# sourceMappingURL=ChatCompletionStream.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/lib/ChatCompletionStream.mjs?");

/***/ }),

/***/ "./node_modules/openai/lib/ChatCompletionStreamingRunner.mjs":
/*!*******************************************************************!*\
  !*** ./node_modules/openai/lib/ChatCompletionStreamingRunner.mjs ***!
  \*******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ChatCompletionStreamingRunner: () => (/* binding */ ChatCompletionStreamingRunner)\n/* harmony export */ });\n/* harmony import */ var _ChatCompletionStream_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ChatCompletionStream.mjs */ \"./node_modules/openai/lib/ChatCompletionStream.mjs\");\n\nclass ChatCompletionStreamingRunner extends _ChatCompletionStream_mjs__WEBPACK_IMPORTED_MODULE_0__.ChatCompletionStream {\n    static fromReadableStream(stream) {\n        const runner = new ChatCompletionStreamingRunner(null);\n        runner._run(() => runner._fromReadableStream(stream));\n        return runner;\n    }\n    /** @deprecated - please use `runTools` instead. */\n    static runFunctions(client, params, options) {\n        const runner = new ChatCompletionStreamingRunner(null);\n        const opts = {\n            ...options,\n            headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runFunctions' },\n        };\n        runner._run(() => runner._runFunctions(client, params, opts));\n        return runner;\n    }\n    static runTools(client, params, options) {\n        const runner = new ChatCompletionStreamingRunner(\n        // @ts-expect-error TODO these types are incompatible\n        params);\n        const opts = {\n            ...options,\n            headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n        };\n        runner._run(() => runner._runTools(client, params, opts));\n        return runner;\n    }\n}\n//# sourceMappingURL=ChatCompletionStreamingRunner.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/lib/ChatCompletionStreamingRunner.mjs?");

/***/ }),

/***/ "./node_modules/openai/lib/EventStream.mjs":
/*!*************************************************!*\
  !*** ./node_modules/openai/lib/EventStream.mjs ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   EventStream: () => (/* binding */ EventStream)\n/* harmony export */ });\n/* harmony import */ var _error_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../error.mjs */ \"./node_modules/openai/error.mjs\");\nvar __classPrivateFieldSet = (undefined && undefined.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {\n    if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n    return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n};\nvar __classPrivateFieldGet = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar _EventStream_instances, _EventStream_connectedPromise, _EventStream_resolveConnectedPromise, _EventStream_rejectConnectedPromise, _EventStream_endPromise, _EventStream_resolveEndPromise, _EventStream_rejectEndPromise, _EventStream_listeners, _EventStream_ended, _EventStream_errored, _EventStream_aborted, _EventStream_catchingPromiseCreated, _EventStream_handleError;\n\nclass EventStream {\n    constructor() {\n        _EventStream_instances.add(this);\n        this.controller = new AbortController();\n        _EventStream_connectedPromise.set(this, void 0);\n        _EventStream_resolveConnectedPromise.set(this, () => { });\n        _EventStream_rejectConnectedPromise.set(this, () => { });\n        _EventStream_endPromise.set(this, void 0);\n        _EventStream_resolveEndPromise.set(this, () => { });\n        _EventStream_rejectEndPromise.set(this, () => { });\n        _EventStream_listeners.set(this, {});\n        _EventStream_ended.set(this, false);\n        _EventStream_errored.set(this, false);\n        _EventStream_aborted.set(this, false);\n        _EventStream_catchingPromiseCreated.set(this, false);\n        __classPrivateFieldSet(this, _EventStream_connectedPromise, new Promise((resolve, reject) => {\n            __classPrivateFieldSet(this, _EventStream_resolveConnectedPromise, resolve, \"f\");\n            __classPrivateFieldSet(this, _EventStream_rejectConnectedPromise, reject, \"f\");\n        }), \"f\");\n        __classPrivateFieldSet(this, _EventStream_endPromise, new Promise((resolve, reject) => {\n            __classPrivateFieldSet(this, _EventStream_resolveEndPromise, resolve, \"f\");\n            __classPrivateFieldSet(this, _EventStream_rejectEndPromise, reject, \"f\");\n        }), \"f\");\n        // Don't let these promises cause unhandled rejection errors.\n        // we will manually cause an unhandled rejection error later\n        // if the user hasn't registered any error listener or called\n        // any promise-returning method.\n        __classPrivateFieldGet(this, _EventStream_connectedPromise, \"f\").catch(() => { });\n        __classPrivateFieldGet(this, _EventStream_endPromise, \"f\").catch(() => { });\n    }\n    _run(executor) {\n        // Unfortunately if we call `executor()` immediately we get runtime errors about\n        // references to `this` before the `super()` constructor call returns.\n        setTimeout(() => {\n            executor().then(() => {\n                this._emitFinal();\n                this._emit('end');\n            }, __classPrivateFieldGet(this, _EventStream_instances, \"m\", _EventStream_handleError).bind(this));\n        }, 0);\n    }\n    _connected() {\n        if (this.ended)\n            return;\n        __classPrivateFieldGet(this, _EventStream_resolveConnectedPromise, \"f\").call(this);\n        this._emit('connect');\n    }\n    get ended() {\n        return __classPrivateFieldGet(this, _EventStream_ended, \"f\");\n    }\n    get errored() {\n        return __classPrivateFieldGet(this, _EventStream_errored, \"f\");\n    }\n    get aborted() {\n        return __classPrivateFieldGet(this, _EventStream_aborted, \"f\");\n    }\n    abort() {\n        this.controller.abort();\n    }\n    /**\n     * Adds the listener function to the end of the listeners array for the event.\n     * No checks are made to see if the listener has already been added. Multiple calls passing\n     * the same combination of event and listener will result in the listener being added, and\n     * called, multiple times.\n     * @returns this ChatCompletionStream, so that calls can be chained\n     */\n    on(event, listener) {\n        const listeners = __classPrivateFieldGet(this, _EventStream_listeners, \"f\")[event] || (__classPrivateFieldGet(this, _EventStream_listeners, \"f\")[event] = []);\n        listeners.push({ listener });\n        return this;\n    }\n    /**\n     * Removes the specified listener from the listener array for the event.\n     * off() will remove, at most, one instance of a listener from the listener array. If any single\n     * listener has been added multiple times to the listener array for the specified event, then\n     * off() must be called multiple times to remove each instance.\n     * @returns this ChatCompletionStream, so that calls can be chained\n     */\n    off(event, listener) {\n        const listeners = __classPrivateFieldGet(this, _EventStream_listeners, \"f\")[event];\n        if (!listeners)\n            return this;\n        const index = listeners.findIndex((l) => l.listener === listener);\n        if (index >= 0)\n            listeners.splice(index, 1);\n        return this;\n    }\n    /**\n     * Adds a one-time listener function for the event. The next time the event is triggered,\n     * this listener is removed and then invoked.\n     * @returns this ChatCompletionStream, so that calls can be chained\n     */\n    once(event, listener) {\n        const listeners = __classPrivateFieldGet(this, _EventStream_listeners, \"f\")[event] || (__classPrivateFieldGet(this, _EventStream_listeners, \"f\")[event] = []);\n        listeners.push({ listener, once: true });\n        return this;\n    }\n    /**\n     * This is similar to `.once()`, but returns a Promise that resolves the next time\n     * the event is triggered, instead of calling a listener callback.\n     * @returns a Promise that resolves the next time given event is triggered,\n     * or rejects if an error is emitted.  (If you request the 'error' event,\n     * returns a promise that resolves with the error).\n     *\n     * Example:\n     *\n     *   const message = await stream.emitted('message') // rejects if the stream errors\n     */\n    emitted(event) {\n        return new Promise((resolve, reject) => {\n            __classPrivateFieldSet(this, _EventStream_catchingPromiseCreated, true, \"f\");\n            if (event !== 'error')\n                this.once('error', reject);\n            this.once(event, resolve);\n        });\n    }\n    async done() {\n        __classPrivateFieldSet(this, _EventStream_catchingPromiseCreated, true, \"f\");\n        await __classPrivateFieldGet(this, _EventStream_endPromise, \"f\");\n    }\n    _emit(event, ...args) {\n        // make sure we don't emit any events after end\n        if (__classPrivateFieldGet(this, _EventStream_ended, \"f\")) {\n            return;\n        }\n        if (event === 'end') {\n            __classPrivateFieldSet(this, _EventStream_ended, true, \"f\");\n            __classPrivateFieldGet(this, _EventStream_resolveEndPromise, \"f\").call(this);\n        }\n        const listeners = __classPrivateFieldGet(this, _EventStream_listeners, \"f\")[event];\n        if (listeners) {\n            __classPrivateFieldGet(this, _EventStream_listeners, \"f\")[event] = listeners.filter((l) => !l.once);\n            listeners.forEach(({ listener }) => listener(...args));\n        }\n        if (event === 'abort') {\n            const error = args[0];\n            if (!__classPrivateFieldGet(this, _EventStream_catchingPromiseCreated, \"f\") && !listeners?.length) {\n                Promise.reject(error);\n            }\n            __classPrivateFieldGet(this, _EventStream_rejectConnectedPromise, \"f\").call(this, error);\n            __classPrivateFieldGet(this, _EventStream_rejectEndPromise, \"f\").call(this, error);\n            this._emit('end');\n            return;\n        }\n        if (event === 'error') {\n            // NOTE: _emit('error', error) should only be called from #handleError().\n            const error = args[0];\n            if (!__classPrivateFieldGet(this, _EventStream_catchingPromiseCreated, \"f\") && !listeners?.length) {\n                // Trigger an unhandled rejection if the user hasn't registered any error handlers.\n                // If you are seeing stack traces here, make sure to handle errors via either:\n                // - runner.on('error', () => ...)\n                // - await runner.done()\n                // - await runner.finalChatCompletion()\n                // - etc.\n                Promise.reject(error);\n            }\n            __classPrivateFieldGet(this, _EventStream_rejectConnectedPromise, \"f\").call(this, error);\n            __classPrivateFieldGet(this, _EventStream_rejectEndPromise, \"f\").call(this, error);\n            this._emit('end');\n        }\n    }\n    _emitFinal() { }\n}\n_EventStream_connectedPromise = new WeakMap(), _EventStream_resolveConnectedPromise = new WeakMap(), _EventStream_rejectConnectedPromise = new WeakMap(), _EventStream_endPromise = new WeakMap(), _EventStream_resolveEndPromise = new WeakMap(), _EventStream_rejectEndPromise = new WeakMap(), _EventStream_listeners = new WeakMap(), _EventStream_ended = new WeakMap(), _EventStream_errored = new WeakMap(), _EventStream_aborted = new WeakMap(), _EventStream_catchingPromiseCreated = new WeakMap(), _EventStream_instances = new WeakSet(), _EventStream_handleError = function _EventStream_handleError(error) {\n    __classPrivateFieldSet(this, _EventStream_errored, true, \"f\");\n    if (error instanceof Error && error.name === 'AbortError') {\n        error = new _error_mjs__WEBPACK_IMPORTED_MODULE_0__.APIUserAbortError();\n    }\n    if (error instanceof _error_mjs__WEBPACK_IMPORTED_MODULE_0__.APIUserAbortError) {\n        __classPrivateFieldSet(this, _EventStream_aborted, true, \"f\");\n        return this._emit('abort', error);\n    }\n    if (error instanceof _error_mjs__WEBPACK_IMPORTED_MODULE_0__.OpenAIError) {\n        return this._emit('error', error);\n    }\n    if (error instanceof Error) {\n        const openAIError = new _error_mjs__WEBPACK_IMPORTED_MODULE_0__.OpenAIError(error.message);\n        // @ts-ignore\n        openAIError.cause = error;\n        return this._emit('error', openAIError);\n    }\n    return this._emit('error', new _error_mjs__WEBPACK_IMPORTED_MODULE_0__.OpenAIError(String(error)));\n};\n//# sourceMappingURL=EventStream.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/lib/EventStream.mjs?");

/***/ }),

/***/ "./node_modules/openai/lib/RunnableFunction.mjs":
/*!******************************************************!*\
  !*** ./node_modules/openai/lib/RunnableFunction.mjs ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ParsingFunction: () => (/* binding */ ParsingFunction),\n/* harmony export */   ParsingToolFunction: () => (/* binding */ ParsingToolFunction),\n/* harmony export */   isRunnableFunctionWithParse: () => (/* binding */ isRunnableFunctionWithParse)\n/* harmony export */ });\nfunction isRunnableFunctionWithParse(fn) {\n    return typeof fn.parse === 'function';\n}\n/**\n * This is helper class for passing a `function` and `parse` where the `function`\n * argument type matches the `parse` return type.\n *\n * @deprecated - please use ParsingToolFunction instead.\n */\nclass ParsingFunction {\n    constructor(input) {\n        this.function = input.function;\n        this.parse = input.parse;\n        this.parameters = input.parameters;\n        this.description = input.description;\n        this.name = input.name;\n    }\n}\n/**\n * This is helper class for passing a `function` and `parse` where the `function`\n * argument type matches the `parse` return type.\n */\nclass ParsingToolFunction {\n    constructor(input) {\n        this.type = 'function';\n        this.function = input;\n    }\n}\n//# sourceMappingURL=RunnableFunction.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/lib/RunnableFunction.mjs?");

/***/ }),

/***/ "./node_modules/openai/lib/Util.mjs":
/*!******************************************!*\
  !*** ./node_modules/openai/lib/Util.mjs ***!
  \******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   allSettledWithThrow: () => (/* binding */ allSettledWithThrow)\n/* harmony export */ });\n/**\n * Like `Promise.allSettled()` but throws an error if any promises are rejected.\n */\nconst allSettledWithThrow = async (promises) => {\n    const results = await Promise.allSettled(promises);\n    const rejected = results.filter((result) => result.status === 'rejected');\n    if (rejected.length) {\n        for (const result of rejected) {\n            console.error(result.reason);\n        }\n        throw new Error(`${rejected.length} promise(s) failed - see the above errors`);\n    }\n    // Note: TS was complaining about using `.filter().map()` here for some reason\n    const values = [];\n    for (const result of results) {\n        if (result.status === 'fulfilled') {\n            values.push(result.value);\n        }\n    }\n    return values;\n};\n//# sourceMappingURL=Util.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/lib/Util.mjs?");

/***/ }),

/***/ "./node_modules/openai/lib/chatCompletionUtils.mjs":
/*!*********************************************************!*\
  !*** ./node_modules/openai/lib/chatCompletionUtils.mjs ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   isAssistantMessage: () => (/* binding */ isAssistantMessage),\n/* harmony export */   isFunctionMessage: () => (/* binding */ isFunctionMessage),\n/* harmony export */   isPresent: () => (/* binding */ isPresent),\n/* harmony export */   isToolMessage: () => (/* binding */ isToolMessage)\n/* harmony export */ });\nconst isAssistantMessage = (message) => {\n    return message?.role === 'assistant';\n};\nconst isFunctionMessage = (message) => {\n    return message?.role === 'function';\n};\nconst isToolMessage = (message) => {\n    return message?.role === 'tool';\n};\nfunction isPresent(obj) {\n    return obj != null;\n}\n//# sourceMappingURL=chatCompletionUtils.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/lib/chatCompletionUtils.mjs?");

/***/ }),

/***/ "./node_modules/openai/lib/parser.mjs":
/*!********************************************!*\
  !*** ./node_modules/openai/lib/parser.mjs ***!
  \********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   hasAutoParseableInput: () => (/* binding */ hasAutoParseableInput),\n/* harmony export */   isAutoParsableResponseFormat: () => (/* binding */ isAutoParsableResponseFormat),\n/* harmony export */   isAutoParsableTool: () => (/* binding */ isAutoParsableTool),\n/* harmony export */   makeParseableResponseFormat: () => (/* binding */ makeParseableResponseFormat),\n/* harmony export */   makeParseableTool: () => (/* binding */ makeParseableTool),\n/* harmony export */   maybeParseChatCompletion: () => (/* binding */ maybeParseChatCompletion),\n/* harmony export */   parseChatCompletion: () => (/* binding */ parseChatCompletion),\n/* harmony export */   shouldParseToolCall: () => (/* binding */ shouldParseToolCall),\n/* harmony export */   validateInputTools: () => (/* binding */ validateInputTools)\n/* harmony export */ });\n/* harmony import */ var _error_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../error.mjs */ \"./node_modules/openai/error.mjs\");\n\nfunction makeParseableResponseFormat(response_format, parser) {\n    const obj = { ...response_format };\n    Object.defineProperties(obj, {\n        $brand: {\n            value: 'auto-parseable-response-format',\n            enumerable: false,\n        },\n        $parseRaw: {\n            value: parser,\n            enumerable: false,\n        },\n    });\n    return obj;\n}\nfunction isAutoParsableResponseFormat(response_format) {\n    return response_format?.['$brand'] === 'auto-parseable-response-format';\n}\nfunction makeParseableTool(tool, { parser, callback, }) {\n    const obj = { ...tool };\n    Object.defineProperties(obj, {\n        $brand: {\n            value: 'auto-parseable-tool',\n            enumerable: false,\n        },\n        $parseRaw: {\n            value: parser,\n            enumerable: false,\n        },\n        $callback: {\n            value: callback,\n            enumerable: false,\n        },\n    });\n    return obj;\n}\nfunction isAutoParsableTool(tool) {\n    return tool?.['$brand'] === 'auto-parseable-tool';\n}\nfunction maybeParseChatCompletion(completion, params) {\n    if (!params || !hasAutoParseableInput(params)) {\n        return {\n            ...completion,\n            choices: completion.choices.map((choice) => ({\n                ...choice,\n                message: {\n                    ...choice.message,\n                    parsed: null,\n                    ...(choice.message.tool_calls ?\n                        {\n                            tool_calls: choice.message.tool_calls,\n                        }\n                        : undefined),\n                },\n            })),\n        };\n    }\n    return parseChatCompletion(completion, params);\n}\nfunction parseChatCompletion(completion, params) {\n    const choices = completion.choices.map((choice) => {\n        if (choice.finish_reason === 'length') {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_0__.LengthFinishReasonError();\n        }\n        if (choice.finish_reason === 'content_filter') {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_0__.ContentFilterFinishReasonError();\n        }\n        return {\n            ...choice,\n            message: {\n                ...choice.message,\n                ...(choice.message.tool_calls ?\n                    {\n                        tool_calls: choice.message.tool_calls?.map((toolCall) => parseToolCall(params, toolCall)) ?? undefined,\n                    }\n                    : undefined),\n                parsed: choice.message.content && !choice.message.refusal ?\n                    parseResponseFormat(params, choice.message.content)\n                    : null,\n            },\n        };\n    });\n    return { ...completion, choices };\n}\nfunction parseResponseFormat(params, content) {\n    if (params.response_format?.type !== 'json_schema') {\n        return null;\n    }\n    if (params.response_format?.type === 'json_schema') {\n        if ('$parseRaw' in params.response_format) {\n            const response_format = params.response_format;\n            return response_format.$parseRaw(content);\n        }\n        return JSON.parse(content);\n    }\n    return null;\n}\nfunction parseToolCall(params, toolCall) {\n    const inputTool = params.tools?.find((inputTool) => inputTool.function?.name === toolCall.function.name);\n    return {\n        ...toolCall,\n        function: {\n            ...toolCall.function,\n            parsed_arguments: isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCall.function.arguments)\n                : inputTool?.function.strict ? JSON.parse(toolCall.function.arguments)\n                    : null,\n        },\n    };\n}\nfunction shouldParseToolCall(params, toolCall) {\n    if (!params) {\n        return false;\n    }\n    const inputTool = params.tools?.find((inputTool) => inputTool.function?.name === toolCall.function.name);\n    return isAutoParsableTool(inputTool) || inputTool?.function.strict || false;\n}\nfunction hasAutoParseableInput(params) {\n    if (isAutoParsableResponseFormat(params.response_format)) {\n        return true;\n    }\n    return (params.tools?.some((t) => isAutoParsableTool(t) || (t.type === 'function' && t.function.strict === true)) ?? false);\n}\nfunction validateInputTools(tools) {\n    for (const tool of tools ?? []) {\n        if (tool.type !== 'function') {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_0__.OpenAIError(`Currently only \\`function\\` tool types support auto-parsing; Received \\`${tool.type}\\``);\n        }\n        if (tool.function.strict !== true) {\n            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_0__.OpenAIError(`The \\`${tool.function.name}\\` tool is not marked with \\`strict: true\\`. Only strict function tools can be auto-parsed`);\n        }\n    }\n}\n//# sourceMappingURL=parser.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/lib/parser.mjs?");

/***/ }),

/***/ "./node_modules/openai/pagination.mjs":
/*!********************************************!*\
  !*** ./node_modules/openai/pagination.mjs ***!
  \********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   CursorPage: () => (/* binding */ CursorPage),\n/* harmony export */   Page: () => (/* binding */ Page)\n/* harmony export */ });\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./core.mjs */ \"./node_modules/openai/core.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nclass Page extends _core_mjs__WEBPACK_IMPORTED_MODULE_0__.AbstractPage {\n    constructor(client, response, body, options) {\n        super(client, response, body, options);\n        this.data = body.data || [];\n        this.object = body.object;\n    }\n    getPaginatedItems() {\n        return this.data ?? [];\n    }\n    // @deprecated Please use `nextPageInfo()` instead\n    /**\n     * This page represents a response that isn't actually paginated at the API level\n     * so there will never be any next page params.\n     */\n    nextPageParams() {\n        return null;\n    }\n    nextPageInfo() {\n        return null;\n    }\n}\nclass CursorPage extends _core_mjs__WEBPACK_IMPORTED_MODULE_0__.AbstractPage {\n    constructor(client, response, body, options) {\n        super(client, response, body, options);\n        this.data = body.data || [];\n        this.has_more = body.has_more || false;\n    }\n    getPaginatedItems() {\n        return this.data ?? [];\n    }\n    hasNextPage() {\n        if (this.has_more === false) {\n            return false;\n        }\n        return super.hasNextPage();\n    }\n    // @deprecated Please use `nextPageInfo()` instead\n    nextPageParams() {\n        const info = this.nextPageInfo();\n        if (!info)\n            return null;\n        if ('params' in info)\n            return info.params;\n        const params = Object.fromEntries(info.url.searchParams);\n        if (!Object.keys(params).length)\n            return null;\n        return params;\n    }\n    nextPageInfo() {\n        const data = this.getPaginatedItems();\n        if (!data.length) {\n            return null;\n        }\n        const id = data[data.length - 1]?.id;\n        if (!id) {\n            return null;\n        }\n        return { params: { after: id } };\n    }\n}\n//# sourceMappingURL=pagination.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/pagination.mjs?");

/***/ }),

/***/ "./node_modules/openai/resource.mjs":
/*!******************************************!*\
  !*** ./node_modules/openai/resource.mjs ***!
  \******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   APIResource: () => (/* binding */ APIResource)\n/* harmony export */ });\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nclass APIResource {\n    constructor(client) {\n        this._client = client;\n    }\n}\n//# sourceMappingURL=resource.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resource.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/audio/audio.mjs":
/*!*******************************************************!*\
  !*** ./node_modules/openai/resources/audio/audio.mjs ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Audio: () => (/* binding */ Audio)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _speech_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./speech.mjs */ \"./node_modules/openai/resources/audio/speech.mjs\");\n/* harmony import */ var _transcriptions_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./transcriptions.mjs */ \"./node_modules/openai/resources/audio/transcriptions.mjs\");\n/* harmony import */ var _translations_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./translations.mjs */ \"./node_modules/openai/resources/audio/translations.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\n\n\n\n\nclass Audio extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    constructor() {\n        super(...arguments);\n        this.transcriptions = new _transcriptions_mjs__WEBPACK_IMPORTED_MODULE_1__.Transcriptions(this._client);\n        this.translations = new _translations_mjs__WEBPACK_IMPORTED_MODULE_2__.Translations(this._client);\n        this.speech = new _speech_mjs__WEBPACK_IMPORTED_MODULE_3__.Speech(this._client);\n    }\n}\nAudio.Transcriptions = _transcriptions_mjs__WEBPACK_IMPORTED_MODULE_1__.Transcriptions;\nAudio.Translations = _translations_mjs__WEBPACK_IMPORTED_MODULE_2__.Translations;\nAudio.Speech = _speech_mjs__WEBPACK_IMPORTED_MODULE_3__.Speech;\n//# sourceMappingURL=audio.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/audio/audio.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/audio/speech.mjs":
/*!********************************************************!*\
  !*** ./node_modules/openai/resources/audio/speech.mjs ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Speech: () => (/* binding */ Speech)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nclass Speech extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    /**\n     * Generates audio from the input text.\n     */\n    create(body, options) {\n        return this._client.post('/audio/speech', {\n            body,\n            ...options,\n            headers: { Accept: 'application/octet-stream', ...options?.headers },\n            __binaryResponse: true,\n        });\n    }\n}\n//# sourceMappingURL=speech.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/audio/speech.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/audio/transcriptions.mjs":
/*!****************************************************************!*\
  !*** ./node_modules/openai/resources/audio/transcriptions.mjs ***!
  \****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Transcriptions: () => (/* binding */ Transcriptions)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core.mjs */ \"./node_modules/openai/uploads.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\nclass Transcriptions extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    create(body, options) {\n        return this._client.post('/audio/transcriptions', _core_mjs__WEBPACK_IMPORTED_MODULE_1__.multipartFormRequestOptions({ body, ...options, __metadata: { model: body.model } }));\n    }\n}\n//# sourceMappingURL=transcriptions.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/audio/transcriptions.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/audio/translations.mjs":
/*!**************************************************************!*\
  !*** ./node_modules/openai/resources/audio/translations.mjs ***!
  \**************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Translations: () => (/* binding */ Translations)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core.mjs */ \"./node_modules/openai/uploads.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\nclass Translations extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    create(body, options) {\n        return this._client.post('/audio/translations', _core_mjs__WEBPACK_IMPORTED_MODULE_1__.multipartFormRequestOptions({ body, ...options, __metadata: { model: body.model } }));\n    }\n}\n//# sourceMappingURL=translations.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/audio/translations.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/batches.mjs":
/*!***************************************************!*\
  !*** ./node_modules/openai/resources/batches.mjs ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Batches: () => (/* binding */ Batches),\n/* harmony export */   BatchesPage: () => (/* binding */ BatchesPage)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _pagination_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../pagination.mjs */ \"./node_modules/openai/pagination.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\nclass Batches extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    /**\n     * Creates and executes a batch from an uploaded file of requests\n     */\n    create(body, options) {\n        return this._client.post('/batches', { body, ...options });\n    }\n    /**\n     * Retrieves a batch.\n     */\n    retrieve(batchId, options) {\n        return this._client.get(`/batches/${batchId}`, options);\n    }\n    list(query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_1__.isRequestOptions)(query)) {\n            return this.list({}, query);\n        }\n        return this._client.getAPIList('/batches', BatchesPage, { query, ...options });\n    }\n    /**\n     * Cancels an in-progress batch. The batch will be in status `cancelling` for up to\n     * 10 minutes, before changing to `cancelled`, where it will have partial results\n     * (if any) available in the output file.\n     */\n    cancel(batchId, options) {\n        return this._client.post(`/batches/${batchId}/cancel`, options);\n    }\n}\nclass BatchesPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_2__.CursorPage {\n}\nBatches.BatchesPage = BatchesPage;\n//# sourceMappingURL=batches.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/batches.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/beta/assistants.mjs":
/*!***********************************************************!*\
  !*** ./node_modules/openai/resources/beta/assistants.mjs ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Assistants: () => (/* binding */ Assistants),\n/* harmony export */   AssistantsPage: () => (/* binding */ AssistantsPage)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _pagination_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../pagination.mjs */ \"./node_modules/openai/pagination.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\nclass Assistants extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    /**\n     * Create an assistant with a model and instructions.\n     */\n    create(body, options) {\n        return this._client.post('/assistants', {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Retrieves an assistant.\n     */\n    retrieve(assistantId, options) {\n        return this._client.get(`/assistants/${assistantId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Modifies an assistant.\n     */\n    update(assistantId, body, options) {\n        return this._client.post(`/assistants/${assistantId}`, {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    list(query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_1__.isRequestOptions)(query)) {\n            return this.list({}, query);\n        }\n        return this._client.getAPIList('/assistants', AssistantsPage, {\n            query,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Delete an assistant.\n     */\n    del(assistantId, options) {\n        return this._client.delete(`/assistants/${assistantId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n}\nclass AssistantsPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_2__.CursorPage {\n}\nAssistants.AssistantsPage = AssistantsPage;\n//# sourceMappingURL=assistants.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/beta/assistants.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/beta/beta.mjs":
/*!*****************************************************!*\
  !*** ./node_modules/openai/resources/beta/beta.mjs ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Beta: () => (/* binding */ Beta)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _assistants_mjs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./assistants.mjs */ \"./node_modules/openai/resources/beta/assistants.mjs\");\n/* harmony import */ var _chat_chat_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./chat/chat.mjs */ \"./node_modules/openai/resources/beta/chat/chat.mjs\");\n/* harmony import */ var _realtime_realtime_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./realtime/realtime.mjs */ \"./node_modules/openai/resources/beta/realtime/realtime.mjs\");\n/* harmony import */ var _threads_threads_mjs__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./threads/threads.mjs */ \"./node_modules/openai/resources/beta/threads/threads.mjs\");\n/* harmony import */ var _vector_stores_vector_stores_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./vector-stores/vector-stores.mjs */ \"./node_modules/openai/resources/beta/vector-stores/vector-stores.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\n\n\n\n\n\n\n\n\nclass Beta extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    constructor() {\n        super(...arguments);\n        this.realtime = new _realtime_realtime_mjs__WEBPACK_IMPORTED_MODULE_1__.Realtime(this._client);\n        this.vectorStores = new _vector_stores_vector_stores_mjs__WEBPACK_IMPORTED_MODULE_2__.VectorStores(this._client);\n        this.chat = new _chat_chat_mjs__WEBPACK_IMPORTED_MODULE_3__.Chat(this._client);\n        this.assistants = new _assistants_mjs__WEBPACK_IMPORTED_MODULE_4__.Assistants(this._client);\n        this.threads = new _threads_threads_mjs__WEBPACK_IMPORTED_MODULE_5__.Threads(this._client);\n    }\n}\nBeta.Realtime = _realtime_realtime_mjs__WEBPACK_IMPORTED_MODULE_1__.Realtime;\nBeta.VectorStores = _vector_stores_vector_stores_mjs__WEBPACK_IMPORTED_MODULE_2__.VectorStores;\nBeta.VectorStoresPage = _vector_stores_vector_stores_mjs__WEBPACK_IMPORTED_MODULE_2__.VectorStoresPage;\nBeta.Assistants = _assistants_mjs__WEBPACK_IMPORTED_MODULE_4__.Assistants;\nBeta.AssistantsPage = _assistants_mjs__WEBPACK_IMPORTED_MODULE_4__.AssistantsPage;\nBeta.Threads = _threads_threads_mjs__WEBPACK_IMPORTED_MODULE_5__.Threads;\n//# sourceMappingURL=beta.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/beta/beta.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/beta/chat/chat.mjs":
/*!**********************************************************!*\
  !*** ./node_modules/openai/resources/beta/chat/chat.mjs ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Chat: () => (/* binding */ Chat)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _completions_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./completions.mjs */ \"./node_modules/openai/resources/beta/chat/completions.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\nclass Chat extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    constructor() {\n        super(...arguments);\n        this.completions = new _completions_mjs__WEBPACK_IMPORTED_MODULE_1__.Completions(this._client);\n    }\n}\n(function (Chat) {\n    Chat.Completions = _completions_mjs__WEBPACK_IMPORTED_MODULE_1__.Completions;\n})(Chat || (Chat = {}));\n//# sourceMappingURL=chat.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/beta/chat/chat.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/beta/chat/completions.mjs":
/*!*****************************************************************!*\
  !*** ./node_modules/openai/resources/beta/chat/completions.mjs ***!
  \*****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ChatCompletionRunner: () => (/* reexport safe */ _lib_ChatCompletionRunner_mjs__WEBPACK_IMPORTED_MODULE_3__.ChatCompletionRunner),\n/* harmony export */   ChatCompletionStream: () => (/* reexport safe */ _lib_ChatCompletionStream_mjs__WEBPACK_IMPORTED_MODULE_2__.ChatCompletionStream),\n/* harmony export */   ChatCompletionStreamingRunner: () => (/* reexport safe */ _lib_ChatCompletionStreamingRunner_mjs__WEBPACK_IMPORTED_MODULE_0__.ChatCompletionStreamingRunner),\n/* harmony export */   Completions: () => (/* binding */ Completions),\n/* harmony export */   ParsingFunction: () => (/* reexport safe */ _lib_RunnableFunction_mjs__WEBPACK_IMPORTED_MODULE_1__.ParsingFunction),\n/* harmony export */   ParsingToolFunction: () => (/* reexport safe */ _lib_RunnableFunction_mjs__WEBPACK_IMPORTED_MODULE_1__.ParsingToolFunction)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _lib_ChatCompletionRunner_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../../lib/ChatCompletionRunner.mjs */ \"./node_modules/openai/lib/ChatCompletionRunner.mjs\");\n/* harmony import */ var _lib_ChatCompletionStreamingRunner_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../lib/ChatCompletionStreamingRunner.mjs */ \"./node_modules/openai/lib/ChatCompletionStreamingRunner.mjs\");\n/* harmony import */ var _lib_ChatCompletionStream_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../lib/ChatCompletionStream.mjs */ \"./node_modules/openai/lib/ChatCompletionStream.mjs\");\n/* harmony import */ var _lib_parser_mjs__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../../lib/parser.mjs */ \"./node_modules/openai/lib/parser.mjs\");\n/* harmony import */ var _lib_RunnableFunction_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../lib/RunnableFunction.mjs */ \"./node_modules/openai/lib/RunnableFunction.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\n\n\n\n\n\n\nclass Completions extends _resource_mjs__WEBPACK_IMPORTED_MODULE_4__.APIResource {\n    parse(body, options) {\n        (0,_lib_parser_mjs__WEBPACK_IMPORTED_MODULE_5__.validateInputTools)(body.tools);\n        return this._client.chat.completions\n            .create(body, {\n            ...options,\n            headers: {\n                ...options?.headers,\n                'X-Stainless-Helper-Method': 'beta.chat.completions.parse',\n            },\n        })\n            ._thenUnwrap((completion) => (0,_lib_parser_mjs__WEBPACK_IMPORTED_MODULE_5__.parseChatCompletion)(completion, body));\n    }\n    runFunctions(body, options) {\n        if (body.stream) {\n            return _lib_ChatCompletionStreamingRunner_mjs__WEBPACK_IMPORTED_MODULE_0__.ChatCompletionStreamingRunner.runFunctions(this._client, body, options);\n        }\n        return _lib_ChatCompletionRunner_mjs__WEBPACK_IMPORTED_MODULE_3__.ChatCompletionRunner.runFunctions(this._client, body, options);\n    }\n    runTools(body, options) {\n        if (body.stream) {\n            return _lib_ChatCompletionStreamingRunner_mjs__WEBPACK_IMPORTED_MODULE_0__.ChatCompletionStreamingRunner.runTools(this._client, body, options);\n        }\n        return _lib_ChatCompletionRunner_mjs__WEBPACK_IMPORTED_MODULE_3__.ChatCompletionRunner.runTools(this._client, body, options);\n    }\n    /**\n     * Creates a chat completion stream\n     */\n    stream(body, options) {\n        return _lib_ChatCompletionStream_mjs__WEBPACK_IMPORTED_MODULE_2__.ChatCompletionStream.createChatCompletion(this._client, body, options);\n    }\n}\n//# sourceMappingURL=completions.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/beta/chat/completions.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/beta/realtime/realtime.mjs":
/*!******************************************************************!*\
  !*** ./node_modules/openai/resources/beta/realtime/realtime.mjs ***!
  \******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Realtime: () => (/* binding */ Realtime)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _sessions_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./sessions.mjs */ \"./node_modules/openai/resources/beta/realtime/sessions.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\nclass Realtime extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    constructor() {\n        super(...arguments);\n        this.sessions = new _sessions_mjs__WEBPACK_IMPORTED_MODULE_1__.Sessions(this._client);\n    }\n}\nRealtime.Sessions = _sessions_mjs__WEBPACK_IMPORTED_MODULE_1__.Sessions;\n//# sourceMappingURL=realtime.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/beta/realtime/realtime.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/beta/realtime/sessions.mjs":
/*!******************************************************************!*\
  !*** ./node_modules/openai/resources/beta/realtime/sessions.mjs ***!
  \******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Sessions: () => (/* binding */ Sessions)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nclass Sessions extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    /**\n     * Create an ephemeral API token for use in client-side applications with the\n     * Realtime API. Can be configured with the same session parameters as the\n     * `session.update` client event.\n     *\n     * It responds with a session object, plus a `client_secret` key which contains a\n     * usable ephemeral API token that can be used to authenticate browser clients for\n     * the Realtime API.\n     */\n    create(body, options) {\n        return this._client.post('/realtime/sessions', {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n}\n//# sourceMappingURL=sessions.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/beta/realtime/sessions.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/beta/threads/messages.mjs":
/*!*****************************************************************!*\
  !*** ./node_modules/openai/resources/beta/threads/messages.mjs ***!
  \*****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Messages: () => (/* binding */ Messages),\n/* harmony export */   MessagesPage: () => (/* binding */ MessagesPage)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _pagination_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../pagination.mjs */ \"./node_modules/openai/pagination.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\nclass Messages extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    /**\n     * Create a message.\n     */\n    create(threadId, body, options) {\n        return this._client.post(`/threads/${threadId}/messages`, {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Retrieve a message.\n     */\n    retrieve(threadId, messageId, options) {\n        return this._client.get(`/threads/${threadId}/messages/${messageId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Modifies a message.\n     */\n    update(threadId, messageId, body, options) {\n        return this._client.post(`/threads/${threadId}/messages/${messageId}`, {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    list(threadId, query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_1__.isRequestOptions)(query)) {\n            return this.list(threadId, {}, query);\n        }\n        return this._client.getAPIList(`/threads/${threadId}/messages`, MessagesPage, {\n            query,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Deletes a message.\n     */\n    del(threadId, messageId, options) {\n        return this._client.delete(`/threads/${threadId}/messages/${messageId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n}\nclass MessagesPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_2__.CursorPage {\n}\nMessages.MessagesPage = MessagesPage;\n//# sourceMappingURL=messages.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/beta/threads/messages.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/beta/threads/runs/runs.mjs":
/*!******************************************************************!*\
  !*** ./node_modules/openai/resources/beta/threads/runs/runs.mjs ***!
  \******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Runs: () => (/* binding */ Runs),\n/* harmony export */   RunsPage: () => (/* binding */ RunsPage)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _lib_AssistantStream_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../../../lib/AssistantStream.mjs */ \"./node_modules/openai/lib/AssistantStream.mjs\");\n/* harmony import */ var _steps_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./steps.mjs */ \"./node_modules/openai/resources/beta/threads/runs/steps.mjs\");\n/* harmony import */ var _pagination_mjs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../../../pagination.mjs */ \"./node_modules/openai/pagination.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\n\n\n\n\nclass Runs extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    constructor() {\n        super(...arguments);\n        this.steps = new _steps_mjs__WEBPACK_IMPORTED_MODULE_1__.Steps(this._client);\n    }\n    create(threadId, params, options) {\n        const { include, ...body } = params;\n        return this._client.post(`/threads/${threadId}/runs`, {\n            query: { include },\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n            stream: params.stream ?? false,\n        });\n    }\n    /**\n     * Retrieves a run.\n     */\n    retrieve(threadId, runId, options) {\n        return this._client.get(`/threads/${threadId}/runs/${runId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Modifies a run.\n     */\n    update(threadId, runId, body, options) {\n        return this._client.post(`/threads/${threadId}/runs/${runId}`, {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    list(threadId, query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_2__.isRequestOptions)(query)) {\n            return this.list(threadId, {}, query);\n        }\n        return this._client.getAPIList(`/threads/${threadId}/runs`, RunsPage, {\n            query,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Cancels a run that is `in_progress`.\n     */\n    cancel(threadId, runId, options) {\n        return this._client.post(`/threads/${threadId}/runs/${runId}/cancel`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * A helper to create a run an poll for a terminal state. More information on Run\n     * lifecycles can be found here:\n     * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n     */\n    async createAndPoll(threadId, body, options) {\n        const run = await this.create(threadId, body, options);\n        return await this.poll(threadId, run.id, options);\n    }\n    /**\n     * Create a Run stream\n     *\n     * @deprecated use `stream` instead\n     */\n    createAndStream(threadId, body, options) {\n        return _lib_AssistantStream_mjs__WEBPACK_IMPORTED_MODULE_3__.AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n    }\n    /**\n     * A helper to poll a run status until it reaches a terminal state. More\n     * information on Run lifecycles can be found here:\n     * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n     */\n    async poll(threadId, runId, options) {\n        const headers = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n        if (options?.pollIntervalMs) {\n            headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n        }\n        while (true) {\n            const { data: run, response } = await this.retrieve(threadId, runId, {\n                ...options,\n                headers: { ...options?.headers, ...headers },\n            }).withResponse();\n            switch (run.status) {\n                //If we are in any sort of intermediate state we poll\n                case 'queued':\n                case 'in_progress':\n                case 'cancelling':\n                    let sleepInterval = 5000;\n                    if (options?.pollIntervalMs) {\n                        sleepInterval = options.pollIntervalMs;\n                    }\n                    else {\n                        const headerInterval = response.headers.get('openai-poll-after-ms');\n                        if (headerInterval) {\n                            const headerIntervalMs = parseInt(headerInterval);\n                            if (!isNaN(headerIntervalMs)) {\n                                sleepInterval = headerIntervalMs;\n                            }\n                        }\n                    }\n                    await (0,_core_mjs__WEBPACK_IMPORTED_MODULE_2__.sleep)(sleepInterval);\n                    break;\n                //We return the run in any terminal state.\n                case 'requires_action':\n                case 'incomplete':\n                case 'cancelled':\n                case 'completed':\n                case 'failed':\n                case 'expired':\n                    return run;\n            }\n        }\n    }\n    /**\n     * Create a Run stream\n     */\n    stream(threadId, body, options) {\n        return _lib_AssistantStream_mjs__WEBPACK_IMPORTED_MODULE_3__.AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n    }\n    submitToolOutputs(threadId, runId, body, options) {\n        return this._client.post(`/threads/${threadId}/runs/${runId}/submit_tool_outputs`, {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n            stream: body.stream ?? false,\n        });\n    }\n    /**\n     * A helper to submit a tool output to a run and poll for a terminal run state.\n     * More information on Run lifecycles can be found here:\n     * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n     */\n    async submitToolOutputsAndPoll(threadId, runId, body, options) {\n        const run = await this.submitToolOutputs(threadId, runId, body, options);\n        return await this.poll(threadId, run.id, options);\n    }\n    /**\n     * Submit the tool outputs from a previous run and stream the run to a terminal\n     * state. More information on Run lifecycles can be found here:\n     * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n     */\n    submitToolOutputsStream(threadId, runId, body, options) {\n        return _lib_AssistantStream_mjs__WEBPACK_IMPORTED_MODULE_3__.AssistantStream.createToolAssistantStream(threadId, runId, this._client.beta.threads.runs, body, options);\n    }\n}\nclass RunsPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_4__.CursorPage {\n}\nRuns.RunsPage = RunsPage;\nRuns.Steps = _steps_mjs__WEBPACK_IMPORTED_MODULE_1__.Steps;\nRuns.RunStepsPage = _steps_mjs__WEBPACK_IMPORTED_MODULE_1__.RunStepsPage;\n//# sourceMappingURL=runs.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/beta/threads/runs/runs.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/beta/threads/runs/steps.mjs":
/*!*******************************************************************!*\
  !*** ./node_modules/openai/resources/beta/threads/runs/steps.mjs ***!
  \*******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   RunStepsPage: () => (/* binding */ RunStepsPage),\n/* harmony export */   Steps: () => (/* binding */ Steps)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _pagination_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../../pagination.mjs */ \"./node_modules/openai/pagination.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\nclass Steps extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    retrieve(threadId, runId, stepId, query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_1__.isRequestOptions)(query)) {\n            return this.retrieve(threadId, runId, stepId, {}, query);\n        }\n        return this._client.get(`/threads/${threadId}/runs/${runId}/steps/${stepId}`, {\n            query,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    list(threadId, runId, query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_1__.isRequestOptions)(query)) {\n            return this.list(threadId, runId, {}, query);\n        }\n        return this._client.getAPIList(`/threads/${threadId}/runs/${runId}/steps`, RunStepsPage, {\n            query,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n}\nclass RunStepsPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_2__.CursorPage {\n}\nSteps.RunStepsPage = RunStepsPage;\n//# sourceMappingURL=steps.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/beta/threads/runs/steps.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/beta/threads/threads.mjs":
/*!****************************************************************!*\
  !*** ./node_modules/openai/resources/beta/threads/threads.mjs ***!
  \****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Threads: () => (/* binding */ Threads)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _lib_AssistantStream_mjs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../../lib/AssistantStream.mjs */ \"./node_modules/openai/lib/AssistantStream.mjs\");\n/* harmony import */ var _messages_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./messages.mjs */ \"./node_modules/openai/resources/beta/threads/messages.mjs\");\n/* harmony import */ var _runs_runs_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./runs/runs.mjs */ \"./node_modules/openai/resources/beta/threads/runs/runs.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\n\n\n\n\nclass Threads extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    constructor() {\n        super(...arguments);\n        this.runs = new _runs_runs_mjs__WEBPACK_IMPORTED_MODULE_1__.Runs(this._client);\n        this.messages = new _messages_mjs__WEBPACK_IMPORTED_MODULE_2__.Messages(this._client);\n    }\n    create(body = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_3__.isRequestOptions)(body)) {\n            return this.create({}, body);\n        }\n        return this._client.post('/threads', {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Retrieves a thread.\n     */\n    retrieve(threadId, options) {\n        return this._client.get(`/threads/${threadId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Modifies a thread.\n     */\n    update(threadId, body, options) {\n        return this._client.post(`/threads/${threadId}`, {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Delete a thread.\n     */\n    del(threadId, options) {\n        return this._client.delete(`/threads/${threadId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    createAndRun(body, options) {\n        return this._client.post('/threads/runs', {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n            stream: body.stream ?? false,\n        });\n    }\n    /**\n     * A helper to create a thread, start a run and then poll for a terminal state.\n     * More information on Run lifecycles can be found here:\n     * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n     */\n    async createAndRunPoll(body, options) {\n        const run = await this.createAndRun(body, options);\n        return await this.runs.poll(run.thread_id, run.id, options);\n    }\n    /**\n     * Create a thread and stream the run back\n     */\n    createAndRunStream(body, options) {\n        return _lib_AssistantStream_mjs__WEBPACK_IMPORTED_MODULE_4__.AssistantStream.createThreadAssistantStream(body, this._client.beta.threads, options);\n    }\n}\nThreads.Runs = _runs_runs_mjs__WEBPACK_IMPORTED_MODULE_1__.Runs;\nThreads.RunsPage = _runs_runs_mjs__WEBPACK_IMPORTED_MODULE_1__.RunsPage;\nThreads.Messages = _messages_mjs__WEBPACK_IMPORTED_MODULE_2__.Messages;\nThreads.MessagesPage = _messages_mjs__WEBPACK_IMPORTED_MODULE_2__.MessagesPage;\n//# sourceMappingURL=threads.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/beta/threads/threads.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/beta/vector-stores/file-batches.mjs":
/*!***************************************************************************!*\
  !*** ./node_modules/openai/resources/beta/vector-stores/file-batches.mjs ***!
  \***************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FileBatches: () => (/* binding */ FileBatches),\n/* harmony export */   VectorStoreFilesPage: () => (/* reexport safe */ _files_mjs__WEBPACK_IMPORTED_MODULE_2__.VectorStoreFilesPage)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _lib_Util_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../../lib/Util.mjs */ \"./node_modules/openai/lib/Util.mjs\");\n/* harmony import */ var _files_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./files.mjs */ \"./node_modules/openai/resources/beta/vector-stores/files.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\n\n\nclass FileBatches extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    /**\n     * Create a vector store file batch.\n     */\n    create(vectorStoreId, body, options) {\n        return this._client.post(`/vector_stores/${vectorStoreId}/file_batches`, {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Retrieves a vector store file batch.\n     */\n    retrieve(vectorStoreId, batchId, options) {\n        return this._client.get(`/vector_stores/${vectorStoreId}/file_batches/${batchId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Cancel a vector store file batch. This attempts to cancel the processing of\n     * files in this batch as soon as possible.\n     */\n    cancel(vectorStoreId, batchId, options) {\n        return this._client.post(`/vector_stores/${vectorStoreId}/file_batches/${batchId}/cancel`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Create a vector store batch and poll until all files have been processed.\n     */\n    async createAndPoll(vectorStoreId, body, options) {\n        const batch = await this.create(vectorStoreId, body);\n        return await this.poll(vectorStoreId, batch.id, options);\n    }\n    listFiles(vectorStoreId, batchId, query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_1__.isRequestOptions)(query)) {\n            return this.listFiles(vectorStoreId, batchId, {}, query);\n        }\n        return this._client.getAPIList(`/vector_stores/${vectorStoreId}/file_batches/${batchId}/files`, _files_mjs__WEBPACK_IMPORTED_MODULE_2__.VectorStoreFilesPage, { query, ...options, headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers } });\n    }\n    /**\n     * Wait for the given file batch to be processed.\n     *\n     * Note: this will return even if one of the files failed to process, you need to\n     * check batch.file_counts.failed_count to handle this case.\n     */\n    async poll(vectorStoreId, batchId, options) {\n        const headers = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n        if (options?.pollIntervalMs) {\n            headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n        }\n        while (true) {\n            const { data: batch, response } = await this.retrieve(vectorStoreId, batchId, {\n                ...options,\n                headers,\n            }).withResponse();\n            switch (batch.status) {\n                case 'in_progress':\n                    let sleepInterval = 5000;\n                    if (options?.pollIntervalMs) {\n                        sleepInterval = options.pollIntervalMs;\n                    }\n                    else {\n                        const headerInterval = response.headers.get('openai-poll-after-ms');\n                        if (headerInterval) {\n                            const headerIntervalMs = parseInt(headerInterval);\n                            if (!isNaN(headerIntervalMs)) {\n                                sleepInterval = headerIntervalMs;\n                            }\n                        }\n                    }\n                    await (0,_core_mjs__WEBPACK_IMPORTED_MODULE_1__.sleep)(sleepInterval);\n                    break;\n                case 'failed':\n                case 'cancelled':\n                case 'completed':\n                    return batch;\n            }\n        }\n    }\n    /**\n     * Uploads the given files concurrently and then creates a vector store file batch.\n     *\n     * The concurrency limit is configurable using the `maxConcurrency` parameter.\n     */\n    async uploadAndPoll(vectorStoreId, { files, fileIds = [] }, options) {\n        if (files == null || files.length == 0) {\n            throw new Error(`No \\`files\\` provided to process. If you've already uploaded files you should use \\`.createAndPoll()\\` instead`);\n        }\n        const configuredConcurrency = options?.maxConcurrency ?? 5;\n        // We cap the number of workers at the number of files (so we don't start any unnecessary workers)\n        const concurrencyLimit = Math.min(configuredConcurrency, files.length);\n        const client = this._client;\n        const fileIterator = files.values();\n        const allFileIds = [...fileIds];\n        // This code is based on this design. The libraries don't accommodate our environment limits.\n        // https://stackoverflow.com/questions/40639432/what-is-the-best-way-to-limit-concurrency-when-using-es6s-promise-all\n        async function processFiles(iterator) {\n            for (let item of iterator) {\n                const fileObj = await client.files.create({ file: item, purpose: 'assistants' }, options);\n                allFileIds.push(fileObj.id);\n            }\n        }\n        // Start workers to process results\n        const workers = Array(concurrencyLimit).fill(fileIterator).map(processFiles);\n        // Wait for all processing to complete.\n        await (0,_lib_Util_mjs__WEBPACK_IMPORTED_MODULE_3__.allSettledWithThrow)(workers);\n        return await this.createAndPoll(vectorStoreId, {\n            file_ids: allFileIds,\n        });\n    }\n}\n\n//# sourceMappingURL=file-batches.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/beta/vector-stores/file-batches.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/beta/vector-stores/files.mjs":
/*!********************************************************************!*\
  !*** ./node_modules/openai/resources/beta/vector-stores/files.mjs ***!
  \********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Files: () => (/* binding */ Files),\n/* harmony export */   VectorStoreFilesPage: () => (/* binding */ VectorStoreFilesPage)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _pagination_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../pagination.mjs */ \"./node_modules/openai/pagination.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\nclass Files extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    /**\n     * Create a vector store file by attaching a\n     * [File](https://platform.openai.com/docs/api-reference/files) to a\n     * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object).\n     */\n    create(vectorStoreId, body, options) {\n        return this._client.post(`/vector_stores/${vectorStoreId}/files`, {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Retrieves a vector store file.\n     */\n    retrieve(vectorStoreId, fileId, options) {\n        return this._client.get(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    list(vectorStoreId, query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_1__.isRequestOptions)(query)) {\n            return this.list(vectorStoreId, {}, query);\n        }\n        return this._client.getAPIList(`/vector_stores/${vectorStoreId}/files`, VectorStoreFilesPage, {\n            query,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Delete a vector store file. This will remove the file from the vector store but\n     * the file itself will not be deleted. To delete the file, use the\n     * [delete file](https://platform.openai.com/docs/api-reference/files/delete)\n     * endpoint.\n     */\n    del(vectorStoreId, fileId, options) {\n        return this._client.delete(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Attach a file to the given vector store and wait for it to be processed.\n     */\n    async createAndPoll(vectorStoreId, body, options) {\n        const file = await this.create(vectorStoreId, body, options);\n        return await this.poll(vectorStoreId, file.id, options);\n    }\n    /**\n     * Wait for the vector store file to finish processing.\n     *\n     * Note: this will return even if the file failed to process, you need to check\n     * file.last_error and file.status to handle these cases\n     */\n    async poll(vectorStoreId, fileId, options) {\n        const headers = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n        if (options?.pollIntervalMs) {\n            headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n        }\n        while (true) {\n            const fileResponse = await this.retrieve(vectorStoreId, fileId, {\n                ...options,\n                headers,\n            }).withResponse();\n            const file = fileResponse.data;\n            switch (file.status) {\n                case 'in_progress':\n                    let sleepInterval = 5000;\n                    if (options?.pollIntervalMs) {\n                        sleepInterval = options.pollIntervalMs;\n                    }\n                    else {\n                        const headerInterval = fileResponse.response.headers.get('openai-poll-after-ms');\n                        if (headerInterval) {\n                            const headerIntervalMs = parseInt(headerInterval);\n                            if (!isNaN(headerIntervalMs)) {\n                                sleepInterval = headerIntervalMs;\n                            }\n                        }\n                    }\n                    await (0,_core_mjs__WEBPACK_IMPORTED_MODULE_1__.sleep)(sleepInterval);\n                    break;\n                case 'failed':\n                case 'completed':\n                    return file;\n            }\n        }\n    }\n    /**\n     * Upload a file to the `files` API and then attach it to the given vector store.\n     *\n     * Note the file will be asynchronously processed (you can use the alternative\n     * polling helper method to wait for processing to complete).\n     */\n    async upload(vectorStoreId, file, options) {\n        const fileInfo = await this._client.files.create({ file: file, purpose: 'assistants' }, options);\n        return this.create(vectorStoreId, { file_id: fileInfo.id }, options);\n    }\n    /**\n     * Add a file to a vector store and poll until processing is complete.\n     */\n    async uploadAndPoll(vectorStoreId, file, options) {\n        const fileInfo = await this.upload(vectorStoreId, file, options);\n        return await this.poll(vectorStoreId, fileInfo.id, options);\n    }\n}\nclass VectorStoreFilesPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_2__.CursorPage {\n}\nFiles.VectorStoreFilesPage = VectorStoreFilesPage;\n//# sourceMappingURL=files.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/beta/vector-stores/files.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/beta/vector-stores/vector-stores.mjs":
/*!****************************************************************************!*\
  !*** ./node_modules/openai/resources/beta/vector-stores/vector-stores.mjs ***!
  \****************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   VectorStores: () => (/* binding */ VectorStores),\n/* harmony export */   VectorStoresPage: () => (/* binding */ VectorStoresPage)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _file_batches_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./file-batches.mjs */ \"./node_modules/openai/resources/beta/vector-stores/file-batches.mjs\");\n/* harmony import */ var _files_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./files.mjs */ \"./node_modules/openai/resources/beta/vector-stores/files.mjs\");\n/* harmony import */ var _pagination_mjs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../../pagination.mjs */ \"./node_modules/openai/pagination.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\n\n\n\n\nclass VectorStores extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    constructor() {\n        super(...arguments);\n        this.files = new _files_mjs__WEBPACK_IMPORTED_MODULE_1__.Files(this._client);\n        this.fileBatches = new _file_batches_mjs__WEBPACK_IMPORTED_MODULE_2__.FileBatches(this._client);\n    }\n    /**\n     * Create a vector store.\n     */\n    create(body, options) {\n        return this._client.post('/vector_stores', {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Retrieves a vector store.\n     */\n    retrieve(vectorStoreId, options) {\n        return this._client.get(`/vector_stores/${vectorStoreId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Modifies a vector store.\n     */\n    update(vectorStoreId, body, options) {\n        return this._client.post(`/vector_stores/${vectorStoreId}`, {\n            body,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    list(query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_3__.isRequestOptions)(query)) {\n            return this.list({}, query);\n        }\n        return this._client.getAPIList('/vector_stores', VectorStoresPage, {\n            query,\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n    /**\n     * Delete a vector store.\n     */\n    del(vectorStoreId, options) {\n        return this._client.delete(`/vector_stores/${vectorStoreId}`, {\n            ...options,\n            headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n        });\n    }\n}\nclass VectorStoresPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_4__.CursorPage {\n}\nVectorStores.VectorStoresPage = VectorStoresPage;\nVectorStores.Files = _files_mjs__WEBPACK_IMPORTED_MODULE_1__.Files;\nVectorStores.VectorStoreFilesPage = _files_mjs__WEBPACK_IMPORTED_MODULE_1__.VectorStoreFilesPage;\nVectorStores.FileBatches = _file_batches_mjs__WEBPACK_IMPORTED_MODULE_2__.FileBatches;\n//# sourceMappingURL=vector-stores.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/beta/vector-stores/vector-stores.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/chat/chat.mjs":
/*!*****************************************************!*\
  !*** ./node_modules/openai/resources/chat/chat.mjs ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Chat: () => (/* binding */ Chat)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _completions_completions_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./completions/completions.mjs */ \"./node_modules/openai/resources/chat/completions/completions.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\nclass Chat extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    constructor() {\n        super(...arguments);\n        this.completions = new _completions_completions_mjs__WEBPACK_IMPORTED_MODULE_1__.Completions(this._client);\n    }\n}\nChat.Completions = _completions_completions_mjs__WEBPACK_IMPORTED_MODULE_1__.Completions;\nChat.ChatCompletionsPage = _completions_completions_mjs__WEBPACK_IMPORTED_MODULE_1__.ChatCompletionsPage;\n//# sourceMappingURL=chat.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/chat/chat.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/chat/completions/completions.mjs":
/*!************************************************************************!*\
  !*** ./node_modules/openai/resources/chat/completions/completions.mjs ***!
  \************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ChatCompletionStoreMessagesPage: () => (/* binding */ ChatCompletionStoreMessagesPage),\n/* harmony export */   ChatCompletionsPage: () => (/* binding */ ChatCompletionsPage),\n/* harmony export */   Completions: () => (/* binding */ Completions)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _messages_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./messages.mjs */ \"./node_modules/openai/resources/chat/completions/messages.mjs\");\n/* harmony import */ var _pagination_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../../pagination.mjs */ \"./node_modules/openai/pagination.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\n\n\nclass Completions extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    constructor() {\n        super(...arguments);\n        this.messages = new _messages_mjs__WEBPACK_IMPORTED_MODULE_1__.Messages(this._client);\n    }\n    create(body, options) {\n        return this._client.post('/chat/completions', { body, ...options, stream: body.stream ?? false });\n    }\n    /**\n     * Get a stored chat completion. Only chat completions that have been created with\n     * the `store` parameter set to `true` will be returned.\n     */\n    retrieve(completionId, options) {\n        return this._client.get(`/chat/completions/${completionId}`, options);\n    }\n    /**\n     * Modify a stored chat completion. Only chat completions that have been created\n     * with the `store` parameter set to `true` can be modified. Currently, the only\n     * supported modification is to update the `metadata` field.\n     */\n    update(completionId, body, options) {\n        return this._client.post(`/chat/completions/${completionId}`, { body, ...options });\n    }\n    list(query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_2__.isRequestOptions)(query)) {\n            return this.list({}, query);\n        }\n        return this._client.getAPIList('/chat/completions', ChatCompletionsPage, { query, ...options });\n    }\n    /**\n     * Delete a stored chat completion. Only chat completions that have been created\n     * with the `store` parameter set to `true` can be deleted.\n     */\n    del(completionId, options) {\n        return this._client.delete(`/chat/completions/${completionId}`, options);\n    }\n}\nclass ChatCompletionsPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_3__.CursorPage {\n}\nclass ChatCompletionStoreMessagesPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_3__.CursorPage {\n}\nCompletions.ChatCompletionsPage = ChatCompletionsPage;\nCompletions.Messages = _messages_mjs__WEBPACK_IMPORTED_MODULE_1__.Messages;\n//# sourceMappingURL=completions.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/chat/completions/completions.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/chat/completions/messages.mjs":
/*!*********************************************************************!*\
  !*** ./node_modules/openai/resources/chat/completions/messages.mjs ***!
  \*********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ChatCompletionStoreMessagesPage: () => (/* reexport safe */ _completions_mjs__WEBPACK_IMPORTED_MODULE_2__.ChatCompletionStoreMessagesPage),\n/* harmony export */   Messages: () => (/* binding */ Messages)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _completions_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./completions.mjs */ \"./node_modules/openai/resources/chat/completions/completions.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\nclass Messages extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    list(completionId, query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_1__.isRequestOptions)(query)) {\n            return this.list(completionId, {}, query);\n        }\n        return this._client.getAPIList(`/chat/completions/${completionId}/messages`, _completions_mjs__WEBPACK_IMPORTED_MODULE_2__.ChatCompletionStoreMessagesPage, { query, ...options });\n    }\n}\n\n//# sourceMappingURL=messages.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/chat/completions/messages.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/completions.mjs":
/*!*******************************************************!*\
  !*** ./node_modules/openai/resources/completions.mjs ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Completions: () => (/* binding */ Completions)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nclass Completions extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    create(body, options) {\n        return this._client.post('/completions', { body, ...options, stream: body.stream ?? false });\n    }\n}\n//# sourceMappingURL=completions.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/completions.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/embeddings.mjs":
/*!******************************************************!*\
  !*** ./node_modules/openai/resources/embeddings.mjs ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Embeddings: () => (/* binding */ Embeddings)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nclass Embeddings extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    /**\n     * Creates an embedding vector representing the input text.\n     */\n    create(body, options) {\n        return this._client.post('/embeddings', { body, ...options });\n    }\n}\n//# sourceMappingURL=embeddings.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/embeddings.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/files.mjs":
/*!*************************************************!*\
  !*** ./node_modules/openai/resources/files.mjs ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FileObjectsPage: () => (/* binding */ FileObjectsPage),\n/* harmony export */   Files: () => (/* binding */ Files)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _error_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../error.mjs */ \"./node_modules/openai/error.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core.mjs */ \"./node_modules/openai/uploads.mjs\");\n/* harmony import */ var _pagination_mjs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../pagination.mjs */ \"./node_modules/openai/pagination.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\n\n\n\nclass Files extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    /**\n     * Upload a file that can be used across various endpoints. Individual files can be\n     * up to 512 MB, and the size of all files uploaded by one organization can be up\n     * to 100 GB.\n     *\n     * The Assistants API supports files up to 2 million tokens and of specific file\n     * types. See the\n     * [Assistants Tools guide](https://platform.openai.com/docs/assistants/tools) for\n     * details.\n     *\n     * The Fine-tuning API only supports `.jsonl` files. The input also has certain\n     * required formats for fine-tuning\n     * [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input) or\n     * [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)\n     * models.\n     *\n     * The Batch API only supports `.jsonl` files up to 200 MB in size. The input also\n     * has a specific required\n     * [format](https://platform.openai.com/docs/api-reference/batch/request-input).\n     *\n     * Please [contact us](https://help.openai.com/) if you need to increase these\n     * storage limits.\n     */\n    create(body, options) {\n        return this._client.post('/files', _core_mjs__WEBPACK_IMPORTED_MODULE_1__.multipartFormRequestOptions({ body, ...options }));\n    }\n    /**\n     * Returns information about a specific file.\n     */\n    retrieve(fileId, options) {\n        return this._client.get(`/files/${fileId}`, options);\n    }\n    list(query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_2__.isRequestOptions)(query)) {\n            return this.list({}, query);\n        }\n        return this._client.getAPIList('/files', FileObjectsPage, { query, ...options });\n    }\n    /**\n     * Delete a file.\n     */\n    del(fileId, options) {\n        return this._client.delete(`/files/${fileId}`, options);\n    }\n    /**\n     * Returns the contents of the specified file.\n     */\n    content(fileId, options) {\n        return this._client.get(`/files/${fileId}/content`, {\n            ...options,\n            headers: { Accept: 'application/binary', ...options?.headers },\n            __binaryResponse: true,\n        });\n    }\n    /**\n     * Returns the contents of the specified file.\n     *\n     * @deprecated The `.content()` method should be used instead\n     */\n    retrieveContent(fileId, options) {\n        return this._client.get(`/files/${fileId}/content`, options);\n    }\n    /**\n     * Waits for the given file to be processed, default timeout is 30 mins.\n     */\n    async waitForProcessing(id, { pollInterval = 5000, maxWait = 30 * 60 * 1000 } = {}) {\n        const TERMINAL_STATES = new Set(['processed', 'error', 'deleted']);\n        const start = Date.now();\n        let file = await this.retrieve(id);\n        while (!file.status || !TERMINAL_STATES.has(file.status)) {\n            await (0,_core_mjs__WEBPACK_IMPORTED_MODULE_2__.sleep)(pollInterval);\n            file = await this.retrieve(id);\n            if (Date.now() - start > maxWait) {\n                throw new _error_mjs__WEBPACK_IMPORTED_MODULE_3__.APIConnectionTimeoutError({\n                    message: `Giving up on waiting for file ${id} to finish processing after ${maxWait} milliseconds.`,\n                });\n            }\n        }\n        return file;\n    }\n}\nclass FileObjectsPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_4__.CursorPage {\n}\nFiles.FileObjectsPage = FileObjectsPage;\n//# sourceMappingURL=files.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/files.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/fine-tuning/fine-tuning.mjs":
/*!*******************************************************************!*\
  !*** ./node_modules/openai/resources/fine-tuning/fine-tuning.mjs ***!
  \*******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FineTuning: () => (/* binding */ FineTuning)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _jobs_jobs_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./jobs/jobs.mjs */ \"./node_modules/openai/resources/fine-tuning/jobs/jobs.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\nclass FineTuning extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    constructor() {\n        super(...arguments);\n        this.jobs = new _jobs_jobs_mjs__WEBPACK_IMPORTED_MODULE_1__.Jobs(this._client);\n    }\n}\nFineTuning.Jobs = _jobs_jobs_mjs__WEBPACK_IMPORTED_MODULE_1__.Jobs;\nFineTuning.FineTuningJobsPage = _jobs_jobs_mjs__WEBPACK_IMPORTED_MODULE_1__.FineTuningJobsPage;\nFineTuning.FineTuningJobEventsPage = _jobs_jobs_mjs__WEBPACK_IMPORTED_MODULE_1__.FineTuningJobEventsPage;\n//# sourceMappingURL=fine-tuning.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/fine-tuning/fine-tuning.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/fine-tuning/jobs/checkpoints.mjs":
/*!************************************************************************!*\
  !*** ./node_modules/openai/resources/fine-tuning/jobs/checkpoints.mjs ***!
  \************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Checkpoints: () => (/* binding */ Checkpoints),\n/* harmony export */   FineTuningJobCheckpointsPage: () => (/* binding */ FineTuningJobCheckpointsPage)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _pagination_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../pagination.mjs */ \"./node_modules/openai/pagination.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\nclass Checkpoints extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    list(fineTuningJobId, query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_1__.isRequestOptions)(query)) {\n            return this.list(fineTuningJobId, {}, query);\n        }\n        return this._client.getAPIList(`/fine_tuning/jobs/${fineTuningJobId}/checkpoints`, FineTuningJobCheckpointsPage, { query, ...options });\n    }\n}\nclass FineTuningJobCheckpointsPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_2__.CursorPage {\n}\nCheckpoints.FineTuningJobCheckpointsPage = FineTuningJobCheckpointsPage;\n//# sourceMappingURL=checkpoints.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/fine-tuning/jobs/checkpoints.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/fine-tuning/jobs/jobs.mjs":
/*!*****************************************************************!*\
  !*** ./node_modules/openai/resources/fine-tuning/jobs/jobs.mjs ***!
  \*****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FineTuningJobEventsPage: () => (/* binding */ FineTuningJobEventsPage),\n/* harmony export */   FineTuningJobsPage: () => (/* binding */ FineTuningJobsPage),\n/* harmony export */   Jobs: () => (/* binding */ Jobs)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../core.mjs */ \"./node_modules/openai/core.mjs\");\n/* harmony import */ var _checkpoints_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./checkpoints.mjs */ \"./node_modules/openai/resources/fine-tuning/jobs/checkpoints.mjs\");\n/* harmony import */ var _pagination_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../../pagination.mjs */ \"./node_modules/openai/pagination.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\n\n\nclass Jobs extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    constructor() {\n        super(...arguments);\n        this.checkpoints = new _checkpoints_mjs__WEBPACK_IMPORTED_MODULE_1__.Checkpoints(this._client);\n    }\n    /**\n     * Creates a fine-tuning job which begins the process of creating a new model from\n     * a given dataset.\n     *\n     * Response includes details of the enqueued job including job status and the name\n     * of the fine-tuned models once complete.\n     *\n     * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)\n     */\n    create(body, options) {\n        return this._client.post('/fine_tuning/jobs', { body, ...options });\n    }\n    /**\n     * Get info about a fine-tuning job.\n     *\n     * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)\n     */\n    retrieve(fineTuningJobId, options) {\n        return this._client.get(`/fine_tuning/jobs/${fineTuningJobId}`, options);\n    }\n    list(query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_2__.isRequestOptions)(query)) {\n            return this.list({}, query);\n        }\n        return this._client.getAPIList('/fine_tuning/jobs', FineTuningJobsPage, { query, ...options });\n    }\n    /**\n     * Immediately cancel a fine-tune job.\n     */\n    cancel(fineTuningJobId, options) {\n        return this._client.post(`/fine_tuning/jobs/${fineTuningJobId}/cancel`, options);\n    }\n    listEvents(fineTuningJobId, query = {}, options) {\n        if ((0,_core_mjs__WEBPACK_IMPORTED_MODULE_2__.isRequestOptions)(query)) {\n            return this.listEvents(fineTuningJobId, {}, query);\n        }\n        return this._client.getAPIList(`/fine_tuning/jobs/${fineTuningJobId}/events`, FineTuningJobEventsPage, {\n            query,\n            ...options,\n        });\n    }\n}\nclass FineTuningJobsPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_3__.CursorPage {\n}\nclass FineTuningJobEventsPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_3__.CursorPage {\n}\nJobs.FineTuningJobsPage = FineTuningJobsPage;\nJobs.FineTuningJobEventsPage = FineTuningJobEventsPage;\nJobs.Checkpoints = _checkpoints_mjs__WEBPACK_IMPORTED_MODULE_1__.Checkpoints;\nJobs.FineTuningJobCheckpointsPage = _checkpoints_mjs__WEBPACK_IMPORTED_MODULE_1__.FineTuningJobCheckpointsPage;\n//# sourceMappingURL=jobs.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/fine-tuning/jobs/jobs.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/images.mjs":
/*!**************************************************!*\
  !*** ./node_modules/openai/resources/images.mjs ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Images: () => (/* binding */ Images)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core.mjs */ \"./node_modules/openai/uploads.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\nclass Images extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    /**\n     * Creates a variation of a given image.\n     */\n    createVariation(body, options) {\n        return this._client.post('/images/variations', _core_mjs__WEBPACK_IMPORTED_MODULE_1__.multipartFormRequestOptions({ body, ...options }));\n    }\n    /**\n     * Creates an edited or extended image given an original image and a prompt.\n     */\n    edit(body, options) {\n        return this._client.post('/images/edits', _core_mjs__WEBPACK_IMPORTED_MODULE_1__.multipartFormRequestOptions({ body, ...options }));\n    }\n    /**\n     * Creates an image given a prompt.\n     */\n    generate(body, options) {\n        return this._client.post('/images/generations', { body, ...options });\n    }\n}\n//# sourceMappingURL=images.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/images.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/models.mjs":
/*!**************************************************!*\
  !*** ./node_modules/openai/resources/models.mjs ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Models: () => (/* binding */ Models),\n/* harmony export */   ModelsPage: () => (/* binding */ ModelsPage)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _pagination_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../pagination.mjs */ \"./node_modules/openai/pagination.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\nclass Models extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    /**\n     * Retrieves a model instance, providing basic information about the model such as\n     * the owner and permissioning.\n     */\n    retrieve(model, options) {\n        return this._client.get(`/models/${model}`, options);\n    }\n    /**\n     * Lists the currently available models, and provides basic information about each\n     * one such as the owner and availability.\n     */\n    list(options) {\n        return this._client.getAPIList('/models', ModelsPage, options);\n    }\n    /**\n     * Delete a fine-tuned model. You must have the Owner role in your organization to\n     * delete a model.\n     */\n    del(model, options) {\n        return this._client.delete(`/models/${model}`, options);\n    }\n}\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nclass ModelsPage extends _pagination_mjs__WEBPACK_IMPORTED_MODULE_1__.Page {\n}\nModels.ModelsPage = ModelsPage;\n//# sourceMappingURL=models.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/models.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/moderations.mjs":
/*!*******************************************************!*\
  !*** ./node_modules/openai/resources/moderations.mjs ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Moderations: () => (/* binding */ Moderations)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nclass Moderations extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    /**\n     * Classifies if text and/or image inputs are potentially harmful. Learn more in\n     * the [moderation guide](https://platform.openai.com/docs/guides/moderation).\n     */\n    create(body, options) {\n        return this._client.post('/moderations', { body, ...options });\n    }\n}\n//# sourceMappingURL=moderations.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/moderations.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/uploads/parts.mjs":
/*!*********************************************************!*\
  !*** ./node_modules/openai/resources/uploads/parts.mjs ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Parts: () => (/* binding */ Parts)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _core_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core.mjs */ \"./node_modules/openai/uploads.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\nclass Parts extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    /**\n     * Adds a\n     * [Part](https://platform.openai.com/docs/api-reference/uploads/part-object) to an\n     * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object.\n     * A Part represents a chunk of bytes from the file you are trying to upload.\n     *\n     * Each Part can be at most 64 MB, and you can add Parts until you hit the Upload\n     * maximum of 8 GB.\n     *\n     * It is possible to add multiple Parts in parallel. You can decide the intended\n     * order of the Parts when you\n     * [complete the Upload](https://platform.openai.com/docs/api-reference/uploads/complete).\n     */\n    create(uploadId, body, options) {\n        return this._client.post(`/uploads/${uploadId}/parts`, _core_mjs__WEBPACK_IMPORTED_MODULE_1__.multipartFormRequestOptions({ body, ...options }));\n    }\n}\n//# sourceMappingURL=parts.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/uploads/parts.mjs?");

/***/ }),

/***/ "./node_modules/openai/resources/uploads/uploads.mjs":
/*!***********************************************************!*\
  !*** ./node_modules/openai/resources/uploads/uploads.mjs ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Uploads: () => (/* binding */ Uploads)\n/* harmony export */ });\n/* harmony import */ var _resource_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../resource.mjs */ \"./node_modules/openai/resource.mjs\");\n/* harmony import */ var _parts_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./parts.mjs */ \"./node_modules/openai/resources/uploads/parts.mjs\");\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n\n\nclass Uploads extends _resource_mjs__WEBPACK_IMPORTED_MODULE_0__.APIResource {\n    constructor() {\n        super(...arguments);\n        this.parts = new _parts_mjs__WEBPACK_IMPORTED_MODULE_1__.Parts(this._client);\n    }\n    /**\n     * Creates an intermediate\n     * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object\n     * that you can add\n     * [Parts](https://platform.openai.com/docs/api-reference/uploads/part-object) to.\n     * Currently, an Upload can accept at most 8 GB in total and expires after an hour\n     * after you create it.\n     *\n     * Once you complete the Upload, we will create a\n     * [File](https://platform.openai.com/docs/api-reference/files/object) object that\n     * contains all the parts you uploaded. This File is usable in the rest of our\n     * platform as a regular File object.\n     *\n     * For certain `purpose`s, the correct `mime_type` must be specified. Please refer\n     * to documentation for the supported MIME types for your use case:\n     *\n     * - [Assistants](https://platform.openai.com/docs/assistants/tools/file-search#supported-files)\n     *\n     * For guidance on the proper filename extensions for each purpose, please follow\n     * the documentation on\n     * [creating a File](https://platform.openai.com/docs/api-reference/files/create).\n     */\n    create(body, options) {\n        return this._client.post('/uploads', { body, ...options });\n    }\n    /**\n     * Cancels the Upload. No Parts may be added after an Upload is cancelled.\n     */\n    cancel(uploadId, options) {\n        return this._client.post(`/uploads/${uploadId}/cancel`, options);\n    }\n    /**\n     * Completes the\n     * [Upload](https://platform.openai.com/docs/api-reference/uploads/object).\n     *\n     * Within the returned Upload object, there is a nested\n     * [File](https://platform.openai.com/docs/api-reference/files/object) object that\n     * is ready to use in the rest of the platform.\n     *\n     * You can specify the order of the Parts by passing in an ordered list of the Part\n     * IDs.\n     *\n     * The number of bytes uploaded upon completion must match the number of bytes\n     * initially specified when creating the Upload object. No Parts may be added after\n     * an Upload is completed.\n     */\n    complete(uploadId, body, options) {\n        return this._client.post(`/uploads/${uploadId}/complete`, { body, ...options });\n    }\n}\nUploads.Parts = _parts_mjs__WEBPACK_IMPORTED_MODULE_1__.Parts;\n//# sourceMappingURL=uploads.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/resources/uploads/uploads.mjs?");

/***/ }),

/***/ "./node_modules/openai/streaming.mjs":
/*!*******************************************!*\
  !*** ./node_modules/openai/streaming.mjs ***!
  \*******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Stream: () => (/* binding */ Stream),\n/* harmony export */   _iterSSEMessages: () => (/* binding */ _iterSSEMessages)\n/* harmony export */ });\n/* harmony import */ var _shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./_shims/index.mjs */ \"./node_modules/openai/_shims/index.mjs\");\n/* harmony import */ var _error_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./error.mjs */ \"./node_modules/openai/error.mjs\");\n/* harmony import */ var _internal_decoders_line_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./internal/decoders/line.mjs */ \"./node_modules/openai/internal/decoders/line.mjs\");\n/* harmony import */ var _internal_stream_utils_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./internal/stream-utils.mjs */ \"./node_modules/openai/internal/stream-utils.mjs\");\n\n\n\n\n\nclass Stream {\n    constructor(iterator, controller) {\n        this.iterator = iterator;\n        this.controller = controller;\n    }\n    static fromSSEResponse(response, controller) {\n        let consumed = false;\n        async function* iterator() {\n            if (consumed) {\n                throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n            }\n            consumed = true;\n            let done = false;\n            try {\n                for await (const sse of _iterSSEMessages(response, controller)) {\n                    if (done)\n                        continue;\n                    if (sse.data.startsWith('[DONE]')) {\n                        done = true;\n                        continue;\n                    }\n                    if (sse.event === null) {\n                        let data;\n                        try {\n                            data = JSON.parse(sse.data);\n                        }\n                        catch (e) {\n                            console.error(`Could not parse message into JSON:`, sse.data);\n                            console.error(`From chunk:`, sse.raw);\n                            throw e;\n                        }\n                        if (data && data.error) {\n                            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.APIError(undefined, data.error, undefined, undefined);\n                        }\n                        yield data;\n                    }\n                    else {\n                        let data;\n                        try {\n                            data = JSON.parse(sse.data);\n                        }\n                        catch (e) {\n                            console.error(`Could not parse message into JSON:`, sse.data);\n                            console.error(`From chunk:`, sse.raw);\n                            throw e;\n                        }\n                        // TODO: Is this where the error should be thrown?\n                        if (sse.event == 'error') {\n                            throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.APIError(undefined, data.error, data.message, undefined);\n                        }\n                        yield { event: sse.event, data: data };\n                    }\n                }\n                done = true;\n            }\n            catch (e) {\n                // If the user calls `stream.controller.abort()`, we should exit without throwing.\n                if (e instanceof Error && e.name === 'AbortError')\n                    return;\n                throw e;\n            }\n            finally {\n                // If the user `break`s, abort the ongoing request.\n                if (!done)\n                    controller.abort();\n            }\n        }\n        return new Stream(iterator, controller);\n    }\n    /**\n     * Generates a Stream from a newline-separated ReadableStream\n     * where each item is a JSON value.\n     */\n    static fromReadableStream(readableStream, controller) {\n        let consumed = false;\n        async function* iterLines() {\n            const lineDecoder = new _internal_decoders_line_mjs__WEBPACK_IMPORTED_MODULE_2__.LineDecoder();\n            const iter = (0,_internal_stream_utils_mjs__WEBPACK_IMPORTED_MODULE_3__.ReadableStreamToAsyncIterable)(readableStream);\n            for await (const chunk of iter) {\n                for (const line of lineDecoder.decode(chunk)) {\n                    yield line;\n                }\n            }\n            for (const line of lineDecoder.flush()) {\n                yield line;\n            }\n        }\n        async function* iterator() {\n            if (consumed) {\n                throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n            }\n            consumed = true;\n            let done = false;\n            try {\n                for await (const line of iterLines()) {\n                    if (done)\n                        continue;\n                    if (line)\n                        yield JSON.parse(line);\n                }\n                done = true;\n            }\n            catch (e) {\n                // If the user calls `stream.controller.abort()`, we should exit without throwing.\n                if (e instanceof Error && e.name === 'AbortError')\n                    return;\n                throw e;\n            }\n            finally {\n                // If the user `break`s, abort the ongoing request.\n                if (!done)\n                    controller.abort();\n            }\n        }\n        return new Stream(iterator, controller);\n    }\n    [Symbol.asyncIterator]() {\n        return this.iterator();\n    }\n    /**\n     * Splits the stream into two streams which can be\n     * independently read from at different speeds.\n     */\n    tee() {\n        const left = [];\n        const right = [];\n        const iterator = this.iterator();\n        const teeIterator = (queue) => {\n            return {\n                next: () => {\n                    if (queue.length === 0) {\n                        const result = iterator.next();\n                        left.push(result);\n                        right.push(result);\n                    }\n                    return queue.shift();\n                },\n            };\n        };\n        return [\n            new Stream(() => teeIterator(left), this.controller),\n            new Stream(() => teeIterator(right), this.controller),\n        ];\n    }\n    /**\n     * Converts this stream to a newline-separated ReadableStream of\n     * JSON stringified values in the stream\n     * which can be turned back into a Stream with `Stream.fromReadableStream()`.\n     */\n    toReadableStream() {\n        const self = this;\n        let iter;\n        const encoder = new TextEncoder();\n        return new _shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__.ReadableStream({\n            async start() {\n                iter = self[Symbol.asyncIterator]();\n            },\n            async pull(ctrl) {\n                try {\n                    const { value, done } = await iter.next();\n                    if (done)\n                        return ctrl.close();\n                    const bytes = encoder.encode(JSON.stringify(value) + '\\n');\n                    ctrl.enqueue(bytes);\n                }\n                catch (err) {\n                    ctrl.error(err);\n                }\n            },\n            async cancel() {\n                await iter.return?.();\n            },\n        });\n    }\n}\nasync function* _iterSSEMessages(response, controller) {\n    if (!response.body) {\n        controller.abort();\n        throw new _error_mjs__WEBPACK_IMPORTED_MODULE_1__.OpenAIError(`Attempted to iterate over a response with no body`);\n    }\n    const sseDecoder = new SSEDecoder();\n    const lineDecoder = new _internal_decoders_line_mjs__WEBPACK_IMPORTED_MODULE_2__.LineDecoder();\n    const iter = (0,_internal_stream_utils_mjs__WEBPACK_IMPORTED_MODULE_3__.ReadableStreamToAsyncIterable)(response.body);\n    for await (const sseChunk of iterSSEChunks(iter)) {\n        for (const line of lineDecoder.decode(sseChunk)) {\n            const sse = sseDecoder.decode(line);\n            if (sse)\n                yield sse;\n        }\n    }\n    for (const line of lineDecoder.flush()) {\n        const sse = sseDecoder.decode(line);\n        if (sse)\n            yield sse;\n    }\n}\n/**\n * Given an async iterable iterator, iterates over it and yields full\n * SSE chunks, i.e. yields when a double new-line is encountered.\n */\nasync function* iterSSEChunks(iterator) {\n    let data = new Uint8Array();\n    for await (const chunk of iterator) {\n        if (chunk == null) {\n            continue;\n        }\n        const binaryChunk = chunk instanceof ArrayBuffer ? new Uint8Array(chunk)\n            : typeof chunk === 'string' ? new TextEncoder().encode(chunk)\n                : chunk;\n        let newData = new Uint8Array(data.length + binaryChunk.length);\n        newData.set(data);\n        newData.set(binaryChunk, data.length);\n        data = newData;\n        let patternIndex;\n        while ((patternIndex = (0,_internal_decoders_line_mjs__WEBPACK_IMPORTED_MODULE_2__.findDoubleNewlineIndex)(data)) !== -1) {\n            yield data.slice(0, patternIndex);\n            data = data.slice(patternIndex);\n        }\n    }\n    if (data.length > 0) {\n        yield data;\n    }\n}\nclass SSEDecoder {\n    constructor() {\n        this.event = null;\n        this.data = [];\n        this.chunks = [];\n    }\n    decode(line) {\n        if (line.endsWith('\\r')) {\n            line = line.substring(0, line.length - 1);\n        }\n        if (!line) {\n            // empty line and we didn't previously encounter any messages\n            if (!this.event && !this.data.length)\n                return null;\n            const sse = {\n                event: this.event,\n                data: this.data.join('\\n'),\n                raw: this.chunks,\n            };\n            this.event = null;\n            this.data = [];\n            this.chunks = [];\n            return sse;\n        }\n        this.chunks.push(line);\n        if (line.startsWith(':')) {\n            return null;\n        }\n        let [fieldname, _, value] = partition(line, ':');\n        if (value.startsWith(' ')) {\n            value = value.substring(1);\n        }\n        if (fieldname === 'event') {\n            this.event = value;\n        }\n        else if (fieldname === 'data') {\n            this.data.push(value);\n        }\n        return null;\n    }\n}\nfunction partition(str, delimiter) {\n    const index = str.indexOf(delimiter);\n    if (index !== -1) {\n        return [str.substring(0, index), delimiter, str.substring(index + delimiter.length)];\n    }\n    return [str, '', ''];\n}\n//# sourceMappingURL=streaming.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/streaming.mjs?");

/***/ }),

/***/ "./node_modules/openai/uploads.mjs":
/*!*****************************************!*\
  !*** ./node_modules/openai/uploads.mjs ***!
  \*****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   createForm: () => (/* binding */ createForm),\n/* harmony export */   fileFromPath: () => (/* reexport safe */ _shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__.fileFromPath),\n/* harmony export */   isBlobLike: () => (/* binding */ isBlobLike),\n/* harmony export */   isFileLike: () => (/* binding */ isFileLike),\n/* harmony export */   isMultipartBody: () => (/* binding */ isMultipartBody),\n/* harmony export */   isResponseLike: () => (/* binding */ isResponseLike),\n/* harmony export */   isUploadable: () => (/* binding */ isUploadable),\n/* harmony export */   maybeMultipartFormRequestOptions: () => (/* binding */ maybeMultipartFormRequestOptions),\n/* harmony export */   multipartFormRequestOptions: () => (/* binding */ multipartFormRequestOptions),\n/* harmony export */   toFile: () => (/* binding */ toFile)\n/* harmony export */ });\n/* harmony import */ var _shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./_shims/index.mjs */ \"./node_modules/openai/_shims/index.mjs\");\n\n\nconst isResponseLike = (value) => value != null &&\n    typeof value === 'object' &&\n    typeof value.url === 'string' &&\n    typeof value.blob === 'function';\nconst isFileLike = (value) => value != null &&\n    typeof value === 'object' &&\n    typeof value.name === 'string' &&\n    typeof value.lastModified === 'number' &&\n    isBlobLike(value);\n/**\n * The BlobLike type omits arrayBuffer() because @types/node-fetch@^2.6.4 lacks it; but this check\n * adds the arrayBuffer() method type because it is available and used at runtime\n */\nconst isBlobLike = (value) => value != null &&\n    typeof value === 'object' &&\n    typeof value.size === 'number' &&\n    typeof value.type === 'string' &&\n    typeof value.text === 'function' &&\n    typeof value.slice === 'function' &&\n    typeof value.arrayBuffer === 'function';\nconst isUploadable = (value) => {\n    return isFileLike(value) || isResponseLike(value) || (0,_shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__.isFsReadStream)(value);\n};\n/**\n * Helper for creating a {@link File} to pass to an SDK upload method from a variety of different data formats\n * @param value the raw content of the file.  Can be an {@link Uploadable}, {@link BlobLikePart}, or {@link AsyncIterable} of {@link BlobLikePart}s\n * @param {string=} name the name of the file. If omitted, toFile will try to determine a file name from bits if possible\n * @param {Object=} options additional properties\n * @param {string=} options.type the MIME type of the content\n * @param {number=} options.lastModified the last modified timestamp\n * @returns a {@link File} with the given properties\n */\nasync function toFile(value, name, options) {\n    // If it's a promise, resolve it.\n    value = await value;\n    // If we've been given a `File` we don't need to do anything\n    if (isFileLike(value)) {\n        return value;\n    }\n    if (isResponseLike(value)) {\n        const blob = await value.blob();\n        name || (name = new URL(value.url).pathname.split(/[\\\\/]/).pop() ?? 'unknown_file');\n        // we need to convert the `Blob` into an array buffer because the `Blob` class\n        // that `node-fetch` defines is incompatible with the web standard which results\n        // in `new File` interpreting it as a string instead of binary data.\n        const data = isBlobLike(blob) ? [(await blob.arrayBuffer())] : [blob];\n        return new _shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__.File(data, name, options);\n    }\n    const bits = await getBytes(value);\n    name || (name = getName(value) ?? 'unknown_file');\n    if (!options?.type) {\n        const type = bits[0]?.type;\n        if (typeof type === 'string') {\n            options = { ...options, type };\n        }\n    }\n    return new _shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__.File(bits, name, options);\n}\nasync function getBytes(value) {\n    let parts = [];\n    if (typeof value === 'string' ||\n        ArrayBuffer.isView(value) || // includes Uint8Array, Buffer, etc.\n        value instanceof ArrayBuffer) {\n        parts.push(value);\n    }\n    else if (isBlobLike(value)) {\n        parts.push(await value.arrayBuffer());\n    }\n    else if (isAsyncIterableIterator(value) // includes Readable, ReadableStream, etc.\n    ) {\n        for await (const chunk of value) {\n            parts.push(chunk); // TODO, consider validating?\n        }\n    }\n    else {\n        throw new Error(`Unexpected data type: ${typeof value}; constructor: ${value?.constructor\n            ?.name}; props: ${propsForError(value)}`);\n    }\n    return parts;\n}\nfunction propsForError(value) {\n    const props = Object.getOwnPropertyNames(value);\n    return `[${props.map((p) => `\"${p}\"`).join(', ')}]`;\n}\nfunction getName(value) {\n    return (getStringFromMaybeBuffer(value.name) ||\n        getStringFromMaybeBuffer(value.filename) ||\n        // For fs.ReadStream\n        getStringFromMaybeBuffer(value.path)?.split(/[\\\\/]/).pop());\n}\nconst getStringFromMaybeBuffer = (x) => {\n    if (typeof x === 'string')\n        return x;\n    if (typeof Buffer !== 'undefined' && x instanceof Buffer)\n        return String(x);\n    return undefined;\n};\nconst isAsyncIterableIterator = (value) => value != null && typeof value === 'object' && typeof value[Symbol.asyncIterator] === 'function';\nconst isMultipartBody = (body) => body && typeof body === 'object' && body.body && body[Symbol.toStringTag] === 'MultipartBody';\n/**\n * Returns a multipart/form-data request if any part of the given request body contains a File / Blob value.\n * Otherwise returns the request as is.\n */\nconst maybeMultipartFormRequestOptions = async (opts) => {\n    if (!hasUploadableValue(opts.body))\n        return opts;\n    const form = await createForm(opts.body);\n    return (0,_shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__.getMultipartRequestOptions)(form, opts);\n};\nconst multipartFormRequestOptions = async (opts) => {\n    const form = await createForm(opts.body);\n    return (0,_shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__.getMultipartRequestOptions)(form, opts);\n};\nconst createForm = async (body) => {\n    const form = new _shims_index_mjs__WEBPACK_IMPORTED_MODULE_0__.FormData();\n    await Promise.all(Object.entries(body || {}).map(([key, value]) => addFormValue(form, key, value)));\n    return form;\n};\nconst hasUploadableValue = (value) => {\n    if (isUploadable(value))\n        return true;\n    if (Array.isArray(value))\n        return value.some(hasUploadableValue);\n    if (value && typeof value === 'object') {\n        for (const k in value) {\n            if (hasUploadableValue(value[k]))\n                return true;\n        }\n    }\n    return false;\n};\nconst addFormValue = async (form, key, value) => {\n    if (value === undefined)\n        return;\n    if (value == null) {\n        throw new TypeError(`Received null for \"${key}\"; to pass null in FormData, you must use the string 'null'`);\n    }\n    // TODO: make nested formats configurable\n    if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n        form.append(key, String(value));\n    }\n    else if (isUploadable(value)) {\n        const file = await toFile(value);\n        form.append(key, file);\n    }\n    else if (Array.isArray(value)) {\n        await Promise.all(value.map((entry) => addFormValue(form, key + '[]', entry)));\n    }\n    else if (typeof value === 'object') {\n        await Promise.all(Object.entries(value).map(([name, prop]) => addFormValue(form, `${key}[${name}]`, prop)));\n    }\n    else {\n        throw new TypeError(`Invalid value given to form, expected a string, number, boolean, object, Array, File or Blob but got ${value} instead`);\n    }\n};\n//# sourceMappingURL=uploads.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/uploads.mjs?");

/***/ }),

/***/ "./node_modules/openai/version.mjs":
/*!*****************************************!*\
  !*** ./node_modules/openai/version.mjs ***!
  \*****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   VERSION: () => (/* binding */ VERSION)\n/* harmony export */ });\nconst VERSION = '4.86.1'; // x-release-please-version\n//# sourceMappingURL=version.mjs.map\n\n//# sourceURL=webpack://y/./node_modules/openai/version.mjs?");

/***/ }),

/***/ "./pages/formtest2.js":
/*!****************************!*\
  !*** ./pages/formtest2.js ***!
  \****************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var openai__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! openai */ \"./node_modules/openai/index.mjs\");\n\r\n\r\nconst openai = new openai__WEBPACK_IMPORTED_MODULE_0__[\"default\"]({\r\n    apiKey:OPENAI_API_KEY , // Substitua pela sua chave de API real\r\n    dangerouslyAllowBrowser: true, // Habilita o uso no navegador (NÃƒO RECOMENDADO para produÃ§Ã£o)\r\n});\r\n\r\nconst perguntas = [\r\n    \"Quais disciplinas apresentam as maiores taxas de reprovaÃ§Ã£o e quais sÃ£o os padrÃµes de dificuldade dos alunos nessas disciplinas?\",\r\n    \"Quais alunos se beneficiariam de intervenÃ§Ãµes pedagÃ³gicas personalizadas, como reforÃ§o em Ã¡reas especÃ­ficas ou atividades de enriquecimento?\",\r\n    \"Quais sÃ£o os padrÃµes de ausÃªncia dos alunos e quais fatores podem estar contribuindo para a falta de frequÃªncia?\",\r\n    \"Quais alunos apresentam padrÃµes de comportamento que podem indicar problemas de disciplina ou dificuldades sociais?\",\r\n    \"Como o ambiente escolar (clima, infraestrutura, relaÃ§Ãµes interpessoais) influencia o comportamento e o engajamento dos alunos?\"\r\n];\r\n\r\nconst respostas = {};\r\nlet perguntaAtual = 0;\r\n\r\nfunction exibirPergunta() {\r\n    if (perguntaAtual < perguntas.length) {\r\n        document.getElementById(\"pergunta\").textContent = perguntas[perguntaAtual];\r\n    } else {\r\n        exibirMensagemFinal();\r\n    }\r\n}\r\n\r\nfunction armazenarResposta() {\r\n    const resposta = document.getElementById(\"resposta\").value.trim();\r\n    if (resposta === \"\") {\r\n        alert(\"Por favor, insira uma resposta.\");\r\n        return;\r\n    }\r\n    respostas[perguntas[perguntaAtual]] = resposta;\r\n    document.getElementById(\"resposta\").value = \"\";\r\n    perguntaAtual++;\r\n    exibirPergunta();\r\n}\r\n\r\nfunction gerarPromptChatGPT() {\r\n    let textoRespostas = \"\";\r\n    for (const pergunta in respostas) {\r\n        textoRespostas += `${pergunta}: ${respostas[pergunta]}\\n`;\r\n    }\r\n\r\n    const prompt = `Analise as seguintes respostas sobre o desempenho dos alunos e forneÃ§a insights concisos e prÃ¡ticos para melhorias:\\n\\n${textoRespostas}\\n\\nForneÃ§a respostas curtas e diretas.`;\r\n    return prompt;\r\n}\r\n\r\nasync function obterRespostaChatGPT() {\r\n    const prompt = gerarPromptChatGPT();\r\n\r\n    try {\r\n        const completion = await openai.chat.completions.create({\r\n            model: \"gpt-4o-mini\", // Modelo vÃ¡lido da OpenAI\r\n            messages: [{ role: \"user\", content: prompt }],\r\n            max_tokens: 200,\r\n        });\r\n\r\n        const respostaIA = completion.choices[0].message.content.trim();\r\n        document.getElementById(\"respostaIA\").textContent = respostaIA;\r\n        document.getElementById(\"respostaIA\").style.display = \"block\";\r\n    } catch (error) {\r\n        console.error(\"Erro ao obter resposta da API da OpenAI:\", error);\r\n        document.getElementById(\"respostaIA\").textContent = \"Erro ao obter resposta da IA.\";\r\n        document.getElementById(\"respostaIA\").style.display = \"block\";\r\n    }\r\n}\r\n\r\nfunction exibirMensagemFinal() {\r\n    document.getElementById(\"pergunta\").style.display = \"none\";\r\n    document.getElementById(\"resposta\").style.display = \"none\";\r\n    document.getElementById(\"enviar\").style.display = \"none\";\r\n    document.getElementById(\"titulo\").style.display = \"none\";\r\n    document.getElementById(\"mensagemFinal\").style.display = \"block\";\r\n    const btnGerarTexto = document.createElement(\"button\");\r\n    btnGerarTexto.textContent = \"Obter resposta da IA\";\r\n    btnGerarTexto.addEventListener(\"click\", obterRespostaChatGPT);\r\n    document.getElementById(\"mensagemFinal\").appendChild(btnGerarTexto);\r\n    const respostaIA = document.createElement(\"p\");\r\n    respostaIA.id = \"respostaIA\";\r\n    respostaIA.style.display = \"none\";\r\n    document.getElementById(\"mensagemFinal\").appendChild(respostaIA);\r\n}\r\n\r\ndocument.getElementById(\"enviar\").addEventListener(\"click\", armazenarResposta);\r\nexibirPergunta();\r\n\n\n//# sourceURL=webpack://y/./pages/formtest2.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./pages/formtest2.js");
/******/ 	
/******/ })()
;